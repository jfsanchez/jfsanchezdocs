{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Presentaci\u00f3ns","text":"<ul> <li> <p>\ud83d\udda5\ufe0f Conceptos de inform\u00e1tica b\u00e1sica</p> </li> <li> <p>\ud83d\udd78\ufe0f Modos de Rede no VirtualBox</p> </li> <li> <p>\ud83d\udc31 Uso b\u00e1sico de git</p> </li> <li> <p>\ud83d\udc0d Conda e pip</p> </li> <li> <p>\u274e XPATH para uso con Selenium</p> </li> <li> <p>\ud83e\udeb6 MongoDB</p> </li> <li> <p>\ud83d\udc33 Docker / Contedores</p> </li> <li> <p>\ud83d\udcd5 FP en Galicia. Desactualizado!</p> </li> </ul> <p>Presentaci\u00f3ns feitas con revealjs.</p> <p>Os materiais publicanse con copyright. Perm\u00edtese o seu uso en docencia, pero non para formaci\u00f3n de formadores. Non se permite a s\u00faa inclusi\u00f3n en materiales elaborados, oficiais ou non por parte de empresas que elaboren/vendan materiais, bootcamps, editoriais e similares ou a instituci\u00f3ns p\u00fablicas ou privadas de calquer tipo, posto que non forman parte dos seus materiais. O \u00fanico uso permitido \u00e9 a docentes para as s\u00faas clases.</p> <p>Se atopas erros, por favor, ponte en contacto conmigo (preme nunha das presentaci\u00f3ns e mira o correo na \u00faltima diapositiva).</p>"},{"location":"apache-hadoop-0-instalacion/","title":"\ud83e\uddfe \ud83d\udc18 Apache Hadoop - Instalaci\u00f3n","text":"<p>Instalaci\u00f3n de Apache Hadoop empregando ClusterShell</p>"},{"location":"apache-hadoop-0-instalacion/#requisitos-previos","title":"Requisitos previos","text":"<p>Estas probas foron feitas nunha contorna baixo Rocky Linux 8.5 v2 no CESGA, no seu OpenStack.</p>"},{"location":"apache-hadoop-0-instalacion/#grupo-de-seguridade","title":"Grupo de seguridade","text":"<p>Teremos que abrir os seguintes portos (ollo, deber\u00edamolos abrir s\u00f3 entre eles e para nos, posto que deixar abertos os portos \u00e9 un importante risco de seguridade):</p> <p>Xerais:</p> <ul> <li>SSH: 22 (TCP).</li> </ul> <p>Apache Hadoop:</p> <ul> <li>HADOOP_HDFS: 9000 (TCP)</li> <li>HADDOP_MASTER_WEB: 9870 (TCP)</li> <li>HADOOP_SECONDARY_NAMENODE_WEB 9864 (TCP) (admin)</li> <li>HADOOP_SECONDARY_NAMENODE_WEB 9868 (TCP)</li> </ul> <p>Apache Spark:</p> <ul> <li>SPARK_MAIN: 9001 (TCP)</li> <li>INFO_MASTER_SPARK: 8080 (TCP)</li> <li>INFO_WORKERS_SPARK: 8081 (TCP)</li> <li>INFO_WORKERS_SPARK_WEB: 4040 (TCP)</li> <li>OUTROS: 7707 (TCP)</li> </ul>"},{"location":"apache-hadoop-0-instalacion/#instalacion-de-clustershell","title":"Instalaci\u00f3n de ClusterShell","text":"<p>Debemos instalar ClusterShell no nodo master ou no equipo onde fagamos a instalaci\u00f3n. ClusterShell \u00e9 un programa que permite enviar \u00e1 vez comandos a varias m\u00e1quinas.</p> <p>Executemos os comandos dende o noso equipo local ou dende o nodo master, podemos incluir o nodo master para conectarnos contra el mesmo e executar tam\u00e9n nel os comandos.</p>"},{"location":"apache-hadoop-0-instalacion/#instalacion-dende-rocky-linux-ou-distro-baseada-en-redhat","title":"Instalaci\u00f3n dende Rocky Linux ou distro baseada en Redhat","text":"<pre><code>sudo yum --enablerepo=extras -y install epel-release\n</code></pre> <pre><code>sudo yum install -y clustershell\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#instalacion-dende-linux-mint-ou-distro-baseada-en-ubuntudebian","title":"Instalaci\u00f3n dende Linux Mint ou distro baseada en Ubuntu/Debian","text":"<pre><code>sudo apt-get install clustershell\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#conexion-aos-servidores-por-nome","title":"Conexi\u00f3n aos servidores por nome","text":"<p>Deberemos configurar o arquivo <code>/etc/hosts</code> cos nomes dos servidores:</p> /etc/hosts<pre><code>X.Y.Z.T1 hadoop1 hadoop1.local\nX.Y.Z.T2 hadoop2 hadoop2.local\nX.Y.Z.T3 hadoop3 hadoop3.local\n...\n[X.Y.Z.Tn hadoopN hadoopN.local]\n</code></pre> <p>Cada un destes servidores debe ter como m\u00ednimo 4 GB de RAM (8 \u00e9 o m\u00ednimo recomendable m\u00e1is imos aplicar restricci\u00f3ns na configuraci\u00f3n).</p> <p>Debemos ter creado un usuario chamado <code>cesgaxuser</code>, co que executaremos t\u00f3dolos comandos. Este usuario existe por defecto nas m\u00e1quinas virtuais novas creadas no OpenStack do CESGA.</p> <p>Dende o nodo master (hadoop1) debemos poder conectar por SSH ao resto de nodos: hadoop2, hadoop3 ... hadoopN (ter copiada a parte p\u00fablica da chave SSH no <code>.ssh/authorized_keys</code>). Podemos xerar e meter unha chave nova no master (empregando <code>ssh-keygen</code>) ou ben copiar a chave que nos xenere o OpenStack (arquivo .pem coa chave RSA).</p> <p>Se copiamos a chave RSA xerada polo OpenStack durante a creaci\u00f3n da m\u00e1quina, podemos copiala mediante scp:</p> <p>Neste exemplo imaxinamos que este arquivo, gardado no directorio onde nos atopemos, ch\u00e1mase: <code>ficheiro-chave-ssh.pem</code></p> <ul> <li> <p>Copiamos o arquivo (ollo, hai que repetir o arquivo, unha vez para pasalo como chave a empregar e outra para copialo):</p> <pre><code>scp -i ficheiro-chave-ssh.pem \\\n  ficheiro-chave-ssh.pem cesgaxuser@hadoop1:/home/cesgaxuser/\n</code></pre> </li> </ul> <p>Se nos devolve un erro coma este:</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nPermissions 0755 for 'ficheiro-chave-ssh.pem' are too open.\nIt is required that your private key files are NOT accessible by others.\nThis private key will be ignored.\nLoad key \"ficheiro-chave-ssh.pem\": bad permissions\n</code></pre> <p>Deberemos dar permisos adecuados (s\u00f3 podemos ler a chave nos):</p> <pre><code>chmod 0600 ficheiro-chave-ssh.pem\n</code></pre> <ul> <li> <p>Conectamos co master:</p> <pre><code>ssh -i ficheiro-chave-ssh.pem cesgaxuser@hadoop1\n</code></pre> </li> <li> <p>Dentro do master, forzaremos a creaci\u00f3n da estrutura <code>.ssh</code> no directorio <code>$HOME</code>:</p> <pre><code>ssh localhost\n</code></pre> </li> </ul> <p>Preguntaranos se queremos conectar co servidor, xa que \u00e9 a primeira vez e non co\u00f1ece a chave:</p> <pre><code>[cesgaxuser@hadoop1 ~]$ ssh localhost\nThe authenticity of host 'localhost (::1)' can't be established.\nECDSA key fingerprint is SHA256:5aeqrZspd4Wev7IrUFH/KS8OXORpa614OEWXRHUG+yE.\nAre you sure you want to continue connecting (yes/no/[fingerprint])? \n</code></pre> <p>Contestamos <code>yes</code> e damos a enter para que se cree a estrutura <code>.ssh</code>.</p> <p>Agora toca mover a chave privada ao directorio por defecto:</p> <pre><code>mv ficheiro-chave-ssh.pem .ssh/id_rsa\n</code></pre> <p>E dar os permisos adecuados:</p> <pre><code>chmod 0600 .ssh/id_rsa\n</code></pre> <p>Finalmente, xeraremos a parte p\u00fablica da nosa chave privada:</p> <pre><code>ssh-keygen -y -f .ssh/id_rsa &gt; .ssh/id_rsa.pub\n</code></pre> <p>Copiaremos as chaves do nodo master ao resto de nodos por comodidade, de xeito que poderemos enviar un comando a t\u00f3dolos nodos dende calquera. Esto pode supor un risco de seguridade, mais poderemos borrar se queremos a chave privada do resto de nodos. De t\u00f3dolos xeitos, tendo en conta que a configuraci\u00f3n \u00e9 a mesma en t\u00f3dolos nodos e que est\u00e1n conectados, que logre acceder a un, moi probablemente poida acceder a todos.</p> <p>No <code>.ssh/known_hosts</code> de hadoop1, hadoop2 ... hadoopN precisamos os fingerprints de todos os servidores. Para facelo:</p> <ul> <li> <p>Descargamos os fingerprints dos servidores (con t\u00f3dalas IPs e nomes):</p> <pre><code>for servidor in $(cat /etc/hosts|grep hadoop); do \\\n  ssh-keyscan -H $servidor; done &gt;&gt; /home/cesgaxuser/.ssh/known_hosts\n</code></pre> </li> </ul> <p>Se mud\u00e1semos a li\u00f1a que lista os hosts por esta: <code>$(cat /etc/hosts|grep hadoop|awk '{print $1}'</code>, poder\u00edamos asociar as chaves s\u00f3 os enderezos IP.</p> <ul> <li> <p>Copiamos a configuraci\u00f3n a t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy /home/cesgaxuser/.ssh \\\n  --dest /home/cesgaxuser/\n</code></pre> </li> </ul>"},{"location":"apache-hadoop-0-instalacion/#actualizacion-de-paquetes","title":"Actualizaci\u00f3n de paquetes","text":"<p>Antes de seguir, \u00e9 moi conveniente actualizar o sistema para evitar erros de seguridade. Deste xeito probamos que podemos conectar con t\u00f3dolos nodos.</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] sudo dnf update -y\n</code></pre> <p>(opcional, m\u00e1is recomendable) E por comodidade, instalamos <code>nano</code> un editor moi simple e m\u00e1is amigable que <code>vi</code> e tam\u00e9n <code>net-tools</code> por se precisamos ver certas configuraci\u00f3ns de rede para diagnosticar erros.</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] sudo dnf install -y nano net-tools\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#instalacion-de-java-openjdk-correto-de-amazon","title":"Instalaci\u00f3n de Java OpenJDK Correto de Amazon","text":"<p>En t\u00f3dolos equipos debemos ter instalada a m\u00e1quina virtual de Java OpenJDK versi\u00f3n Corrreto de Amazon a trav\u00e9s de repositorio. </p> <p>Engadimos o respositorio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo curl -L -o /etc/yum.repos.d/corretto.repo \\\n  https://yum.corretto.aws/corretto.repo\n</code></pre> <p>Instalamos o paquete:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo dnf install -y java-11-amazon-corretto-devel`\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#configuracion-do-nodo-master","title":"Configuraci\u00f3n do nodo master","text":"<p>Debemos conectarnos por SSH ao nodo master:</p> <pre><code>ssh cesgaxuser@hadoop1\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#configuracion-de-java_home-en-todolos-servidores","title":"Configuraci\u00f3n de JAVA_HOME en t\u00f3dolos servidores","text":"<p>Editaremos o arquivo <code>/home/cesgaxuser/.bashrc</code> para configurar as variables de contorna necesarias.</p> <pre><code>nano .bashrc\n</code></pre> <p>Metemos esta li\u00f1a ao final:</p> .bashrc<pre><code>export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'\n</code></pre> <p>Esto configura a variable de contorna <code>JAVA_HOME</code>. Non deber\u00eda ser necesario ao estar instalada a m\u00e1quina dende un repositorio automatizado, pero \u00e9 unha boa pr\u00e1ctica para que o resto de scripts non dean fallos ou avisos.</p> <p>Pechamos a sesi\u00f3n (Ctrl+D) e volvemos entrar (ou executamos <code>. ./bashrc</code> ou <code>source .bashrc</code> para recargar as variables de entorno).</p> <p>Copiamos este arquivo ao resto de nodos, empregaremos clustershell para simplificar o proceso:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] --copy .bashrc --dest /home/cesgaxuser/\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#descargando-e-instalando-apache-hadoop-en-todolos-nodos","title":"Descargando e instalando Apache Hadoop en t\u00f3dolos nodos","text":"<p>No nodo master, descargamos Apache Hadoop da web oficial:</p> <pre><code>curl https://dlcdn.apache.org/hadoop/common/hadoop-3.2.4/hadoop-3.2.4.tar.gz \\\n  --output hadoop-3.2.4.tar.gz\n</code></pre> <p>E copi\u00e1molo ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy hadoop-3.2.4.tar.gz --dest /home/cesgaxuser/\n</code></pre> <p>Descomprimimos en t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \n  tar -xzf hadoop-3.2.4.tar.gz\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#configurando-as-variables-de-contorna-especificas-de-apache-hadoop","title":"Configurando as variables de contorna espec\u00edficas de Apache Hadoop","text":"<p>Metemos no <code>.bashrc</code> ao final as seguintes novas variables da contorna:</p> .bashrc<pre><code>export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'\nexport PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin\n</code></pre> <p>E copiamos o arquivo ao resto de nodos para aplicar a mesma configuraci\u00f3n:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy .bashrc --dest /home/cesgaxuser/\n</code></pre> <p>Pechamos a sesi\u00f3n (Ctrl+D) e volvemos entrar (ou executamos <code>. ./bashrc</code> ou <code>source .bashrc</code> para recargar as variables de entorno).</p> <p>Para comprobar se funciona a instalaci\u00f3n b\u00e1sica e as variables de contorna, podemos escribir o comando:</p> <pre><code>hdfs\n</code></pre> <p>E deber\u00eda devolvernos a axuda do comando.</p>"},{"location":"apache-hadoop-0-instalacion/#configurando-apache-hadoop","title":"Configurando Apache Hadoop","text":"<p>Editamos os arquivos de configuraci\u00f3n seguintes e os deixamos as\u00ed:</p> hadoop-3.2.4/etc/hadoop/core-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;fs.default.name&lt;/name&gt;\n            &lt;value&gt;hdfs://hadoop1:9000&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre> hadoop-3.2.4/etc/hadoop/hdfs-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n            &lt;value&gt;/home/cesgaxuser/data/nameNode&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n            &lt;value&gt;/home/cesgaxuser/data/dataNode&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;dfs.replication&lt;/name&gt;\n            &lt;value&gt;1&lt;/value&gt;\n        &lt;/property&gt;\n    &lt;/configuration&gt;\n</code></pre> hadoop-3.2.4/etc/hadoop/mapred-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n            &lt;value&gt;yarn&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n            &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;\n            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n            &lt;name&gt;mapreduce.map.env&lt;/name&gt;\n            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;property&gt;\n            &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;\n            &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n        &lt;/property&gt;\n\n    &lt;!-- L\u00edmite de uso de RAM (non po\u00f1er se temos alomenos 8GB por servidor --&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;yarn.app.mapreduce.am.resource.mb&lt;/name&gt;\n        &lt;value&gt;512&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;\n        &lt;value&gt;256&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;\n        &lt;value&gt;256&lt;/value&gt;\n    &lt;/property&gt;\n\n    &lt;/configuration&gt;\n</code></pre> <p>No seguinte arquivo lembra substituir XXX.XXX.XXX.XXX pola IP do nodo master ou mellor polo host: hadoop1:</p> hadoop-3.2.4/etc/hadoop/yarn-site.xml<pre><code>    &lt;configuration&gt;\n        &lt;property&gt;\n            &lt;name&gt;yarn.acl.enable&lt;/name&gt;\n            &lt;value&gt;0&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n            &lt;value&gt;XXX.XXX.XXX.XXX&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;!-- L\u00edmite de uso de RAM (non po\u00f1er se temos +8GB por servidor --&gt;\n        &lt;property&gt;\n            &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;\n            &lt;value&gt;1536&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;\n            &lt;value&gt;1536&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;\n            &lt;value&gt;128&lt;/value&gt;\n        &lt;/property&gt;\n\n        &lt;property&gt;\n            &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;\n            &lt;value&gt;false&lt;/value&gt;\n        &lt;/property&gt;\n\n    &lt;/configuration&gt;\n</code></pre> <p>E tam\u00e9n metemos os nodos que queiramos que fagan de workers no arquivo:</p> hadoop-3.2.4/etc/hadoop/workers<pre><code>hadoop1\nhadoop2\nhadoop3\nhadoop4\n</code></pre> <p>Agora precisamos crear os directorios que almacenar\u00e1n os datos:</p> <pre><code>mkdir -p /home/cesgaxuser/data/nameNode\nmkdir -p /home/cesgaxuser/data/dataNode\n</code></pre> <p>Con esto ter\u00edamos configurado yarn en hadoop1 (master).</p>"},{"location":"apache-hadoop-0-instalacion/#configuracion-do-resto-de-nodos","title":"Configuraci\u00f3n do resto de nodos","text":"<p>Podemos copiar simplemente a configuraci\u00f3n ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy hadoop-3.2.4/etc/hadoop/workers \\\n  hadoop-3.2.4/etc/hadoop/yarn-site.xml \\\n  hadoop-3.2.4/etc/hadoop/mapred-site.xml \\\n  hadoop-3.2.4/etc/hadoop/hdfs-site.xml \\\n  hadoop-3.2.4/etc/hadoop/core-site.xml \\\n  --dest /home/cesgaxuser/hadoop-3.2.4/etc/hadoop\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#formatear-o-hdfs","title":"Formatear o HDFS:","text":"<p>Dende hadoop1 (o nodo master) executamos:</p> <pre><code>hdfs namenode -format\n</code></pre> <p>E finalmente dende o master iniciamos todo o sistema (esto conecta por SSH aos nodos e executa os comandos necesarios para que se po\u00f1an a traballar):</p> <pre><code>start-dfs.sh\nstart-yarn.sh\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#arrancando-apache-hadoop-ao-inicio-con-cron","title":"Arrancando Apache Hadoop ao inicio con cron","text":"<p>Se queremos lanzar o proceso de Apache Hadoop dende cron (por exemplo para facer uso da opci\u00f3n <code>@reboot</code>) deberemos cambiar por si acaso o arquivo: <code>hadoop-3.2.4/etc/hadoop/hadoop-env.sh</code> e mudar as seguintes variables, para non depender do .bashrc do usuario:</p> hadoop-3.2.4/etc/hadoop/hadoop-env.sh<pre><code>    export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'\n    export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'\n    export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\n    #HADOOP_OPTS=\n</code></pre> <p>Unha vez cambiemos o arquivo, copiar\u00e9molo ao resto de nodos, por coherencia e por manter igual a configuraci\u00f3n en t\u00f3dolos sitios.</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  --copy hadoop-3.2.4/etc/hadoop/hadoop-env.sh \\\n  --dest /home/cesgaxuser/hadoop-3.2.4/etc/hadoop\n</code></pre> <p>Finalmente editaremos o cron do nodo master para indicarlle que arranque Hadoop cando iniciemos a m\u00e1quina:</p> <p>(importante: Se non queres empregar vi, establece a variable <code>EDITOR=nano</code> se o tes instalado)</p> <pre><code>crontab -e\n</code></pre> <p>E metemos no arquivo o seguinte contido:</p> <pre><code>@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-dfs.sh\n@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-yarn.sh\n</code></pre> <p>Por \u00faltimo reiniciamos t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] sudo reboot\n</code></pre>"},{"location":"apache-hadoop-0-instalacion/#comprobando-que-funciona","title":"Comprobando que funciona","text":"<p>Para obter informaci\u00f3n do HDFS, podemos empregar o comando:</p> <pre><code>hdfs dfsadmin -report\n</code></pre> <p>Queda iniciar yarn.</p>"},{"location":"apache-hadoop-0-instalacion/#bibliografia","title":"Bibliograf\u00eda","text":"<p>Podes atopar m\u00e1is informaci\u00f3n:</p> <ul> <li>https://www.linode.com/docs/guides/how-to-install-and-set-up-hadoop-cluster/</li> <li>https://sparkbyexamples.com/spark/spark-setup-on-hadoop-yarn/</li> <li>https://www.linode.com/docs/guides/install-configure-run-spark-on-top-of-hadoop-yarn-cluster/</li> <li>https://www.tutorialspoint.com/es/hadoop/hadoop_multi_node_cluster.htm</li> <li>https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</li> </ul>"},{"location":"apache-hadoop-0-instalacion/#copyright","title":"Copyright","text":"<p>\u00a9 2023 - Jose S\u00e1nchez</p> <p>Se atopas erros, agradecerei que me env\u00edes un email/mensaxe co aviso ou as correcci\u00f3ns.</p>"},{"location":"apache-hadoop-1-comandos/","title":"\ud83d\udd32 Apache Hadoop - Comandos","text":"<p>Apache Hadoop, \u00e9 un framework que permite o procesamento distribuido de grande volume de datos sobre cl\u00fasteres de computadoras empregando modelos sinxelos de programaci\u00f3n.</p> <p>O HDFS ou Hadoop Distributed File System \u00e9 un sistema de arquivos distribu\u00eddo empregado por Apache Hadoop que espalla os datos polos distintos discos dos servidores que forman o cl\u00faster de Hadoop.</p> <ul> <li> <p>Os arquivos grandes div\u00eddense en bloques (blocks) por defecto de 128 MiB.</p> </li> <li> <p>De cada bloque hai varias copias, o n\u00famero exacto establ\u00e9ceo o factor de replicaci\u00f3n (replication factor) por defecto 3.</p> </li> </ul>"},{"location":"apache-hadoop-1-comandos/#onde-estan-os-meus-datos","title":"Onde est\u00e1n os meus datos?","text":"<p>A primeira pregunta que debemos facernos \u00e9: Onde est\u00e1n os meus datos?</p> <ul> <li>No $HOME do teu usuario -&gt; /home/subdirs-opcionais/usuario.</li> <li>No HOME do servidor de HADOOP -&gt; /user/usuario.</li> </ul> <p>A variable $HOME normalmente fai referencia ao teu cartafol persoal. Este adoita estar en /home/usuario ou en /home/algo/mais/usuario. Estes son os arquivos aos que accedes normalmente.</p> <p>O HOME de Hadoop normalmente estar\u00e1 en: /user/usuario e para acceder a \u00e9l debes empregar o comando hdfs ou ben API ou programas que se relacionen con Hadoop. A URL de acceso ao arquivo ten o formato: hdfs://nameservice1/user/usuario/arquivo.</p>"},{"location":"apache-hadoop-1-comandos/#interactuando-co-sistema-de-arquivos","title":"Interactuando co sistema de arquivos","text":"<p>O programa hdfs danos unha interfaz e operaci\u00f3ns \u00fatiles para acceder ao HDFS de Hadoop. Os comandos seguen unha sintaxe de tipo:</p> <pre><code>hdfs dfs -COMANDO # (1)!\n</code></pre> <ol> <li>dfs: Indica que a operaci\u00f3n \u00e9 de arquivos sobre o sistema de arquivos.</li> </ol> <p>Os comandos habituais son:</p>"},{"location":"apache-hadoop-1-comandos/#ver-arquivos-e-directorios","title":"Ver arquivos e directorios","text":"<p>Ver arquivos no noso HOME de HDFS. Imos ver adem\u00e1is as distintas rutas: relativas, absolutas e completas.</p> <pre><code>hdfs dfs -ls\n</code></pre> <p>Ver arquivos que hai en \"directorio\" que \u00e9 un directorio que est\u00e1 no noso HOME de HDFS:</p> <pre><code>hdfs dfs -ls directorio\n</code></pre> <p>O mesmo que o anterior pero empregando unha ruta absoluta:</p> <pre><code>hdfs dfs -ls /user/usuario/directorio\n</code></pre> <p>O mesmo que o anterior pero empregando a ruta absoluta e completa do HDFS:</p> <pre><code>hdfs dfs -ls hdfs://nameservice1/user/usuario/directorio\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#transferindo-datos-entre-o-hdfs-e-o-almacenamento-local","title":"Transferindo datos entre o HDFS e o almacenamento local","text":"<p>\ud83d\udd3c Subir/Enviar o ARQUIVO_LOCAL que est\u00e1 no noso $HOME (\"o noso disco duro\") a un directorio de HDFS chamado \"DIRECTORIO_HDFS\":</p> <pre><code>hdfs dfs -put ARQUIVO_LOCAL DIRECTORIO_HDFS\n</code></pre> <p>\ud83d\udd3d Baixar/Descargar/Recibir do HDFS (\"cl\u00faster de Hadoop\") o arquivo ao noso almacenamento local (\"disco duro\"):</p> <pre><code>hdfs dfs -get arquivo-do-hdfs.txt\n</code></pre> <p>Amosar un arquivo do HDFS por consola en modo texto. Adem\u00e1is admite o formato ZIP e TextRecordInputStream:</p> <pre><code>hdfs dfs -text arquivo.zip\nhdfs dfs -text arquivo.txt\n</code></pre> <p>Amosar un arquivo do HDFS por consola, danos igual o formato no que estea:</p> <pre><code>hdfs dfs -cat arquivo-calquera.xyz\n</code></pre> <p>Ver o inicio do arquivo (cabeceira) empregando pipes:</p> <pre><code>hdfs dfs -cat arquivo-moi-grande.csv|head\n</code></pre> <p>Amosar a cola (o final) do arquivo. \u00datil para comprobar se est\u00e1 ben recibido e o formato.</p> <pre><code>hdfs dfs -tail arquivo-longo.csv\n</code></pre> <p>Copiar un arquivo dentro do HDFS (de HDFS a HDFS)</p> <pre><code>hdfs dfs -cp ARQUIVO_ORIXE ARQUIVO_DESTINO\n</code></pre> <p>Mover un arquivo dentro do HDFS (de HDFS a HDFS)</p> <p><pre><code>hdfs dfs -mv ARQUIVO_ORIXE ARQUIVO_DESTINO\n</code></pre> Borrar un arquivo do HDFS</p> <pre><code>hdfs dfs -rm arquivo.txt\n</code></pre> <p>Resultado:</p> <pre><code>25/02/08 16:39:19 INFO fs.TrashPolicyDefault: Moved: 'hdfs://nameservice1/user/usuario/arquivo.txt' to trash at: hdfs://nameservice1/user/usuario/.Trash/Current/user/usuario/arquivo.txt\n</code></pre> <p>Borrar un arquivo do HDFS evitando a papeleira (skipTrash):</p> <pre><code>hdfs dfs -rm -skipTrash arquivo.txt\n</code></pre> <p>Resultado: <pre><code>Deleted arquivo.txt\n</code></pre></p>"},{"location":"apache-hadoop-1-comandos/#mudando-de-usuario-grupo-e-permisos","title":"Mudando de usuario, grupo e permisos","text":"<p>Seguindo a m\u00e1scara de permisos UGO podemos mudar os permisos dun arquivo ou dun directorio de forma recursiva (-R):</p> <pre><code>hdfs dfs -chmod 765 ficheiro\n</code></pre> <pre><code>hdfs dfs -chmod -R 755 meudir\n</code></pre> <p>Tam\u00e9n podemos mudar o propietario e o grupo do ficheiro (tam\u00e9n admite -R para directorios):</p> <pre><code>hdfs dfs -chown hadoop:hadoop ficheiro123.txt\n</code></pre> <p>Ou mudar solo o grupo:</p> <pre><code>hdfs dfs -chgrp hadoop ficheiro321.txt\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#e-cuestion-de-espazo","title":"\u00c9 cuesti\u00f3n de espazo","text":"<p>Medir o espazo consumido non sempre \u00e9 directo. Se preguntamos canto oucpa un arquivo:</p> <pre><code>dfs dfs -du -h -s 100MB.zip\n</code></pre> <p>Veremos dous tama\u00f1os: Tama\u00f1o do arquivo e o espazo en disco consumido.</p> <pre><code>100 M  300 M  100MB.zip\n</code></pre> <p>O tama\u00f1o en disco consumido p\u00f3dese calcular como o resultado de multiplicar o tama\u00f1o do arquivo polo factor de replicaci\u00f3n. Pode haber diferencias debidas ao tama\u00f1o de bloque, sobre todo con tama\u00f1os de bloque grandes.</p> <p>Consultar o espazo libre dispo\u00f1ible:</p> <pre><code>hdfs dfs -df -h\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#outros-comandos-utiles-probar","title":"Outros comandos \u00fatiles (probar):","text":"<p>Engadir (concatenar) o contido de <code>ventas-diarias-hoxe-LOCAL.txt</code> que est\u00e1 no almacenamento local (disco duro local ou $HOME) ao arquivo do HDFS <code>ventas-HDFS.txt</code></p> <pre><code>hdfs dfs -appendToFile ventas-diarias-hoxe-LOCAL.txt ventas-HDFS.txt\n</code></pre> <p>Descargar a local ao arquivo <code>ventas-local.txt</code> o resultado da concatenaci\u00f3n dos arquivos do HDFS: <code>ventas-HDFS-part1.txt</code> e <code>ventas-HDFS-part2.txt</code>.</p> <pre><code>hdfs dfs -getmerge -nl ventas-HDFS-part1.txt ventas-HDFS-part2.txt ventas-local.txt\n</code></pre> <p>Xerar un checksum dos datos para comprobar se est\u00e1n ben (empr\u00e9gase MD5, non est\u00e1 pensado para modificaci\u00f3ns maliciosas dos datos, sen\u00f3n para cambios accidentais)</p> <pre><code>hdfs dfs -checksum ventas-HDFS.txt\n</code></pre> <p>Mudar o factor de replicaci\u00f3n dun arquivo ou dun directorio:</p> <pre><code>hadoop fs -setrep -w 3 100MB.zip\nhadoop fs -setrep -w 3 -R /user/usuario/directorio\n</code></pre> <p>C\u00f3mo se comproba que mudou. D\u00faas maneiras:</p> <p>Con ls, o n\u00famero antes de usuario \u00e9 o factor de replicaci\u00f3n:</p> <pre><code>-rw-r--r--   **4** usuario grupo  104857600 2025-01-29 22:00 100MB.zip\n</code></pre> <p>Con du mirando que sube o espacio ocupado en disco:</p> <pre><code>hdfs dfs -du -h -s 100MB.zip\n</code></pre> <p>Vemos que:</p> <pre><code>100 M  400 M  100MB.zip\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#arquivos-de-configuracion","title":"Arquivos de configuraci\u00f3n","text":""},{"location":"apache-hadoop-1-comandos/#hdfs-sitexml-tamano-de-bloque","title":"hdfs-site.xml. Tama\u00f1o de bloque","text":"<p>Cada arquivo div\u00eddese en bloques (m\u00ednimo 1 bloque por arquivo) de por defecto 128 MiB.</p> <pre><code>&lt;property&gt;\n&lt;name&gt;dfs.block.size&lt;/name&gt;\n&lt;value&gt;134217728&lt;/value&gt;\n&lt;property&gt;\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#hdfs-sitexml-factor-de-replicacion","title":"hdfs-site.xml. Factor de replicaci\u00f3n","text":"<p>O n\u00famero de copias de cada bloque, por defecto 3.</p> <pre><code>&lt;property&gt;\n&lt;name&gt;dfs.replication&lt;/name&gt;\n&lt;value&gt;3&lt;/value&gt;\n&lt;/property&gt;\n</code></pre>"},{"location":"apache-hadoop-1-comandos/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://bigdata.cesga.es/tutorials/hdfs.html</li> </ul> <p>Se empregas os recursos do CESGA, lembra que dende a casa debes conectarte \u00e1 VPN antes de conectarte por SSH ao servidor hadoop.cesga.es.</p>"},{"location":"apache-nifi-0-instalacion/","title":"\ud83d\udca7 Apache Nifi - Instalaci\u00f3n","text":"<p>Web Oficial: https://nifi.apache.org/ </p> <p>\u00c9 un software adicado a automatizar o fluxo de datos entre sistemas.</p> <p>Empregaremos o software integr\u00e1ndoo co Apache Hadoop do CESGA, de xeito que poidamos ler e escribir do HDFS.</p>"},{"location":"apache-nifi-0-instalacion/#instalacion","title":"Instalaci\u00f3n","text":"<p>Instalaremos sobre o noso usuario no servidor: <code>hadoop.cesga.es</code>, \u00e9 conveniente que conectemos coa VPN para evitar problemas cos portos.</p> <p>Cando conectamos con alg\u00fan servizo do CESGA por SSH, en realidade estamos nun nodo de login, dende o que accedemos aos servizos. Esto implica que podemos chegar a ter unha IP interna diferente incluso se abrimos d\u00faas sesi\u00f3ns ao \u00abmesmo\u00bb host.</p> <p>Ten en conta que Nifi abrir\u00e1 un porto e expor\u00e1 o seu servizo https \u00e1 rede que lle indiquemos. Precisar\u00e1s co\u00f1ecer a IP cando esteas a cambiar os arquivos de configuraci\u00f3n.</p>"},{"location":"apache-nifi-0-instalacion/#aviso-previo","title":"Aviso previo","text":"<p>AVISO: A versi\u00f3n 23 de amazon-corretto \u00e9 necesaria para executar a \u00faltima versi\u00f3n 2 de Apache Nifi.</p> <p>Se s\u00f3 queres probar Nifi, emprega a imaxe \"oficial\" non-oficial https://hub.docker.com/r/apache/nifi:</p> <pre><code>docker run --name nifi \\\n  -p 8443:8443 \\\n  -d \\\n  -e SINGLE_USER_CREDENTIALS_USERNAME=admin \\\n  -e SINGLE_USER_CREDENTIALS_PASSWORD=EsteEunContrasinalMoiLongo1234567890 \\\n  apache/nifi:latest\n</code></pre>"},{"location":"apache-nifi-0-instalacion/#descarga-verificacion-e-outras-operacions","title":"Descarga, verificaci\u00f3n e outras operaci\u00f3ns","text":"<p>Precisamos unha versi\u00f3n de Java m\u00e1is recente, imos empregar a versi\u00f3n 11 de Amazon Corretto (A versi\u00f3n 21 de Corretto en decembro de 2023, est\u00e1 a dar problemas coa execuci\u00f3n de Nifi na contorna do CESGA).</p> <p>Descargamos Amazon Corretto v11 e descomprimimos:</p> <pre><code>wget wget https://corretto.aws/downloads/latest/amazon-corretto-11-x64-linux-jdk.tar.gz\ntar -xzf amazon-corretto-11-x64-linux-jdk.tar.gz\n</code></pre> <p>Creamos un directorio local bin no que po\u00f1eremos t\u00f3dalas ferramentas necesarias:</p> <pre><code>mkdir bin\n</code></pre> <p>Descargamos Apache Nifi 1.24.0 e o seu arquivo de firma (asc):</p> <pre><code>wget https://dlcdn.apache.org/nifi/1.24.0/nifi-1.24.0-bin.zip --no-check-certificate\nwget https://dlcdn.apache.org/nifi/1.24.0/nifi-1.24.0-bin.zip.asc --no-check-certificate\n</code></pre> <p>Comprobar a firma (e por tanto a integridade do arquivo e que non foi alterado) \u00e9 unha boa pr\u00e1ctica, as\u00ed que primeiro baixamos a chave SSH coa que foi firmado o arquivo:</p> <pre><code>gpg --keyserver pgpkeys.mit.edu --recv-key 0C07C6D5\n</code></pre> <p>E verificamos que coincide:</p> <pre><code>gpg --verify nifi-1.24.0-bin.zip.asc nifi-1.24.0-bin.zip\n</code></pre> <p>Se todo coincide dir\u00e1 \"Good signature from ...\". En caso de non coincidir a sinatura, debemos comprobar de novo os arquivos, volvelos baixar, revisar o sitio oficial e buscar outra descarga, etc.</p> <p>Descomprimimos Apache Nifi:</p> <pre><code>unzip nifi-1.24.0-bin.zip\n</code></pre> <p>Agora imos copiar tanto Amazon Corretto como Apache Nifi dentro do directorio bin que temos creado</p> <pre><code>mv amazon-corretto-11.0.21.9.1-linux-x64 nifi-1.24.0 bin/\n</code></pre> <p>Finalmente facemos un pouco de limpieza:</p> <pre><code>rm nifi-1.24.0-bin.zip nifi-1.24.0-bin.zip.asc\n</code></pre>"},{"location":"apache-nifi-0-instalacion/#configuracion","title":"Configuraci\u00f3n","text":"<p>Debemos configurar varias partes para que funcione:</p> <ul> <li>Variables do contorno: PATH e JAVA_HOME</li> <li>Apache Nifi (env e arquivo de configuraci\u00f3n)</li> </ul>"},{"location":"apache-nifi-0-instalacion/#configuracion-do-path","title":"Configuraci\u00f3n do PATH","text":"<p>Imos configurar as variables de contorno: <code>PATH</code> e <code>JAVA_HOME</code>. A\u00ednda que non \u00e9 absolutamente necesario (posto que imos sobreescribir estes cambios tam\u00e9n en Nifi) si que \u00e9 conveniente por si empregamos outros programas que queremos que fagan uso de esta versi\u00f3n de OpenJDK.</p> <p>Editamos o arquivo: $HOME/.bash_profile e engadimos ao final as li\u00f1as:</p> $HOME/.bash_profile<pre><code>export PATH=$HOME/bin:$HOME/bin/amazon-corretto-11.0.21.9.1-linux-x64/bin:$PATH\nexport JAVA_HOME=$HOME/bin/amazon-corretto-11.0.21.9.1-linux-x64/\n</code></pre> <p>Agora temos d\u00faas opci\u00f3ns: Ou sair e volver a entrar (logout e login) ou empregar o comando . ou source co arquivo .bash_profile:</p> <pre><code>source ~/.bash_profile\n</code></pre> <p>ou</p> <pre><code>. ~/.bash_profile\n</code></pre>"},{"location":"apache-nifi-0-instalacion/#configuracion-de-apache-nifi","title":"Configuraci\u00f3n de Apache Nifi","text":"<p>Precisamos mudar dous arquivos:</p> <ul> <li>bin/nifi-env.sh</li> <li>conf/nifi.properties</li> </ul> <p>Editamos primeiro <code>nifi-env.sh</code>:</p> <pre><code>nano $HOME/bin/nifi-1.24.0/bin/nifi-env.sh\n</code></pre> <p>Teremos que indicarlle que m\u00e1quina de Java coller (descomentamos se fai falta o JAVA_HOME e po\u00f1\u00e9molo como segue):</p> <pre><code>export JAVA_HOME=\"$HOME/bin/amazon-corretto-11.0.21.9.1-linux-x64/\"\n</code></pre> <p>Agora debemos configurar no arquivo <code>nifi.properties</code> o porto https, a IP na que vai a escoitar e o interfaz por defecto. Por defecto Apache Nifi abre un porto de xesti\u00f3n aleatorio, m\u00e1is non abre o porto para a interfaz web.</p> <p>A instalaci\u00f3n \u00e9 dependente da IP do nodo de login, polo que debemos consultala. A que se pon aqu\u00ed dase como exemplo e debes mirar a t\u00faa.</p> <p>Miramos a ip co comando <code>ifconfig</code>, en concreto inter\u00e9sanos a IPv4:</p> <pre><code>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 9000\n        inet 10.10.10.101  netmask 255.0.0.0  broadcast 0.0.0.0\n        inet6 fe80::0001:0203:0405:0001  prefixlen 64  scopeid 0x20&lt;link&gt;\n        ether 00:01:02:03:04:05  txqueuelen 1000  (Ethernet)\n        RX packets 324227052  bytes 234877693356 (218.7 GiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 242422788  bytes 830555348369 (773.5 GiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n</code></pre> <p>Debemos escoller un porto non ocupado por ningu\u00e9n. Recomendaci\u00f3n: Colle un porto algo, por exemplo 648XX e substit\u00fae XX polo teu n\u00famero de usuario.</p> <p>Anota nalg\u00fan sitio a IP do comando anterior o porto que acabas de escoller. Vou empregar de exemplo a IP: 10.10.10.101 e o porto 64801. Ollo! emprega os datos correctos ou non che funcionar\u00e1.</p> <p>Editamos o arquivo <code>nifi.properties</code>:</p> <pre><code>nano $HOME/bin/nifi-1.24.0/conf/nifi.properties\n</code></pre> <p>E cubrimos cos datos anteriores as seguintes variables no arquivo:</p> conf/nifi.properties<pre><code>nifi.web.https.host=10.10.10.101\nnifi.web.https.port=64801\n</code></pre>"},{"location":"apache-nifi-0-instalacion/#inicio-de-nifi","title":"Inicio de Nifi","text":"<p>Dentro de nifi hai un directorio bin que cont\u00e9n os scripts de lanzamento. En cocnreto inter\u00e9sanos:</p> <ul> <li>bin/nifi.sh</li> </ul> <p>Entramos dentro do directorio:</p> <pre><code>cd $HOME/bin/nifi-1.24.0/bin\n</code></pre> <p>E executamos:</p> <pre><code>./nifi.sh start\n</code></pre> <p>Agora debemos consultar o usuario e clave por defecto en:</p> <ul> <li>logs/nifi-app.log</li> </ul> <p>Buscaremos o texto \"Generated\":</p> <pre><code>cat $HOME/bin/nifi-1.24.0/logs/nifi-app.log| grep Generated\n</code></pre> <p>Con eses datos xa podemos entrar nun navegador web na IP do nodo do paso anterior (no meu exemplo: https://10.10.10.101:64801). Por favor non esquezas o https.</p> <p>Cando remates, antes de desconectarte do servidor de SSH, non esquezas executar un:</p> <pre><code>./nifi.sh stop\n</code></pre>"},{"location":"apache-spark-0-instalacion/","title":"\u269d Apache Spark - Instalaci\u00f3n","text":"<p>Faremos unha instalaci\u00f3n de Apache Spark en 4 m\u00e1quinas con ClusterShell, un programa que permite enviar \u00e1 vez comandos a varias m\u00e1quinas.</p> <p>A presente instalaci\u00f3n contempla 1 master e 3 nodos (ou 4 nodos de actuar o m\u00e1ster tam\u00e9n como worker). Se tes un n\u00famero diferente de m\u00e1quinas, deber\u00e1s mudar nos comandos a parte do [1-4] ou [2-4] adapt\u00e1ndoo \u00e1s t\u00faas necesidades.</p> <p>Consideraremos os seguintes nomes de m\u00e1quinas:</p> /etc/hosts<pre><code>10.X.Y.101 hadoop1 hadoop1.local master1.local\n10.X.Y.102 hadoop2 hadoop2.local\n10.X.Y.103 hadoop3 hadoop3.local\n10.X.Y.104 hadoop4 hadoop4.local\n</code></pre> <p>Imos empregar Rocky 8.5 v2, sen embargo, en caso de empregar Debian, podemos empregar <code>apt</code> en lugar de <code>dnf</code>. Consideramos tam\u00e9n o contorno do cesga con usuario por defecto: <code>cesgaxuser</code> e <code>$HOME</code> en <code>/home/cesgaxuser/</code>.</p> <p>Se est\u00e1s nun contorno Cloud no que debes destruir as instancias por tema de custes e p\u00f3dense asignar distintos enderezos IP, lembra sempre facer:</p> <ol> <li> <p>Editar o arquivo <code>/etc/hosts</code> cos nomes que correspondan \u00e1s novas IP.</p> </li> <li> <p>Borrar o known_hosts:     <pre><code>rm ~/.ssh/known_hosts\n</code></pre></p> </li> <li> <p>Rexenerar o <code>/etc/hosts</code>:</p> <pre><code>for servidor in $(cat /etc/hosts|grep hadoop); do \\\n  ssh-keyscan -H $servidor; done &gt;&gt; /home/cesgaxuser/.ssh/known_hosts\n</code></pre> </li> <li> <p>Copialo ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  --copy $HOME/.ssh/known_hosts \\\n  --dest $HOME/.ssh/known_hosts\n</code></pre> </li> <li> <p>Copia o <code>/etc/hosts</code> ao resto de nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] --copy /etc/hosts --dest /tmp\nclush -l cesgaxuser -bw hadoop[2-4] sudo cp /tmp/hosts /etc/hosts\n</code></pre> </li> </ol>"},{"location":"apache-spark-0-instalacion/#instalacion-de-clustershell","title":"Instalaci\u00f3n de Clustershell","text":"<ol> <li> <p>Activar repo:</p> <pre><code>sudo yum --enablerepo=extras install epel-release\n</code></pre> </li> <li> <p>Instalaci\u00f3n de paquete:</p> <pre><code>sudo yum install clustershell\n</code></pre> </li> </ol>"},{"location":"apache-spark-0-instalacion/#descargar-a-maquina-de-java-amazon-corretto","title":"Descargar a m\u00e1quina de Java (Amazon Corretto)","text":"<p>Configuramos o repo de Amazon Corretto e instalamos o paquete de Java en t\u00f3dolos nodos:</p> <ol> <li> <p>Importamos a chave do repositorio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo rpm --import https://yum.corretto.aws/corretto.key\n</code></pre> </li> <li> <p>Baixamos o repositorio e o configuramos nos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo curl -L -o /etc/yum.repos.d/corretto.repo \\\n  https://yum.corretto.aws/corretto.repo\n</code></pre> </li> <li> <p>Instalamos o paquete de Java deste novo repostorio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo dnf install -y java-11-amazon-corretto-devel\n</code></pre> </li> <li> <p>Configuramos as variables do contorno: <code>nano .bashrc</code> as li\u00f1as:</p> .bashrc<pre><code>export JAVA_HOME='/usr/lib/jvm/java-11-amazon-corretto/'\nexport EDITOR=nano\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre> <ul> <li> <p>Se non temos o editor nano, podemos empregar vi. Lembra para gardar e sair en nano: Ctrl+O [ENTER], Ctrl + X. En vi: [ESC] :wq! [ENTER]</p> </li> <li> <p>Logo de gardar, lembra recargar as variables de contorno!</p> </li> </ul> <pre><code>source ~/.bashrc\n</code></pre> </li> <li> <p>Copia ao resto de nodos esta configuraci\u00f3n:     <pre><code>clush -l cesgaxuser -bw hadoop[1-4] --copy $HOME/.bashrc \\\n  --dest $HOME/.bashrc\n</code></pre></p> </li> </ol>"},{"location":"apache-spark-0-instalacion/#descarga-de-apache-spark","title":"Descarga de Apache Spark","text":"<p>Se non che funciona a descarga, pode ser que te\u00f1as que averiguar a nova ruta por existir unha nova versi\u00f3n. Podes ir ao nivel superior da p\u00e1xina e buscar a nova versi\u00f3n: https://dlcdn.apache.org/spark/.</p> <p>Segundo as t\u00faas necesidades podes ter que escoller entre a versi\u00f3n con ou sen Apache Hadoop.</p> <p>Outra opci\u00f3n se contas con pouco ancho de banda \u00e9 baixar unha vez o arquivo dende o master e facer un --copy  a --dest con Clustershell.</p> <ol> <li> <p>Baixamos Apache Spark (actualizado a 20 de abril de 2024):</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo curl -L -O https://dlcdn.apache.org/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz \\\n  -o /home/cesgaxuser/spark-bin-hadoop3.tar.gz\n</code></pre> <ul> <li>G\u00e1rdase no arquivo <code>spark-bin-hadoop3.tar.gz</code> para que futuras versi\u00f3ns destes apuntes non te\u00f1an que ser mudados t\u00f3dolos comandos por mor da versi\u00f3n.</li> </ul> </li> <li> <p>Descomprimimos simult\u00e1neamente en t\u00f3dolos nodos:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo tar xzvf spark-bin-hadoop3.tgz\n</code></pre> </li> <li> <p>Configuramos as variables de contorno por comodidade <code>nano .bashrc</code>:</p> .bashrc<pre><code>export SPARK_HOME=$HOME/spark-bin-hadoop3\nexport PATH=$PATH:$SPARK_HOME/sbin/:$SPARK_HOME/bin/\n</code></pre> <ul> <li>Logo de gardar, lembra recargar as variables do contorno!</li> </ul> <pre><code>source ~/.bashrc\n</code></pre> </li> <li> <p>Copia ao resto de nodos esta configuraci\u00f3n:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] --copy $HOME/.bashrc \\\n  --dest $HOME/.bashrc\n</code></pre> </li> <li> <p>Copiamos o template de configuraci\u00f3n:</p> <pre><code>sudo cp $SPARK_HOME/conf/spark-defaults.conf.template \\\n  $SPARK_HOME/conf/spark-defaults.conf\n</code></pre> </li> <li> <p>Editamos o novo arquivo de configuraci\u00f3n:</p> <pre><code>sudo nano $SPARK_HOME/conf/spark-defaults.conf\n</code></pre> <ul> <li>Dentro do arquivo, mudamos a configuraci\u00f3n de Apache Spark para que empregue YARN (Yet Another Resource Negociator):</li> </ul> $SPARK_HOME/conf/spark-defaults.conf<pre><code>spark.master yarn\n</code></pre> </li> <li> <p>No nodo master executamos o script <code>start-master.sh</code> (estamos a executar todo como root):</p> <pre><code>sudo start-master.sh\n</code></pre> </li> <li> <p>Nos nodos slaves executamos o <code>start-worker.sh</code>:</p> <pre><code>clush -l cesgaxuser -bw hadoop[2-4] \\\n  sudo $SPARK_HOME/sbin/start-worker.sh spark://hadoop1:7077\n</code></pre> </li> </ol>"},{"location":"apache-spark-0-instalacion/#instalacion-de-pyspark","title":"Instalaci\u00f3n de PySpark","text":"<ol> <li> <p>Instalamos Python 3.9:</p> <p><pre><code>clush -l cesgaxuser -bw hadoop[1-4] \\\n  sudo dnf install -y python39\n</code></pre> - Lembra que a nivel sistema podes seleccionar o python por defecto que queres cos comandos:</p> <pre><code>sudo /usr/sbin/alternatives --config python\nsudo /usr/sbin/alternatives --config python3\n</code></pre> <ul> <li>\u26a0\ufe0f Considera que quiz\u00e1s a mellor opci\u00f3n sexa instalar miniconda e dende ah\u00ed ter un contorno estable que poidas importar a t\u00f3dolos nodos cunha versi\u00f3n concreta de funcional de: Python, ipython, pyspark, jupyterlab, ipykernel, nbclassic, nbconvert, py4j, pandas, numpy, pyarrow, fastparquet... </li> </ul> </li> <li> <p>Lanzar pyspark:</p> <pre><code>pyspark --master spark://hadoop1:7077\n</code></pre> </li> <li> <p>Configurar para que o worker arranque no inicio do servidor:</p> <pre><code>sudo crontab -e\n</code></pre> <ul> <li>De iniciarseche vi, preme a tecla INS para habilitar inserci\u00f3n de texto neste editor. Lembra que para gardar debes premer a tecla ESC e despois <code>:wq!</code> e logo premer ENTER.</li> </ul> <pre><code>@reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-worker.sh spark://hadoop1:7077\n</code></pre> </li> <li> <p>E no master o mesmo, pero con comando master:</p> <pre><code>sudo crontab -e\n</code></pre> <ul> <li>E meter no arquivo:</li> </ul> <pre><code>@reboot /home/cesgaxuser/spark-bin-hadoop3/sbin/start-master.sh\n@reboot /home/cesgaxuser/hadoop-3.2.4/sbin/start-yarn.sh\n</code></pre> </li> <li> <p>Lembra darlle un reboot a t\u00f3dalas m\u00e1quinas para ver que todo se est\u00e1 a executar ben ao inicio:</p> <pre><code>clush -l cesgaxuser -bw hadoop[1-4] reboot\n</code></pre> </li> </ol> <p></p>"},{"location":"apache-spark-0-instalacion/#configurando-spark-para-que-funcione-con-hadoop","title":"Configurando Spark para que funcione con Hadoop","text":"<p>O arquivo <code>.bashrc</code> tam\u00e9n debe ter a config de Apache Hadoop do exercicio anterior: En <code>.bashrc</code> aseg\u00farate que tes:</p> .bashrc<pre><code>export HADOOP_HOME='/home/cesgaxuser/hadoop-3.2.4'\nexport HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\nexport PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin\nexport LD_LIBRARY_PATH=${HADOOP_HOME}/lib/native:$LD_LIBRARY_PATH\n</code></pre> <p>E lembra ter todas as variables definidas nos arquivos -env.sh correspondentes.</p>"},{"location":"apache-spark-0-instalacion/#lanzando-traballos-con-spark-submit","title":"Lanzando traballos con spark-submit","text":"<p>Executamos dende o master con spark-submit un traballo, que deber\u00eda enviarse ao hadoop.</p> <pre><code>spark-submit --deploy-mode client \\\n  --class org.apache.spark.examples.SparkPi \\\n  $SPARK_HOME/examples/jars/spark-examples_2.14-3.4.2.jar 2\n</code></pre> <p>Miramos nos logs de hadoop que se executara.</p>"},{"location":"apache-spark-0-instalacion/#lendo-arquivos-do-hdfs-dende-jupyterlab","title":"Lendo arquivos do HDFS dende jupyterlab","text":"<p>Para ler arquivos do HDFS dende yarn / jupyterlab / pyspark hai que:</p> <ol> <li> <p>Crear o directorio de usuario no HDFS:</p> <pre><code>hdfs dfs -mkdir /user/\nhdfs dfs -mkdir /user/cesgaxuser\n</code></pre> </li> <li> <p>Po\u00f1er a ruta completa no c\u00f3digo:</p> ler_csv_dende_spark.py<pre><code>df = spark.read.csv(\"hdfs://hadoop1:9000/user/cesgaxuser/arquivo.csv\")\n</code></pre> <ul> <li>Ollo! se probas dende pyspark, mira que acceda ao cluster e non cree unha instancia nova propia.</li> </ul> </li> </ol>"},{"location":"apache-spark-0-instalacion/#lanzando-exemplos","title":"Lanzando exemplos","text":"<p>Se tes Apache Hadoop instalado do paso anterior, lembra que tam\u00e9n podes probar os exemplos con:</p> <pre><code>yarn jar hadoop-3.2.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.4.jar \\\n  wordcount \"books/*\" output\n</code></pre>"},{"location":"apache-spark-0-instalacion/#comandos-e-outros","title":"Comandos e outros","text":"<p>Haber\u00e1 que documentar:</p> <ul> <li> <p>hdfs dfs -put ARQUIVO</p> </li> <li> <p>hdfs dfs -ls</p> </li> <li> <p>yarn top</p> </li> <li> <p>yarn node -list</p> </li> <li> <p>yarn application (-list/-kill)</p> </li> <li> <p>jps -&gt; De java (non Spark ou Hadoop)</p> </li> </ul>"},{"location":"apache-sqoop-0-resumo/","title":"\ud83c\uddf8 Apache sqoop","text":"<p>Apache sqoop \u00e9 un proxecto xa obsoleto, a \u00faltima publicaci\u00f3n data do 18 de xaneiro de 2019. En 2021, foi movido ao \"\u00e1tico\" de Apache, o lugar onde se atopan os proxectos retirados ou que finalizaron o seu ciclo de vida ou non te\u00f1en suficientes desenvolvedores activos involucrados.</p> <p>Este proxecto perm\u00edtenos mover datos entre o HDFS (Hadoop Distributed File System) e un RDBMS (Relational Database Management System).</p> <p>Hai d\u00faas operaci\u00f3ns b\u00e1sicas que nos interesan:</p> <ul> <li>import: Importar datos ao HDFS dende un RDBMS (direcci\u00f3n: do RDBMS ao HDFS).</li> <li>export: Exportar datos do HDFS ao RDBMS (direcci\u00f3n: do HDFS ao RDBMS).</li> </ul>"},{"location":"apache-sqoop-0-resumo/#instalacion","title":"Instalaci\u00f3n","text":"<ol> <li>Precisamos Java 1.8 ou Amazon Corretto.</li> </ol> <p>wget https://corretto.aws/downloads/latest/amazon-corretto-21-x64-linux-jdk.deb   sudo dpkg -i amazon-corretto-21-x64-linux-jdk.deb</p> <ol> <li>Baixamos a versi\u00f3n 1.4.7:</li> </ol> <p>wget https://archive.apache.org/dist/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</p> <ol> <li>Descomprimimos:</li> </ol> <p>tar -xzf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</p> <p>3.</p>"},{"location":"apache-sqoop-0-resumo/#manexo","title":"Manexo","text":"<p>Imos ver o funcionamento con estes dous drivers:</p> <ul> <li>MySQL/MariaDB</li> <li>PostgreSQL</li> </ul>"},{"location":"apache-sqoop-0-resumo/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://sqoop.apache.org/</li> <li>https://attic.apache.org/projects/sqoop.html</li> <li>https://bigdata.cesga.es/tutorials/sqoop.html#/</li> </ul>"},{"location":"conda-0-config-basica/","title":"\ud83d\udc0d Conda: Contorno BigData","text":"<p>Este contorno permite facer os exercicios da clase. Imos instalar algunhas librar\u00edas b\u00e1sicas, o jupyterlab (para os notebook) e configurar o Visual Studio Code (vscode/code) por comodidade.</p> <p>Pasos:</p> <ol> <li>Baixa miniconda https://docs.conda.io/projects/miniconda/en/latest/ e inst\u00e1lao no teu equipo.</li> <li>(Opcional) Mete miniconda no PATH de Microsoft Windows. O instalador di que pode dar problemas, pero \u00e9 s\u00f3 se temos configuraci\u00f3ns previas que empreguen Python e nalg\u00fans casos moi especiais (mira os pasos abaixo).</li> <li> <p>Actualiza t\u00f3dolos paquetes do contorno base para que non dea problemas:     <pre><code>conda update --all\n</code></pre></p> </li> <li> <p>Borra o contorno bigdata anterior:     <pre><code>conda env remove -n bigdata\n</code></pre></p> </li> <li> <p>Crea o novo contorno bigdata e act\u00edvao:     <pre><code>conda create -n bigdata python=3.11\nconda activate bigdata\n</code></pre></p> </li> <li> <p>Instala os paquetes m\u00ednimos que imos precisar     <pre><code>conda install -c conda-forge jupyterlab ipykernel ipython \\\n   nbconvert pandas numpy pyarrow fastparquet wordcloud nltk \\\n   pymysql ipython-sql sqlalchemy selenium requests beautifulsoup4 \\\n   psycopg2\n</code></pre></p> </li> </ol>"},{"location":"conda-0-config-basica/#engadir-miniconda-ao-path","title":"Engadir miniconda ao PATH","text":""},{"location":"conda-0-config-basica/#gnulinux","title":"GNU/Linux","text":"<p>O instalador ofr\u00e9cenos por defecto inicializar conda e metela no PATH, deber\u00edamos optar por esta opci\u00f3n.</p> <p>Se non o fixemos e non queremos executar de novo o instalador coa opci\u00f3n -u, ent\u00f3n podemos engadir ao final do .bashrc (considerando que ocnda estea instalado na ruta por defecto e a nivel usuario):</p> <pre><code>export PATH=$PATH:$HOME/miniconda3\n</code></pre>"},{"location":"conda-0-config-basica/#microsoft-windows","title":"Microsoft Windows","text":"<p>O instalador tam\u00e9n ofrece a posibilidade de meter conda no PATH pero o desaconsella, se non o fixeches (non \u00e9 unha opci\u00f3n por defecto) ent\u00f3n, p\u00f3delo meter manualmente como se indica a continuaci\u00f3n.</p> <p>Men\u00fa inicio -&gt; Editar las variables de entorno de esta cuenta</p> <p></p> <p></p> <p>Premer en \"Editar...\"</p> <p></p> <p>Logo en \"Nuevo\" e engadir unha entrada por li\u00f1a</p> <p>Mirar cal das d\u00faas aplica (mira os directorios e busca onde tes conda instalado) <pre><code>%USERPROFILE%\\AppData\\Local\\miniconda3\\condabin\n%USERPROFILE%\\Miniconda3\\bin\n</code></pre></p>"},{"location":"conda-0-config-basica/#configurar-visual-studio-code-vscode-con-conda-e-jupyterlab","title":"Configurar Visual Studio Code (vscode) con conda e jupyterlab","text":""},{"location":"conda-0-config-basica/#instalar-plugin-de-jupyterlab","title":"Instalar plugin de jupyterlab","text":"<p>Selecciona na roda de configuraci\u00f3n (abaixo, esquerda) a opci\u00f3n \"Extensiones\".</p> <p>Busca \"Jupyter\" do autor \"Microsoft\" e inst\u00e1lao.</p>"},{"location":"conda-0-config-basica/#configurar-a-ruta-base-de-conda","title":"Configurar a ruta base de conda","text":"<ol> <li>Vai \u00e1 roda de configuraci\u00f3n e selecciona configuraci\u00f3n (En GNU/Linux: Ctrl+,).</li> <li>Busca <code>conda path</code>.</li> <li>No cadro pon a ruta ao executable de conda (conda.bat en Microsoft Windows)</li> </ol> <pre><code>/home/USUARIO/miniconda3/bin/conda\n</code></pre>"},{"location":"conda-0-config-basica/#configurar-a-terminal","title":"Configurar a terminal","text":"<ol> <li>Abre o code.</li> <li> <p>Abre unha terminal (En GNU/Linux: Ctrl+Shift+`, en Microsoft Windows: Ctrl+\u00f1) e escribir o comando (en Windows podemos especificar tam\u00e9n powershell ao final):     <pre><code>conda init\n</code></pre></p> </li> <li> <p>Pecha t\u00f3dolos terminais e xa podes abrir un que ser\u00e1 inicializado no contorno base.</p> </li> </ol>"},{"location":"dbeaver-tunel-ssh/","title":"\ud83e\uddab DBeaver e t\u00faneles SSH","text":"<p>DBeaver \u00e9 un programa cliente SQL que permite ver, administrar e xestionar bases de datos. Emprega JDBC para conectarse.</p> <p>\u00c9 especialmente \u00fatil porque detecta e descarga autom\u00e1ticamente os drivers para moitos tipos diferentes de bases de datos.</p> <p>Imos ver paso a paso como configurar unha conexi\u00f3n facendo uso dun t\u00fanel SSH simple (sen saltar por m\u00e1is dun host).</p> <p>Neste exemplo configuraremos un servidor de MySQL que temos instalado mediante docker</p> <ol> <li> <p>Seleccionamos o tipo de base de datos MySQL. </p> </li> <li> <p>Na lapela General metemos a configuraci\u00f3n b\u00e1sica: Usuario e contrasinal de base de datos, a propia base de datos \u00e1 que imos conectar (employees) e metemos como servidor localhost e porto 3306 posto que imos redireccionar un porto hacia nos. </p> </li> <li> <p>Na lapela Driver properties mudamos o valor de allowPublicKeyRetrieval a TRUE posto que \u00e9 necesario no caso de empregar cifrado. Segundo a configuraci\u00f3n, pode ser necesario. </p> </li> <li> <p>Na lapela SSH d\u00e1moslle ao l\u00e1piz de editar (arriba \u00e1 dereita, despois de profile). O motivo de facelo dende ah\u00ed \u00e9 poder reutilizar este perfil con m\u00e1is conexi\u00f3ns a BBDD. </p> </li> <li> <p>Abrirase unha nova ventana, activamos o check Use SSH tunnel. </p> </li> <li> <p>Activaranse t\u00f3dalas casi\u00f1as a curbir. Na parte de Settings, no Host/IP meteremos o enderezo IP do servidor de SSH e o porto por defecto 22. Cubrimos o usuario e seleccionamos o m\u00e9todo de autenticaci\u00f3n Private Key. Prememos no \ud83d\udcc1 cartafol laranxa e buscamos a nosa chave privada (id_rsa ou equivalente se empregas outra diferente a RSA). No passphrase ir\u00e1 o contrasinal desta chave privada (se o arquivo est\u00e1 protexido). </p> </li> <li> <p>Seguimos cubrindo datos na parte de Advanced settings. En Local host metemos a nosa IP do interfaz de loopback (127.0.0.1) para non expo\u00f1er o servizo \u00e1 nosa rede, deixamos o porto por defecto 3306 posto que o puxemos no paso 2. En remote host metemos o servidor de BBDD ao que nos queremos conectar: 172.17.0.2 e porto por defecto: 3306. </p> </li> <li> <p>Co perfil xa seleccionado, podemos premer no bot\u00f3n Probar conexi\u00f3n e finalmente en Finalizar </p> </li> </ol> <p>O programa ten opci\u00f3ns para m\u00faltiples saltos no caso que precises conectarte a varios servidores ata chegar \u00e1 rede de producci\u00f3n.</p> <p>Ollo, ten en conta que se fas m\u00faltiples saltos, a velocidade poder\u00eda verse diminuida.</p>"},{"location":"docker-0-base-simple/","title":"\ud83d\udd35 Docker \u2014 Gu\u00eda b\u00e1sica","text":"<ul> <li>Baseado en: https://docs.docker.com/engine/install/debian/</li> <li>Tam\u00e9n hai dispo\u00f1ible unha presentaci\u00f3n de \ud83d\udc33 Docker / Contedores</li> </ul>"},{"location":"docker-0-base-simple/#instalacion-de-docker-en-debian","title":"Instalaci\u00f3n de docker en Debian","text":"<ol> <li> <p>Crear a m\u00e1quina en AWS / GCloud / Azure / CESGA Cloud ou instalaci\u00f3n local en Microsoft Windows con WSL (Debian ou Ubuntu) e conectarse a ela por SSH. De ser unha instancia na nube, trataremos de elexir unha distribuci\u00f3n Debian (recom\u00e9ndase a \u00faltima estable).</p> </li> <li> <p>Actualizamos ata o final a m\u00e1quina: <pre><code>sudo apt update\nsudo apt -y dist-upgrade\nsudo apt -y install curl\n</code></pre></p> </li> <li> <p>Executamos o script (gui\u00f3n) recomendado pola p\u00e1xina oficial de docker: <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh ./get-docker.sh\n</code></pre></p> </li> <li> <p>Engadimos o noso usuario ao grupo docker (para evitar empregar sudo): <pre><code>sudo usermod -a -G docker $USER\n</code></pre></p> </li> <li> <p>Sa\u00edmos da sesi\u00f3n e volvemos abrila (ou abrimos unha sesi\u00f3n sobre a actual como se indica a continuaci\u00f3n): <pre><code>sudo su - $USER\n</code></pre></p> </li> <li> <p>Probamos o docker de exemplo de hola-mundo: <pre><code>docker run hello-world\n</code></pre></p> </li> </ol> <p>Se est\u00e1s nun contorno WSL coa distribuci\u00f3n GNU/Debian instalada e recibes o erro:</p> /var/log/docker.log<pre><code>failed to start daemon: Error initializing network controller: error obtaining controller instance: failed to register \"bridge\" driver: unable to add return rule in DOCKER-ISOLATION-STAGE-1 chain:  (iptables failed: iptables --wait -A DOCKER-ISOLATION-STAGE-1 -j RETURN: iptables v1.8.9 (nf_tables):  RULE_APPEND failed (No such file or directory): rule in chain DOCKER-ISOLATION-STAGE-1\n</code></pre> <p>\u00c9 debido a que docker emprega iptables cunha versi\u00f3n modificada de nftables. Para arranxalo, podemos empregar as legacy iptables:</p> <pre><code>sudo update-alternatives --set iptables /usr/sbin/iptables-legacy\nsudo update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy\n</code></pre> <p>Despois de cambialas, dockerd deber\u00eda iniciarse correctamente (Fonte: GitHub).</p> <pre><code>sudo service docker restart\n</code></pre>"},{"location":"docker-0-base-simple/#conceptos-basicos-de-dockers","title":"Conceptos b\u00e1sicos de dockers","text":"<p>Podes ver a presentaci\u00f3n de: \ud83d\udce6 Docker / Contedores</p> <p>\u26a0\ufe0f Este resumo cont\u00e9n imprecisi\u00f3ns porque pretende ser breve.</p> <p><pre><code>mindmap\n  root((Docker))\n    Contedores\n    Imaxes\n    Volumes\n    Redes</code></pre> En docker existen os conceptos de: Contedores, imaxes, volumes e redes.</p> <p>Cando executamos un \"docker run\", cr\u00e9ase un contedor baseado nunha imaxe que se descarga de internet e arr\u00e1ncase. Este contedor \u00e9 como unha m\u00e1quina virtual xa configurada e funcionando.</p> <p>Hai imaxes xa listas en internet: https://hub.docker.com/ ou ben podemos facer a nosa.</p> <p>Unha vez creado un contedor pod\u00e9molo parar ou arrancar.</p> <p>Podemos gardar os datos en volumes ou directorios compartidos. Se non especificamos nada a informaci\u00f3n queda no contedor ou no volume que cree por defecto (se o crea).</p>"},{"location":"docker-0-base-simple/#contedores","title":"Contedores","text":"<ul> <li>Ver contedores en execuci\u00f3n: <code>docker ps</code></li> <li>Ver t\u00f3dolos contedores: <code>docker ps -a</code></li> <li>Crear un contedor: <code>docker run hello-world</code><ul> <li><code>-d</code>: modo dettached (execuci\u00f3n en segundo plano).</li> <li><code>--rm</code>: borra a instancia cando se para.</li> </ul> </li> <li>Parar un contedor: <code>docker stop [ID ou NOME]</code></li> <li>Iniciar un contedor: <code>docker start [ID ou NOME]</code></li> <li>Executar un comando dentro do contenedor: <code>docker exec -it [ID ou NOME] [COMANDO]</code><ul> <li><code>-it</code>: Modo interactivo</li> </ul> </li> <li>Ver t\u00f3dalas opci\u00f3ns do contedor: <code>docker inspect [ID ou NOME]</code></li> <li>Borrar un contedor: <code>docker rm [ID ou NOME]</code></li> </ul> <p>\ud83d\udc41\ufe0f Se queremos que os contedores volvan executarse cando a m\u00e1quina se reinicie, cando no momento da creaci\u00f3n (run) do contedor podemos especificar a opci\u00f3n: <code>--restart unless-stopped</code></p>"},{"location":"docker-0-base-simple/#imaxes","title":"Imaxes","text":"<ul> <li>Ver imaxes: <code>docker image ls</code></li> <li>Borrar imaxe: <code>docker image rm [ID ou NOME]</code></li> </ul>"},{"location":"docker-0-base-simple/#volumes","title":"Volumes","text":"<ul> <li>Ver volume: <code>docker volume ls</code></li> <li>Borrar volume: <code>docker volume rm [ID ou NOME]</code></li> </ul>"},{"location":"docker-0-base-simple/#volumes-en-cada-contedor","title":"Volumes en cada contedor","text":"<p>Se queremos ver qu\u00e9 volumes est\u00e1n asociados a que contedor:</p> <pre><code>docker ps -a --no-trunc --format \"{{.Names}}: {{.Mounts}}\"\n</code></pre>"},{"location":"docker-0-base-simple/#recuperando-datos-dun-volume","title":"Recuperando datos dun volume","text":"<p>\ud83d\udc41\ufe0f Se queremos ver os datos dun volume que xa non est\u00e1 asociado a un contedor, podemos crear un contedor temporal para velos: <code>docker run -it --rm -v [ID do volume]:/vol busybox ls -l /vol</code></p>"},{"location":"docker-0-base-simple/#asociar-un-volume-previo-a-un-contedor","title":"Asociar un volume previo a un contedor","text":"<pre><code>docker run -p 9907:3306 --name contedor_mariadb \\\n  -v ID_VOLUME:/var/lib/mysql \\\n  --restart unless-stopped \\\n  -d mariadb:latest\n</code></pre> <p>Se <code>ID_VOLUME</code> o cambiamos por un directorio, estar\u00edamos a mapear un directorio do anfitri\u00f3n.</p>"},{"location":"docker-0-base-simple/#estados-dun-contedor","title":"Estados dun contedor","text":"<pre><code>---\ntitle: Estados dun contenedor docker\n---\nstateDiagram-v2\n    [*] --&gt; Creado\n    Creado --&gt; En_Execuci\u00f3n\n    En_Execuci\u00f3n --&gt; Parado_Rematado\n    En_Execuci\u00f3n --&gt; Erro\n    En_Execuci\u00f3n --&gt; Pausado\n    Pausado --&gt; En_Execuci\u00f3n\n    Parado_Rematado --&gt; Erro\n    Parado_Rematado --&gt; En_Execuci\u00f3n\n    Parado_Rematado --&gt; Borrado\n    Parado_Rematado --&gt; Morto\n    Erro --&gt; En_Reinicio\n    En_Reinicio --&gt; Erro\n    En_Reinicio --&gt; En_Execuci\u00f3n\n    Morto --&gt; Borrado\n    Borrado --&gt; [*]\n</code></pre> <p>Realmente existen 6 estados. O estado borrado \u00e9 para que se vexa mellor no diagrama m\u00e1is non \u00e9 un estado. O <code>Erro</code> ou <code>Morto</code> poden ser o mesmo estado nalgunhas circunstancias.</p> <p>M\u00e1is informaci\u00f3n acerca dos estados en: https://www.baeldung.com/ops/docker-container-states.</p>"},{"location":"docker-0-base-simple/#imaxes-oficiales-para-docker-que-podes-probar","title":"Imaxes oficiales para docker que podes probar","text":"<p>Nesta p\u00e1xina tes algunhas configuraci\u00f3ns r\u00e1pidas (exemplos xa feitos) baseados nestas imaxes:</p> <ul> <li>https://hub.docker.com/_/mysql</li> <li>https://hub.docker.com/_/mariadb</li> <li>https://mariadb.com/kb/en/installing-and-using-mariadb-via-docker/</li> <li>https://hub.docker.com/_/microsoft-mssql-server</li> <li>https://hub.docker.com/_/mongo</li> <li>https://hub.docker.com/_/redis</li> <li>https://hub.docker.com/_/postgres</li> <li>https://hub.docker.com/_/cassandra</li> </ul>"},{"location":"docker-1-my-maria/","title":"\ud83e\uddfe MySQL / MariaDB","text":"<ul> <li>Baseado nas imaxes oficiais:<ul> <li>MySQL: https://hub.docker.com/_/mysql</li> <li>MariaDB: https://hub.docker.com/_/mariadb</li> </ul> </li> </ul> <p>Imos ver e instalar dous sabores deste servidor SQL tan popular.</p>"},{"location":"docker-1-my-maria/#mysql","title":"MySQL","text":""},{"location":"docker-1-my-maria/#instalacion-de-mysql","title":"Instalaci\u00f3n de MySQL","text":"<p>E recomendable crear un volume previamente cun nome para ter localizado onde temos os datos:</p> <pre><code>docker volume create datosmysql\n</code></pre> <p>E logo crear o contedor asociado a ese volume:</p> <pre><code>docker run -p 9906:3306 --name contedor_mysql \\\n  -v datosmysql:/var/lib/mysql \\ # (1)!\n  -e MYSQL_RANDOM_ROOT_PASSWORD=1 \\ # (2)!\n  -e MYSQL_DATABASE=basededatos \\ # (3)!\n  -e MYSQL_USER=usuario \\ # (4)!\n  -e MYSQL_PASSWORD=Contrasinal123. \\ # (5)!\n  --restart unless-stopped \\ # (6)!\n  -d mysql:8\n</code></pre> <ol> <li>Volume para os datos.</li> <li>Contrasinal de root.</li> <li>Crea a base de datos <code>basededatos</code>.</li> <li>Crea o usuario <code>usuario</code> con acceso de superusaurio a <code>basededatos</code>.</li> <li>Establece o contrasinal de <code>usuario</code> (\u00e9 preciso para que se cree o usuario).</li> <li>Para que inicie autom\u00e1ticamente o contedor tras un reinicio de docker ou da m\u00e1quina.</li> </ol> <p>Copia de aqu\u00ed o comando para que non fallen as novas li\u00f1as e espacios:</p> <pre><code>docker run -p 9906:3306 --name contedor_mysql -v datosmysql:/var/lib/mysql -e MYSQL_RANDOM_ROOT_PASSWORD=1 -e MYSQL_DATABASE=basededatos -e MYSQL_USER=usuario -e MYSQL_PASSWORD=Contrasinal123. --restart unless-stopped -d mysql:8\n</code></pre> <p>Aclaraci\u00f3ns:</p> <ul> <li><code>-p 9906:3306</code> redirixe o porto <code>9906</code> do anfitri\u00f3n ao porto <code>3306</code> do contedor.</li> <li><code>--env</code> ou <code>-e</code> serven para definir variables de entorno (configuraci\u00f3n) presentes na imaxe.</li> <li><code>-v</code> permite asociar (montar) un directorio local a un directorio de dentro do contedor. Poder\u00edamos asociado un directorio local <code>/root/mysqldatos</code> ao contedor en <code>/var/lib/mysql</code> co par\u00e1metro: <code>-v /root/mysqldatos:/var/lib/mysql</code>. Tam\u00e9n poder\u00edamos mapear un volume anterior con: <code>-v ID_DO_VOLUME:/var/lib/mysql</code>.</li> <li>Para saber o contrasinal de root asignado aleatoriamente debemos buscar nos logs unha li\u00f1a que conte\u00f1a: \"[Note] [Entrypoint]: GENERATED ROOT PASSWORD:\":     <pre><code>docker logs contedor_mysql\n</code></pre></li> </ul> <p>Por \u00faltimo comprobamos que te\u00f1amos correctamente asociado o volume de datos ao noso contedor:</p> <pre><code>docker ps -a --no-trunc --format \"{{.Names}}: {{.Mounts}}\"\n</code></pre>"},{"location":"docker-1-my-maria/#recuperar-instancia-de-mysql-co-seu-volume","title":"Recuperar instancia de MySQL co seu volume","text":"<p>Se queremos recuperar unha instancia borrada, sempre e cando non borr\u00e1semos o seu volume de datos, anterior (non fai falta especificar usuarios ou contrasinais):</p> <pre><code>docker run -p 9906:3306 --name contedor_mysql \\\n  -v datosmysql:/var/lib/mysql \\\n  --restart unless-stopped \\\n  -d mysql:8\n</code></pre>"},{"location":"docker-1-my-maria/#cli-conexion-con-mysql","title":"(CLI) Conexi\u00f3n con MySQL","text":"Conectar co cliente do dockerConectar cun cliente doutro host <pre><code>docker exec -it contedor_mysql mysql -uusuario -pContrasinal123.\n</code></pre> <ul> <li>Podemos engadir <code>-hX.X.X.X</code> para conectar con outro equipo.</li> </ul> <pre><code>mysql -hX.X.X.X -P9907 -uusuario -pContrasinal123.\n</code></pre> <ul> <li><code>X.X.X.X</code> \u00e9 a IP do servidor ao que queremos conectar.</li> </ul>"},{"location":"docker-1-my-maria/#mariadb","title":"MariaDB","text":""},{"location":"docker-1-my-maria/#instalacion-de-mariadb","title":"Instalaci\u00f3n de MariaDB","text":"<p>E recomendable crear un volume previamente cun nome para ter localizado onde temos os datos:</p> <pre><code>docker volume create datosmariadb\n</code></pre> <pre><code>docker run -p 9907:3306 --name contedor_mariadb \\\n  -v datosmariadb:/var/lib/mysql \\ # (1)!\n  --env MARIADB_RANDOM_ROOT_PASSWORD=1 \\ # (2)!\n  --env MARIADB_DATABASE=demaria \\ # (3)!\n  --env MARIADB_USER=usuariamaria \\ # (4)!\n  --env MARIADB_PASSWORD=DonaMaria123456 \\ # (5)!\n  --restart unless-stopped \\ # (6)!\n  -d mariadb:latest\n</code></pre> <ol> <li>Volume para os datos.</li> <li>Elexir un contrasinal de root aleatorio.</li> <li>Crea a base de datos <code>demaria</code>.</li> <li>Crea o usuario <code>usuariamaria</code> con acceso de superusaurio a <code>demaria</code>.</li> <li>Establece o contrasinal de <code>usuariamaria</code> (\u00e9 preciso para que se cree o usuario).</li> <li>Para que inicie autom\u00e1ticamente o contedor tras un reinicio de docker ou da m\u00e1quina.</li> </ol> <p>Copia de aqu\u00ed o comando para que non fallen as novas li\u00f1as e espacios:</p> <pre><code>docker run -p 9907:3306 --name contedor_mariadb -v datosmariadb:/var/lib/mysql --env MARIADB_RANDOM_ROOT_PASSWORD=1 --env MARIADB_DATABASE=demaria --env MARIADB_USER=usuariamaria --env MARIADB_PASSWORD=DonaMaria123456 --restart unless-stopped -d mariadb:latest\n</code></pre> <p>Aclaraci\u00f3ns:</p> <ul> <li><code>-p 9906:3306</code> redirixe o porto <code>9906</code> do anfitri\u00f3n ao porto <code>3306</code> do contedor.</li> <li><code>--env</code> ou <code>-e</code> serven para definir variables de entorno (configuraci\u00f3n) presentes na imaxe.</li> <li><code>-v</code> permite asociar (montar) un directorio local a un directorio de dentro do contedor. Poder\u00edamos asociado un directorio local <code>/root/mariadbdatos</code> ao contedor en <code>/var/lib/mysql</code> co par\u00e1metro: <code>-v /root/mariadbdatos:/var/lib/mysql</code></li> <li>A imaxe xa executa o script: <code>/usr/bin/mariadb-secure-installation</code> que equivale ao <code>mysql_secure_installation</code>.</li> <li>Para saber o contrasinal de root asignado aleatoriamente debemos buscar nos logs unha li\u00f1a que conte\u00f1a: \"[Note] [Entrypoint]: GENERATED ROOT PASSWORD:\":     <pre><code>docker logs contedor_mariadb\n</code></pre> Por \u00faltimo comprobamos que te\u00f1amos correctamente asociado o volume de datos ao noso contedor:</li> </ul> <pre><code>docker ps -a --no-trunc --format \"{{.Names}}: {{.Mounts}}\"\n</code></pre>"},{"location":"docker-1-my-maria/#recuperar-instancia-de-mariadb-co-seu-volume","title":"Recuperar instancia de MariaDB co seu volume","text":"<p>Se queremos recuperar unha instancia borrada, sempre e cando non borr\u00e1semos o seu volume de datos, anterior (non fai falta especificar usuarios ou contrasinais):</p> <pre><code>docker run -p 9907:3306 --name contedor_mariadb \\\n  -v datosmariadb:/var/lib/mysql \\\n  --restart unless-stopped \\\n  -d mariadb:latest\n</code></pre>"},{"location":"docker-1-my-maria/#cli-conexion-con-mariadb","title":"(CLI) Conexi\u00f3n con MariaDB","text":"Conectar co cliente do dockerConectar cun cliente doutro host <pre><code>docker exec -it contedor_mariadb mariadb -uusuariamaria -pDonaMaria123456\n</code></pre> <ul> <li>Podemos engadir <code>-hX.X.X.X</code> para conectar con outro equipo.</li> </ul> <pre><code>mariadb -hX.X.X.X -P9907 -uusuariamaria -pDonaMaria123456\n</code></pre> <ul> <li><code>X.X.X.X</code> \u00e9 a IP do servidor ao que queremos conectar.</li> </ul>"},{"location":"docker-1-my-maria/#gui-conectar-a-mariadbmysql-con-dbeaver","title":"(GUI) Conectar a MariaDB/MySQL con DBeaver","text":"<p>Se queremos conectar dende DBeaver na nosa m\u00e1quina local e temos instalado o contedor de MariaDB/MySQL nunha m\u00e1quina remota, tampouco debemos esquecer configurar o porto:</p> <p></p> <p>Na lapela Driver properties lembra mudar o valor de allowPublicKeyRetrieval a TRUE posto que \u00e9 necesario no caso de empregar cifrado. Segundo a configuraci\u00f3n, pode ser necesario.</p> <p>Podes acceder a un manual m\u00e1is detallado en \ud83e\uddab DBeaver e t\u00faneles SSH onde tam\u00e9n aprender\u00e1s como realizar un t\u00fanel SSH. Este t\u00fanel pode ser necesario si o servidor de base de datos est\u00e1 detr\u00e1s dun firewall.</p>"},{"location":"docker-1-my-maria/#comandos-utiles-dende-consola-mysqlmariadb","title":"Comandos \u00fatiles dende consola MySQL/MariaDB","text":""},{"location":"docker-1-my-maria/#comandos-simples","title":"Comandos simples","text":"<ul> <li>Ver as bases de datos:     <pre><code>show databases;\n</code></pre></li> <li>Seleccionar unha base de datos:      <pre><code>use database;\n</code></pre></li> <li>Ver as t\u00e1boas da BBDD actual seleccionada:      <pre><code>show tables;\n</code></pre></li> <li>Ver informaci\u00f3n do estado do servidor:     <code>\\s</code></li> <li>Sa\u00edr do cliente. Tam\u00e9n funcionar\u00eda: <code>quit</code> ou <code>Crtl+D</code>:     <code>\\q</code></li> </ul>"},{"location":"docker-1-my-maria/#crear-usuario-e-conceder-permisos-a-base-de-datos","title":"Crear usuario e conceder permisos a base de datos","text":"<pre><code>CREATE USER 'usuario-a-crear'@'%' IDENTIFIED BY 'contrasinal-abc123.';\nGRANT ALL PRIVILEGES ON base-de-datos.* TO 'usuario-a-crear'@'%';\nFLUSH PRIVILEGES;\n</code></pre>"},{"location":"docker-1-my-maria/#executar-un-arquivo-sql-util-para-recuperar-un-backup","title":"Executar un arquivo .sql (\u00fatil para recuperar un backup)","text":"<pre><code>source /ruta/ao/arquivo.sql\n</code></pre>"},{"location":"docker-1-my-maria/#importar-unha-base-de-datos-de-proba","title":"Importar unha base de datos de proba","text":"<p>Estas instrucci\u00f3ns son para un servidor MariaDB/MySQL execut\u00e1ndose dentro doutra m\u00e1quina (real ou virtual) en caso que instalases MariaDB/MySQL nun docker, estas instrucci\u00f3ns debes adaptalas. Probablemente se tes instalado con dockers ser\u00edache m\u00e1is c\u00f3modo facer a importaci\u00f3n con DBeaver.</p> <ol> <li> <p>Descargar a BD employees: https://github.com/datacharmer/test_db/releases/tag/v1.0.7</p> </li> <li> <p>Copiar a BBDD ao servidor que te\u00f1amos montado (neste exemplo copiamos de local ao servidor con scp, se instalaches con docker o comando cambiar\u00e1):</p> <pre><code>scp -i chave-ssh.key employees_db-full-1.0.7.tar.gz usuario@IP-DO-SERVIDOR:/tmp/\n</code></pre> </li> <li> <p>Conectamos co servidor (neste exemplo conectamos por SSH, pero si tes montado un docker, pode que precises engadir/mudar os comandos)</p> <pre><code>ssh -i chave-ssh.key usuario@IP-DO-SERVIDOR\nsudo su -\ncd /tmp\ntar -xvzf employees_db-full-1.0.7.tar.gz\nmysql -h localhost\n    source /tmp/employees_db/employees.sql\n    show tables;\n</code></pre> </li> </ol> <p>Se est\u00e1s a traballar coa versi\u00f3n: employees_db-full-1.0.6.tar.bz2 pode ser que te\u00f1as alg\u00fan problema co engine. Neste caso, engadir \"default_\" diante das d\u00faas li\u00f1as en employees.sql axuda. Fonte: stackoverflow.</p> <p>Webgraf\u00eda:</p> <ul> <li>https://github.com/datacharmer/test_db</li> <li>https://downloads.mysql.com/docs/world-db.tar.gz</li> <li>https://dev.mysql.com/doc/employee/en/employees-installation.html</li> </ul>"},{"location":"docker-1-my-maria/#comando-mysqldump-para-backup-dende-shell","title":"Comando mysqldump para backup (dende shell)","text":"Backup dunha BBDDBackup de todas as BBDD <pre><code>mysqldump -uUSUARIO -pCLAVE --databases BASE_DATOS &gt; YYYY-mm-dd_mysql_backup.sql\n</code></pre> <pre><code>mysqldump -uUSUARIO -pCLAVE --all-databases &gt; YYYY-mm-dd_mysql_backup.sql\n</code></pre>"},{"location":"docker-1-my-maria/#conectar-a-mysql-dende-python","title":"Conectar a MySQL dende Python","text":"<ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/mysql.ipynb</li> </ul> <p>\u26a0\ufe0f AVISO: Esta configuraci\u00f3n NON pretende ser segura, o seu obxectivo \u00e9 montar de xeito r\u00e1pido un contorno para a aprendizaxe. Entre outras cousas deber\u00edamos deshabilitar o usuario root para conexi\u00f3ns remotas, borrar as BBDD de proba e impedir o acceso directo ao servidor de base de datos.</p>"},{"location":"docker-1-my-maria/#adicional-porto-aberto","title":"Adicional: Porto aberto?","text":"<p>En GNU/Linux podes ver qu\u00e9 portos est\u00e1n abertos con:</p> <pre><code>netstat -atun\n</code></pre> <p>En docker podes ver as redirecci\u00f3ns de portos don <code>docker inspect</code>.</p> <p>No caso de instalaci\u00f3n con docker, se ves que non tes aberto o 9906/9907 (segundo o exemplo) no anfitri\u00f3n ou o 3306 onde te\u00f1as MySQL, probablemente debas cambiar o bind-address na configuraci\u00f3n de MySQL oy MariaDB.</p> <p>Edita o arquivo correspondente (en MySQL: /etc/mysql/mysql.conf.d/mysqld.cnf) e mete ou descomenta esta li\u00f1a:</p> <pre><code>bind-address por 0.0.0.0\n</code></pre> <p>Ollo! Si \u00e9 que non conectas ao porto 3306 pero o ves aberto, moi probablemente estea filtrado no firewall (na computaci\u00f3n na nube \u00e1s veces filtran ese porto a\u00ednda que t\u00ed o abras expl\u00edcitamente).</p>"},{"location":"docker-2-mongodb/","title":"\ud83e\uddfe MongoDB","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/_/mongo</li> </ul>"},{"location":"docker-2-mongodb/#introducion","title":"Introduci\u00f3n","text":"<p>Podemos executar MongoDB de tres modos diferentes:</p> <ul> <li>Standalone server: Un s\u00f3 servidor, \u00fatil para desenvolvemento e probas.</li> <li>Replica set (ou cluster simple): \u00datil en produci\u00f3n, varias instancias de servidor en execuci\u00f3n. Engade redundancia e dispo\u00f1ibilidade (escalado horizontal).</li> <li>Sharded cluster: \u00datil en produci\u00f3n, varias instancias de servidor en execuci\u00f3n. Engade a posibilidade de particionar os datos. Permite un manexo de alto volume de datos e operaci\u00f3ns.</li> </ul> <p>Non confundamos estes modos de operaci\u00f3n coa licencia ou version de mongo:</p> <ul> <li>Community: Gratuita.</li> <li>Enterprise: Versi\u00f3n comercial con soporte e optimizaci\u00f3ns. Gratuita para desenvolvemento.</li> <li>Atlas: Versi\u00f3n na nube. Gratuita ata 512MB.</li> </ul>"},{"location":"docker-2-mongodb/#instalacion-en-modo-standalone-server-simple","title":"Instalaci\u00f3n en modo standalone server (simple):","text":"<ul> <li> <p>Instalaci\u00f3n:</p> <pre><code>docker run -d --name mongo \\\n  -e MONGO_INITDB_ROOT_USERNAME=mongoadmin \\\n  -e MONGO_INITDB_ROOT_PASSWORD=abc123Secret \\\n  -p 27017:27017 \\\n  mongo\n</code></pre> </li> <li> <p>Conexi\u00f3n con par\u00e1metros:</p> <pre><code>docker exec -it mongo \\\nmongosh --host localhost --port 27017 --apiVersion 1 \\\n--username mongoadmin --password abc123Secret\n</code></pre> </li> <li> <p>Conexi\u00f3n con URL:</p> <pre><code>docker exec -it mongo mongosh \\\n  \"mongodb://mongoadmin:abc123Secret@localhost:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000\"\n</code></pre> </li> </ul> <p>No docker de instalaci\u00f3n, podes mapear un cartafol co host para ver como almacena mongo os datos coa opci\u00f3n: <code>-v /root/mongo:/data/db</code>, m\u00e1is o recomendado \u00e9 gardar os datos nun volume.</p> <p>Webgraf\u00eda:</p> <ul> <li>https://hub.docker.com/_/mongo</li> <li>https://www.mongodb.com/docs/mongodb-shell/connect/</li> </ul>"},{"location":"docker-2-mongodb/#conexion-a-mongodb-cliente","title":"Conexi\u00f3n a mongodb (cliente)","text":"<p>Estas instrucci\u00f3n son s\u00f3 no caso de querer instalar o cliente en local. Lembremos que sempre podemos conectar co cliente mongosh de dentro do contedor.</p> <p>Instrucci\u00f3ns para GNU/Linux Debian 12 Bookworm:</p> <ol> <li> <p>Instalaci\u00f3n de dependencias:     <pre><code>sudo apt-get install gnupg curl\n</code></pre></p> </li> <li> <p>Baixar a chave GNUpg que firma os paquetes do repositorio:</p> <pre><code>curl -fsSL https://www.mongodb.org/static/pgp/server-7.0.asc | \\\n sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg \\\n --dearmor\n</code></pre> </li> <li> <p>Engadir o novo repositorio:</p> <pre><code>echo \"deb [ signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] http://repo.mongodb.org/apt/debian bookworm/mongodb-org/7.0 main\" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list\n</code></pre> </li> <li> <p>Actualizar a informaci\u00f3n de paquetes dos repositorios:</p> <pre><code>sudo apt-get update\n</code></pre> </li> <li> <p>Instalar os paquetes:</p> <pre><code>sudo apt-get install -y mongodb-org\n</code></pre> </li> </ol> <p>Coidado co ulimit! O n\u00famero de arquivos abertos m\u00e1ximos debe ser superior a 64.000.</p> <p>Webgraf\u00eda: - https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-debian/</p>"},{"location":"docker-2-mongodb/#gui-conectar-con-compass","title":"(GUI) Conectar con Compass","text":"<p>Compass \u00e9 un cliente gr\u00e1fico gratuito oficial que nos permite conectar con Mongo e mesmo ver algunhas estat\u00edsticas do servidor. Debido a que mongodb \u00e9 amplamente empregado no mundo empresarial, moitos clientes de base de datos que te\u00f1en versi\u00f3n community soen ser de pago con mongo (exemplo: DBeaver).</p> <p>Podes baixar compass da s\u00faa p\u00e1xina oficial: - https://www.mongodb.com/products/tools/compass</p> <p>E para conectar, podes empregar a cadea de conexi\u00f3n:</p> <p><code>mongodb://mongoadmin:abc123Secret@localhost:27017/?directConnection=true&amp;serverSelectionTimeoutMS=2000</code></p> <p>Lembra premer no bot\u00f3n de \"Save and connect\" para gardar a conexi\u00f3n co usuario e contrasinal \u00e1 esquerda e non ter que volver introducilos manualmente (ou ter que introducir a cadea de conexi\u00f3n que tam\u00e9n incl\u00fae eses datos).</p>"},{"location":"docker-2-mongodb/#conectar-contra-atlas-servidor-na-nube","title":"Conectar contra Atlas (servidor na nube)","text":""},{"location":"docker-2-mongodb/#cli-mongosh-contra-atlas","title":"(CLI) Mongosh contra atlas","text":"<ul> <li> <p>Chamamos \u00e1 consola mongosh cos par\u00e1metros:</p> <pre><code> mongosh \"mongodb+srv://.../\" --apiVersion 1 --username USUARIO\n</code></pre> </li> </ul>"},{"location":"docker-2-mongodb/#cli-cliente-atlas","title":"(CLI) Cliente Atlas","text":"<ul> <li> <p>Instalaci\u00f3n:</p> <pre><code>sudo apt install mongodb-atlas-cli\n</code></pre> </li> <li> <p>Iniciar sesi\u00f3n:</p> <pre><code>atlas auth login\n</code></pre> </li> </ul>"},{"location":"docker-2-mongodb/#lecturas-complementarias","title":"Lecturas complementarias","text":"<ul> <li>Apuntes de MongoDB en formato presentaci\u00f3n</li> <li>Conectar a MongoDB dende Python (notebook)</li> <li>Como securizar un servidor mongo accesible en internet (ingl\u00e9s, p\u00e1xina oficial)</li> </ul>"},{"location":"docker-2-mongodb/#creando-un-clusterreplica-set-de-mongo-en-docker","title":"Creando un cluster/replica set de mongo en docker","text":"<p>Fai falta seguir uns pasos l\u00f3xicos: Crear una nova rede en docker para que se comuniquen os contedores entre eles, executar alomenos tres contedores de mongo asociados a esa rede e finalmente facer que se unan entre eles nun replica set.</p>"},{"location":"docker-2-mongodb/#crear-a-rede-en-docker","title":"Crear a rede en docker","text":"<p>Como en calquer caso, creamos unha nova rede cun nome que nos guste:</p> <pre><code>docker network create mongoReplicado\n</code></pre>"},{"location":"docker-2-mongodb/#lanzar-os-contedores","title":"Lanzar os contedores","text":"<pre><code>docker run -d -p 27017:27017 --name mongoVermello --network mongoReplicado mongo mongod --replSet replicados --bind_ip localhost,mongoVermello\ndocker run -d -p 27027:27017 --name mongoVerde --network mongoReplicado mongo mongod --replSet replicados --bind_ip localhost,mongoVerde\ndocker run -d -p 27037:27017 --name mongoAzul --network mongoReplicado mongo mongod --replSet replicados --bind_ip localhost,mongoAzul\n</code></pre> <p>Os portos redirixidos do anfitri\u00f3n ao contedor van ser os seguintes:</p> <ul> <li>27017: mongoVermello (o por defecto)</li> <li>27027: mongoVerde</li> <li>27037: mongoAzul</li> </ul>"},{"location":"docker-2-mongodb/#unir-os-servidores","title":"Unir os servidores","text":"<pre><code>docker exec -it mongoVermello mongosh --eval \"rs.initiate({\n _id: \\\"replicados\\\",\n members: [\n   {_id: 0, host: \\\"mongoVermello\\\"},\n   {_id: 1, host: \\\"mongoVerde\\\"},\n   {_id: 2, host: \\\"mongoAzul\\\"}\n ]\n})\"\n</code></pre>"},{"location":"docker-2-mongodb/#probar-que-estean-funcionando-en-modo-replica-set","title":"Probar que estean funcionando en modo replica set","text":"<pre><code>docker exec -it mongoVermello mongosh --eval \"rs.status()\"\n</code></pre> <p>E se paramos o \"principal\":</p> <pre><code>docker stop mongoVermello\n</code></pre> <p>E consultamos os outros, todo deber\u00eda seguir funcionando igual, os datos seguen dispo\u00f1ibles:</p> <pre><code>docker exec -it mongoVerde mongosh --eval \"rs.status()\"\ndocker exec -it mongoAzul mongosh --eval \"rs.status()\"\n</code></pre> <p>Webgraf\u00eda:</p> <ul> <li>https://www.mongodb.com/resources/products/compatibilities/deploying-a-mongodb-cluster-with-docker</li> <li>https://www.mongodb.com/docs/manual/tutorial/convert-standalone-to-replica-set/</li> <li>https://www.mongodb.com/docs/manual/reference/replica-configuration/#std-label-replica-set-configuration-document</li> </ul>"},{"location":"docker-2-mongodb/#conversion-do-replica-set-a-sharded-cluster","title":"Conversi\u00f3n do Replica Set a Sharded Cluster","text":"<p>O principal obxectivo deste tipo de configuraci\u00f3n \u00e9 ter particionado os datos cunha shard key.</p> <p>Hai un titorial na web oficial de mongodb sobre como pasar dun replica set (con autenticaci\u00f3n habilitada) a un sharded cluster:</p> <ul> <li>https://www.mongodb.com/docs/manual/tutorial/convert-replica-set-to-replicated-shard-cluster/</li> </ul>"},{"location":"docker-3-redis/","title":"\ud83e\uddfe Redis","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/r/redis/redis-stack-server</li> </ul> <p>Creamos o volume para persisitir os datos (opcional):</p> <pre><code>docker create volume redis-data\n</code></pre>"},{"location":"docker-3-redis/#creamos-o-docker","title":"Creamos o docker:","text":"<pre><code>docker run -d --name redis-stack \\\n    -v redis-data:/data \\ # (1)!\n    -e REDIS_ARGS=\"--requirepass 123quetal123\" \\ # (2)!\n    -p 6379:6379 -p 8001:8001 \\\n    redis/redis-stack:latest\n</code></pre> <ol> <li>Nome do volume, no caso que queiramos persistir os datos.</li> <li>Contrasinal.</li> </ol> <p>Copia de aqu\u00ed o comando se tes problemas coas novas li\u00f1as:</p> <pre><code>docker run -d --name redis-stack -v redis-data:/data -e REDIS_ARGS=\"--requirepass 123quetal123\" -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n</code></pre>"},{"location":"docker-3-redis/#cli-conectando-a-redis-dende-o-propio-docker","title":"(CLI) Conectando a redis dende o propio docker:","text":"<pre><code>docker exec -it redis-stack \\\n    redis-cli -h localhost -p 6379 -a 123quetal123\n</code></pre> <p>Se non especificamos o contrasinal con <code>-a 123quetal123</code> en li\u00f1a de comandos, para autenticarnos deberemos po\u00f1er o comando: <code>AUTH 123quetal123</code> dentro do cliente de redis.</p> <p>Dentro da consola de texto de redis, creamos un usuario:</p> <pre><code>acl setuser usuarioredis &gt;contrasinal123inseguro on allchannels allkeys +get +set +del +info +scan +exists +hset +type +expire +getrange +hlen +hscan +hdel +sadd +srem +scard +sscan +sismember +lpush +llen +lset +rpushx +lrange +zrange +zadd +xadd +zcard +json.set +json.get +slowlog|get +config|get +xinfo|stream\n</code></pre> <pre><code>docker exec -it redis-stack \\\n    redis-cli --user usuarioredis --pass contrasinal123inseguro\n</code></pre>"},{"location":"docker-3-redis/#gui-conexion-contra-redisinsight","title":"(GUI) Conexi\u00f3n contra redisinsight","text":"<p>Se empregaches a configuraci\u00f3n de docker de enriba, s\u00f3 tes que conectar \u00e1 IP da m\u00e1quina do docker ao porto 8081. Por exemplo: http://localhost:8001. Inicia sesi\u00f3n co usuario <code>usuarioredis</code> e o contrasinal <code>contrasinal123inseguro</code>.</p>"},{"location":"docker-3-redis/#outras-variables-de-contorno-do-docker","title":"Outras variables de contorno do docker","text":"<p>Segundo a documentaci\u00f3n da imaxe oficial, temos acceso a modificar as seguintes variables de contorno:</p> <ul> <li>REDIS_ARGS: Redis</li> <li>REDISEARCH_ARGS: RediSearch</li> <li>REDISJSON_ARGS: RedisJSON</li> <li>REDISGRAPH_ARGS: RedisGraph</li> <li>REDISTIMESERIES_ARGS: RedisTimeSeries</li> <li>REDISBLOOM_ARGS: RedisBloom</li> </ul> <p>Por exemplo, se quix\u00e9ramos persistir os datos no RedisTimeSeries, podemos engadir unha variable de contorno \u00e1 creaci\u00f3n do docker:</p> <p><code>-e REDISTIMESERIES_ARGS=\"RETENTION_POLICY=20\"</code></p>"},{"location":"docker-3-redis/#comandos-utiles","title":"Comandos \u00fatiles:","text":"<ul> <li>Autenticarse: <code>AUTH contrasinal</code></li> <li>Probar se estamos conectados: <code>PING</code></li> <li>Almacenar unha clave (KEY-VALUE): <code>set clave valor</code></li> <li>Recuperar unha clave: <code>get clave</code></li> <li>Establecer ou mudar o contrasinal: <code>config set requirepass 123quetal123</code></li> <li>Crear un usuario: <code>acl setuser ...</code></li> <li>Pedir clave no CLI: <code>config set requirepass 123quetal123</code></li> </ul>"},{"location":"docker-3-redis/#uso-con-python","title":"Uso con Python","text":"<p>Instalar as librar\u00edas con conda para poder conectar a redis:</p> <pre><code>!conda install -y -c conda-forge redis-py sqlalchemy\n</code></pre> <p>C\u00f3digo de python:</p> redis.py<pre><code>#from redis import Redis\nempregamos_docker=True\n\nimport redis\n\ndata = {\n    'dog': {\n        'scientific-name' : 'Canis familiaris'\n    }\n}\n\nr = redis.Redis(password=\"123quetal123\")\n#r.auth(\"123quetal123\")\nr.ping()\n#Non instalado no escenario a extensi\u00f3n JSON\n\nif (empregamos_docker):\n    r.json().set('doc', '$', data)\n    doc = r.json().get('doc', '$')\n    dog = r.json().get('doc', '$.dog')\n    scientific_name = r.json().get('doc', '$..scientific-name')\n    print(scientific_name)\n</code></pre> <p>Podes descargar o notebook de:</p> <ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/redis.ipynb</li> </ul>"},{"location":"docker-4-postgresql/","title":"\ud83e\uddfe PostgreSQL","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/_/postgres</li> </ul>"},{"location":"docker-4-postgresql/#instalacion-co-docker","title":"Instalaci\u00f3n co docker","text":"<pre><code>docker run --name de-postre-sql -e POSTGRES_PASSWORD=Cl431Ns3gur4 \\\n    -p 5432:5432 -p 5433:5433 -d postgres\n</code></pre> <p>Se non che funciona a conexi\u00f3n dende o exterior, cambia o porto a outro que non sexa co\u00f1ecido. Alg\u00fans servizos poden bloquear, por seguridade, portos co\u00f1ecidos.</p>"},{"location":"docker-4-postgresql/#conexion-simple-co-cliente-nativo","title":"Conexi\u00f3n simple co cliente nativo","text":"<pre><code>docker exec -it de-postre-sql psql -U postgres\n</code></pre>"},{"location":"docker-4-postgresql/#comandos-utiles","title":"Comandos \u00fatiles","text":"<p>Amosar bases de datos</p> <pre><code>\\l\n</code></pre> <p>Seleccionar base de datos a empregar</p> <pre><code>\\c postgres\n</code></pre> <p>Amosar t\u00e1boas</p> <pre><code>\\dt\n</code></pre> <p>Crear base de datos</p> <pre><code>CREATE DATABASE sobremesa;\n</code></pre> <p>Crear un usuario</p> <pre><code>CREATE USER lambon WITH PASSWORD 'Fl4nD3C4f3';\n</code></pre> <p>Dar permisos</p> <p>Damos os permisos sobre a BBDD ao usuario:</p> <pre><code>GRANT ALL PRIVILEGES ON DATABASE sobremesa to lambon;\n</code></pre> <p>Conectamos \u00e1 base de datos:</p> <pre><code>\\c sobremesa\n</code></pre> <p>Damos permiso ao esquema public:</p> <pre><code>GRANT ALL ON SCHEMA public TO lambon;\n</code></pre> <p>Conectar co usuario, contrasinal e BBDD creadas</p> <p>Se temos aberta a conexi\u00f3n \u00e1 BBDD, pech\u00e1mola.</p> <pre><code>docker exec -it de-postre-sql \\\n    psql postgresql://lambon:Fl4nD3C4f3@localhost/sobremesa\n</code></pre>"},{"location":"docker-4-postgresql/#conexion-dende-python","title":"Conexi\u00f3n dende Python","text":"<ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/postgresql-psycopg2-sqlalchemy.ipynb</li> </ul>"},{"location":"docker-4-postgresql/#mais-informacion","title":"M\u00e1is informaci\u00f3n","text":"<ul> <li>https://www.postgresql.org/</li> <li>https://www.w3schools.com/postgresql/index.php</li> <li>https://www.postgresql.org/docs/current/datatype.html</li> </ul>"},{"location":"docker-5-mssql-server/","title":"\ud83e\uddfe Microsoft SQL Server","text":""},{"location":"docker-5-mssql-server/#microsoft-sql-server-en-ubuntu-con-docker","title":"Microsoft SQL Server en Ubuntu (con docker).","text":"<ul> <li>Baseado na imaxe oficial: https://hub.docker.com/_/microsoft-mssql-server</li> </ul>"},{"location":"docker-5-mssql-server/#instalacion-con-docker","title":"Instalaci\u00f3n con docker","text":"<pre><code>docker run \\\n -e \"ACCEPT_EULA=Y\" \\\n -e \"MSSQL_SA_PASSWORD=Abc12300\" \\\n -e \"MSSQL_PID=Evaluation\" \\\n -p 41433:1433  \\\n --name sqlpreview \\\n --hostname sqlpreview \\\n -d mcr.microsoft.com/mssql/server:2022-preview-ubuntu-22.04\n</code></pre>"},{"location":"docker-5-mssql-server/#datos-de-conexion","title":"Datos de conexi\u00f3n","text":"<ul> <li>Usuario por defecto (admin): sa</li> <li>Contrasinal de exemplo: Abc12300. Advertencia: O contrasinal debe ter alomenos unha letra mai\u00fascula, unha min\u00fascula, un n\u00famero e alomenos oito caracteres, do contrario o docker finalizar\u00e1.</li> <li>Porto ao que conectarse de forma exterior: <code>41433</code>: El\u00edxese este porto posto que o habitual <code>1433</code> est\u00e1 bloqueado no contorno que empregamos por alg\u00fans filtros autom\u00e1ticos que non se pode abrir no grupo de seguridade.</li> <li>Existe o cliente: mssql-cli que se pode instalar con pip:</li> </ul> <pre><code>pip install mssql-cli\npip install --upgrade cli_helpers\npip install --upgrade tabulate\nexport DOTNET_SYSTEM_GLOBALIZATION_INVARIANT=true\n</code></pre>"},{"location":"docker-5-mssql-server/#como-conectar-dende-python","title":"C\u00f3mo conectar dende Python","text":"<ul> <li>https://github.com/jfsanchez/SBD/blob/main/notebooks/bbdd/mssql-pyodbc.ipynb</li> </ul>"},{"location":"docker-6-oracle/","title":"\ud83e\uddfe Oracle Free","text":"<p>\u26a0\ufe0f AVISO: Apuntes en elaboraci\u00f3n. Incompletos.</p> <ul> <li>Baseado en: https://www.oracle.com/es/database/free/get-started/</li> </ul>"},{"location":"docker-6-oracle/#1-instalacion","title":"1. Instalaci\u00f3n","text":""},{"location":"docker-6-oracle/#11-baixar-a-imaxe","title":"1.1. Baixar a imaxe","text":"<pre><code>docker pull container-registry.oracle.com/database/free:latest\n</code></pre>"},{"location":"docker-6-oracle/#12-executar-o-contenedor","title":"1.2. Executar o contenedor","text":"<pre><code>docker run -p 5560:5560 -d --name oracle_free \\\n    container-registry.oracle.com/database/free\n</code></pre>"},{"location":"docker-6-oracle/#2-conexion","title":"2. Conexi\u00f3n","text":"<pre><code>docker exec -it oracle_free sqlplus / as sysdba\n</code></pre> <p>Para conectar a Oracle, dependendo se o temos instalado directamente ou nun docker, podemos empregar os seguintes comandos.</p>"},{"location":"docker-6-oracle/#3-comandos-para-conexion-directa","title":"3. Comandos para conexi\u00f3n directa:","text":"<pre><code>sqlplus sys@localhost:1521/FREEPDB1 as sysdba\nsqlplus sys@localhost:1521/FREE as sysdba\n</code></pre>"},{"location":"docker-6-oracle/#4-comandos-para-docker","title":"4. Comandos para docker:","text":"<pre><code>docker exec -it dbname sqlplus / as sysdba\ndocker exec -it dbname sqlplus sys/cdb-user-password@cdb-sid as sysdba\ndocker exec -it dbname sqlplus system/cdb-user-password@cdb-sid\ndocker exec -it dbname sqlplus pdbadmin/pdb-user-password@pdbname\n</code></pre>"},{"location":"docker-6-oracle/#5-exemplo-de-creacion-de-usuario-e-asignacion-de-permisos","title":"5. Exemplo de creaci\u00f3n de usuario e asignaci\u00f3n de permisos","text":"<pre><code>CREATE USER oraclefreeuser\n  IDENTIFIED BY Abc12300 \n  DEFAULT TABLESPACE tablespace\n  TEMPORARY TABLESPACE tbs_temp_01\n  QUOTA UNLIMITED on tablespace;\n</code></pre> <pre><code>GRANT CREATE VIEW, CREATE PROCEDURE,\n    CREATE SEQUENCE, CREATE TRIGGER to oraclefreeuser;\n\nGRANT ALTER ANY TABLE to oraclefreeuser;\nGRANT ALTER ANY PROCEDURE to oraclefreeuser;\nGRANT ALTER ANY TRIGGER to oraclefreeuser;\nGRANT DELETE ANY TABLE to oraclefreeuser;\nGRANT DROP ANY PROCEDURE to oraclefreeuser;\nGRANT DROP ANY TRIGGER to oraclefreeuser;\nGRANT DROP ANY VIEW to oraclefreeuser;\nGRANT CREATE TABLE to oraclefreeuser;\n</code></pre> <ul> <li>M\u00e1is informaci\u00f3n sobre a creaci\u00f3n de usuarios: https://blog.devart.com/how-to-create-oracle-user.html</li> </ul>"},{"location":"docker-6-oracle/#6-conexion-dende-python","title":"6. Conexi\u00f3n dende Python","text":"oracle.py<pre><code>import oracledb\n\nconn = oracledb.connect(user=\"[Username]\", password=\"[Password]\", \\\n                             dsn=\"localhost:1521/FREEPDB1\")\nwith conn.cursor() as cur:\n   cur.execute(\"SELECT 'Hello World!' FROM dual\")\n   res = cur.fetchall()\n   print(res)\n</code></pre>"},{"location":"docker-6-oracle/#7-limitacions-de-oracle-free","title":"7. Limitaci\u00f3ns de Oracle Free:","text":"<ul> <li>Uso m\u00e1ximo de memoria RAM: 2 GB</li> <li>Cores que emprega como m\u00e1ximo: 2</li> <li>Tama\u00f1o m\u00e1ximo de BD: 12 GB</li> <li>Unha soa instancia por medio l\u00f3xico.</li> </ul>"},{"location":"docker-6-oracle/#8-mais-informacion","title":"8. M\u00e1is informaci\u00f3n:","text":"<ul> <li>https://www.oracle.com/es/database/free/get-started/</li> <li>https://docs.oracle.com/en/database/oracle/oracle-database/21/deeck/index.html</li> <li>https://docs.oracle.com/en/database/oracle/oracle-database/23/xeinl/licensing-restrictions.html</li> </ul>"},{"location":"docker-7-kafka/","title":"\ud83e\uddfe Kafka","text":"<p>\u26a0\ufe0f AVISO: Apuntes en elaboraci\u00f3n. Incompletos.</p> <ul> <li>Baseado na imaxe oficial: https://hub.docker.com/r/apache/kafka</li> </ul>"},{"location":"docker-7-kafka/#creando-o-contedor","title":"Creando o contedor","text":"<p>Lanzamos un novo contedor kafkiano que escoita no porto 9092.</p> <pre><code>docker run -d  \\\n  --name kafkiano \\\n  -p 9092:9092 -p 9093:9093 \\\n  -e KAFKA_NODE_ID=1 \\\n  -e KAFKA_PROCESS_ROLES=broker,controller \\\n  -e KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \\\n  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \\\n  -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \\\n  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \\\n  -e KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 \\\n  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \\\n  -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \\\n  -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \\\n  -e KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0 \\\n  -e KAFKA_NUM_PARTITIONS=3 \\\n  --restart unless-stopped \\\n  apache/kafka:latest\n</code></pre>"},{"location":"docker-7-kafka/#creando-un-topic","title":"Creando un topic","text":"<p>Empregando o script <code>kafka-topics.sh</code> crearemos o topic (tema) topicprimeiro.</p> <pre><code>docker exec -it kafkiano \\\n  /opt/kafka/bin/kafka-topics.sh \\\n  --bootstrap-server localhost:9092 \\\n  --create --topic topicprimeiro\n</code></pre>"},{"location":"docker-7-kafka/#escribindo-mensaxes-ao-topic-produtor","title":"Escribindo mensaxes ao topic (produtor)","text":"<p>Imos escribir unha serie de mensaxes no produtor, a\u00ednda que ningu\u00e9n estea suscrito ao topic consumindo estes datos. Para lanzar un produtor (enviar datos a Kafka) empregamos o producer de consola de dentro do contedor:</p> <p><pre><code>docker exec -it kafkiano \\\n    /opt/kafka/bin/kafka-console-producer.sh \\\n    --bootstrap-server localhost:9092 \\\n    --topic topicprimeiro\n</code></pre> Agora poderemos escribir alg\u00fans textos, por exemplo:</p> <pre><code>Hola Mundo!\nClave=Valor\n1234567890\nabc\n</code></pre> <p>Se queremos sair da consola, premeremos Ctrl+C.</p>"},{"location":"docker-7-kafka/#recibindo-mensaxes-consumidor","title":"Recibindo mensaxes (consumidor)","text":"<p>Os datos anteriores seguen en Kafka e podemos ter acceso ao topic dende o inicio do mesmo:</p> <pre><code>docker exec --interactive -it kafkiano \\\n    /opt/kafka/bin/kafka-console-consumer.sh \\\n    --bootstrap-server localhost:9092 \\\n    --topic topicprimeiro \\\n    --from-beginning\n</code></pre> <p>Se deixamos aberta esta consola e noutra lanzamos un produtor que env\u00ede datos ao topicprimeiro, deber\u00edan reflectirse nesta primeira consola en pouco tempo.</p>"},{"location":"docker-7-kafka/#traballando-en-python-con-apache-kafka","title":"Traballando en Python con Apache Kafka","text":""},{"location":"docker-7-kafka/#ligazons-a-mais-informacion","title":"Ligaz\u00f3ns a m\u00e1is informaci\u00f3n","text":""},{"location":"docker-7-kafka/#descargas-oficiais-do-software","title":"Descargas oficiais do software","text":"<ul> <li>http://kafka.apache.org</li> <li>https://hub.docker.com/r/apache/kafka</li> </ul>"},{"location":"docker-7-kafka/#librarias-de-conexion-en-python","title":"Librar\u00edas de conexi\u00f3n en Python","text":"<ul> <li>https://github.com/dpkp/kafka-python</li> <li>https://github.com/confluentinc/confluent-kafka-python</li> </ul>"},{"location":"docker-7-kafka/#outros","title":"Outros","text":"<ul> <li>https://developer.confluent.io/get-started/python</li> </ul>"},{"location":"docker-8-apache-nifi/","title":"\ud83e\uddfe Apache Nifi","text":""},{"location":"docker-8-apache-nifi/#apache-nifi-empregando-docker","title":"Apache Nifi empregando Docker","text":"<ul> <li>Baseado no repositorio do proxecto Apache coa imaxe \"non\" oficial de Apache Nifi: https://hub.docker.com/r/apache/nifi/</li> </ul>"},{"location":"docker-8-apache-nifi/#instalacion-con-docker","title":"Instalaci\u00f3n con docker","text":"<pre><code>docker run --name nifi \\\n  -p 8443:8443 \\\n  -d \\\n  -e SINGLE_USER_CREDENTIALS_USERNAME=admin \\\n  -e SINGLE_USER_CREDENTIALS_PASSWORD=EsteEunContrasinalMoiLongo1234567890 \\\n  apache/nifi:latest\n</code></pre>"},{"location":"docker-8-apache-nifi/#datos-de-conexion","title":"Datos de conexi\u00f3n","text":"<ul> <li>Usuario por defecto: admin</li> <li>Contrasinal de exemplo: EsteEunContrasinalMoiLongo1234567890</li> <li>Emprega https para conectar. Exemplo: https://localhost:8443</li> </ul>"},{"location":"docker-z-guia-refinitiva/","title":"\ud83d\udcd8 Docker: La gu\u00eda \"re\"finitiva","text":"<p>\u26a0\ufe0f \u26a0\ufe0f \u26a0\ufe0f Esta gu\u00eda est\u00e1 desordenada, es el resultado de varios cursos, investigaci\u00f3n por mi cuenta e ir apuntando pasos. La idea es ir orden\u00e1ndola poco a poco. Puede contener errores, repeticiones y no ser exacta.</p>"},{"location":"docker-z-guia-refinitiva/#componentes","title":"Componentes","text":"<ul> <li>Docker Host: M\u00e1quina que ejecutar\u00e1 docker.</li> <li>Docker CLI: Cliente con el que conectamos y administramos dockers.</li> <li>Rest API: Permite administrar docker con peticiones GET/POST.</li> <li>Docker Daemon: El servidor de docker.</li> </ul>"},{"location":"docker-z-guia-refinitiva/#contenedores","title":"Contenedores","text":"<p>Un contenedor es una capa donde se ejecutan las im\u00e1genes.</p> <p>Las im\u00e1genes son la base del sistema, se las supone stateless (sin estado) y se usan para desplegar varios contenedores. Una imagen es de s\u00f3lo lectura mientras que el contenedor permite escritura.</p> <p>Un contenedor es temporal. Si queremos guardar los cambios necesitamos un volumen de datos. Adem\u00e1s de RAM y procesador, un contenedor puede emplear: Im\u00e1genes, vol\u00famenes y redes.</p> <p>Los vol\u00famenes permiten almacenar informaci\u00f3n a los contenedores. Esta informaci\u00f3n no deber\u00eda almacenarse directamente en el contenedor, ya que de borrarse, se eliminar\u00edan los datos.</p> <p>Un contenedor puede tener acceso a todos los procesadores y RAM del host (por defecto) o se pueden establecer l\u00edmites.</p> <p>Pueden crearse varias redes para relacionar unos contenedores con otros. Un docker puede estar en una o varias redes.</p>"},{"location":"docker-z-guia-refinitiva/#ejemplo-lanzar-el-servidor-de-bbdd-mariadb-oficial","title":"Ejemplo: Lanzar el servidor de BBDD MariaDB oficial","text":"<pre><code>    docker run --detach --name maria1 --env MARIADB_USER=unusuario \\\n    --env MARIADB_PASSWORD=unacontrasena \\\n    --env MARIADB_ROOT_PASSWORD=clavederoot \\\n    mariadb:latest\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#asociar-una-carpeta-local-a-una-carpeta-del-contenedor","title":"Asociar una carpeta local a una carpeta del contenedor","text":"<p>Por ejemplo: <code>/tmp/mariadatos</code> al <code>/var/lib/mysql</code> del docker</p> <p>Este ejemplo crea un contenedor con la \u00faltima versi\u00f3n de mariadb y por medio de las variables de entorno que permite su imagen, le pasa un usuario, una clave, una clave de administrador y asocia una carpeta de nuestro host dentro del contenedor.</p> <pre><code>    docker run -v /tmp/mariadatos:/var/lib/mysql/ --detach \\\n    --name maria2 --env MARIADB_USER=unusuario \\\n    --env MARIADB_PASSWORD=unacontrasena \\\n    --env MARIADB_ROOT_PASSWORD=clavederoot \\\n    mariadb:latest\n</code></pre> <p>Comando <code>run</code>:</p> <p>Descarga una imagen (si no existe) y crea e inicia el contenedor.</p> <p>Opci\u00f3n <code>--detach</code>:</p> <p>Libera la terminal, no nos deja la consola bloqueada, lo pasa a segundo plano.</p> <p>Pasar una variable de entorno:</p> <pre><code>    docker exec -e var='value' CONTENEDOR COMANDO\n</code></pre> <p>Leyenda: -e: Environment.</p>"},{"location":"docker-z-guia-refinitiva/#asociar-carpeta-del-contenedor-a-un-volumen","title":"Asociar carpeta del contenedor a un volumen","text":"<pre><code>    docker run -v VOLUMENNUEVO:/var/lib/mysql/ \\\n    --detach --name maria3 \\\n    --env MARIADB_USER=unusuario \\\n    --env MARIADB_PASSWORD=unacontrasena \\\n    --env MARIADB_ROOT_PASSWORD=clavederoot \\\n    mariadb:latest\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#volumenes","title":"Vol\u00famenes","text":"<p>Existen tres tipos b\u00e1sicos de vol\u00famenes:</p> <ul> <li>Vol\u00famenes Host.</li> <li>Vol\u00famenes an\u00f3nimos.</li> <li>Vol\u00famenes nombrados.</li> </ul> <p>Por defecto se guardan en: <code>/var/lib/docker/volumes</code></p> <p>Conviene acceder a ellos s\u00f3lo con herramientas de docker. https://docs.docker.com/storage/volumes/</p> <p>Comandos \u00fatiles (se ver\u00e1n de nuevo en los ejemplos) <pre><code>    docker volume ls\n    docker inspect VOLUMEN\n</code></pre></p> <p>Por defecto emplearemos el driver <code>local</code> para los vol\u00famenes, sin embargo hay otras opciones como flocker o convoy con opciones interesantes. Por ejemplo: Sacar snapshots del volumen de datos.</p> <p>Se permiten pasar opciones a <code>volume</code> para especificar tama\u00f1o (o guardar el volumen de forma vol\u00e1til con tmpfs)</p>"},{"location":"docker-z-guia-refinitiva/#nombrado","title":"Nombrado","text":"<p>Para acceder a los contendores o bien podemos referirnos por su nombre (crea un nombre aleatorio si no le especificamos uno con <code>--name</code>) o por su <code>CONTAINER ID</code>. En el caso del <code>CONTAINER ID</code> podemos escribir tan s\u00f3lo los dos o tres primeros caracteres (siempre que no haya otro contenedor en el que coincidan estos y con ello se pueda inferir inequ\u00edvocamente el contenedor referenciado).</p>"},{"location":"docker-z-guia-refinitiva/#ejemplos-de-comandos-basicos","title":"Ejemplos de comandos b\u00e1sicos","text":"<p>En CONTENEDOR puede valer el nombre asignado o los primeros d\u00edgitos/letras de su identificador \u00bfCuantos caracteres hay que poner del identificador? F\u00e1cil, tantos como permitan identificarlo de forma \u00fanica.</p>"},{"location":"docker-z-guia-refinitiva/#listar-volumenes","title":"Listar vol\u00famenes:","text":"<pre><code>    docker volume ls\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#listar-imagenes","title":"Listar im\u00e1genes:","text":"<pre><code>    docker image ls\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#listar-contenedores-en-ejecucion-opciones","title":"Listar contenedores (en ejecuci\u00f3n). Opciones:","text":"<pre><code>    docker ps\n    docker container ls\n    docker container ps\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#listar-contenedores-en-ejecucion-y-finalizados-opciones","title":"Listar contenedores (en ejecuci\u00f3n y finalizados). Opciones:","text":"<pre><code>    docker ps -a\n    docker container ls -a\n    docker container ps -a\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#parar-un-contenedor","title":"Parar un contenedor:","text":"<pre><code>    docker container stop CONTENEDOR\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#inciar-un-contenedor-que-este-previamente-creado-y-exista","title":"Inciar un contenedor (que est\u00e9 previamente creado y exista):","text":"<pre><code>    docker container start CONTENEDOR\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#volumenes-creacion-explicita","title":"Vol\u00famenes. Creaci\u00f3n expl\u00edcita","text":"<pre><code>    docker volume create mi-volumen\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#volumenes-ver-informacion","title":"Vol\u00famenes. Ver informaci\u00f3n","text":"<pre><code>    docker volume inspect mi-volumen\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#asociar-un-volumen-a-un-contenedor-en-la-creacion-del-contenedor","title":"Asociar un volumen a un contenedor (en la creaci\u00f3n del contenedor)","text":"<pre><code>    docker run -d \\\n      --name entornoDES \\\n      --mount source=mi-volumen,target=/app \\\n      nginx:latest\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#mapearredirigir-un-puerto","title":"Mapear/Redirigir un puerto","text":"<p>Si necesitamos asignar un puerto del anfitri\u00f3n al contenedor, podemos hacerlo con la opci\u00f3n: <code>-p PUERTO_ANFITRI\u00d3N:PUERTO_INVITADO</code>.</p> <pre><code>docker run -it -d -p 3001:3000 imagen/tag\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#borrar-un-contenedor","title":"Borrar un contenedor","text":"<pre><code>    docker container rm CONTENEDOR\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#borrar-un-volumen","title":"Borrar un volumen","text":"<pre><code>    docker volume rm VOLUMEN\n</code></pre> <p>Al borrar un contenedor, por defecto, no se borra el volumen asociado.</p>"},{"location":"docker-z-guia-refinitiva/#borrar-una-imagen","title":"Borrar una imagen","text":"<pre><code>    docker image rm IMAGEN\n</code></pre> <p>Al borrar un contenedor, por defecto, no se borra la imagen asociada a partir de la cual se ha hecho el contenedor.</p> <p>Salvo que forcemos el borrado, no se puede borrar una imagen si tiene asociado alg\u00fan contenedor.</p>"},{"location":"docker-z-guia-refinitiva/#ejecutando-un-comando-dentro-del-contenedor","title":"Ejecutando un comando dentro del contenedor","text":"<p>Una de los casos m\u00e1s t\u00edpicos es ejecutar un bash para cambiar o consultar algo dentro del contenedor.</p> <p>Crear el contenedor y que nos devuelva una terminal:</p> <pre><code>    docker run -it ubuntu:18.04 bash\n</code></pre> <ul> <li><code>-it</code>: nos conecta (attach) a una sesi\u00f3n interactiva de forma que podamos ver e interactuar con ella).</li> <li><code>run</code>: Descarga la imagen, crea el contenedor y lo arranca.</li> </ul> <p>Conectarnos a una terminal de un contenedor ya creado: <pre><code>    docker exec -it CONTENEDOR /bin/bash\n</code></pre></p> <ul> <li><code>exec</code>: Ejecuta el comando /bin/bash en el CONTENEDOR.</li> </ul> <p>En el caso que no necesitemos una sesi\u00f3n interactiva, podemos ejecutar un comando directamente:</p> <pre><code>    docker exec CONTENEDOR ls\n</code></pre> <p>La diferencia entre <code>docker run</code> y <code>docker exec</code> es que <code>docker exec</code> ejecuta el comando que le especifiquemos en un contenedor ya creado y en ejecuci\u00f3n, mientras que <code>docker run</code> crea y ejecuta un contenedor temporal, ejecuta el comando y para el contenedor cuando acaba.</p>"},{"location":"docker-z-guia-refinitiva/#bajar-la-imagen","title":"Bajar la imagen","text":"<p>Este comando baja la imagen sin usarla en ning\u00fan contenedor. Con posterioridad podr\u00e1 ser utilizada.</p> <pre><code>docker pull IMAGEN\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#archivo-dockerfile","title":"Archivo Dockerfile","text":"<p>Ejemplo Dockerfile:</p> <pre><code>FROM node:16-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nESXPOSE 3000\nCMD [\"node\", \"server.js\"]\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#from","title":"FROM","text":"<ul> <li> <p>Inicia una nueva etapa de construcci\u00f3n: <code>FROM &lt;image&gt;[:&lt;tag&gt;][AS &lt;NAME&gt;]</code></p> </li> <li> <p><code>AS &lt;NAME&gt;</code> nombra la etapa de compilaci\u00f3n.</p> </li> <li>Puede aparecer varias veces (varias im\u00e1genes o indicar dependencia).</li> <li>Los tags son opcionales, por defecto <code>latest</code>.</li> </ul> <p>Se pueden tener m\u00faltiples fases de construcci\u00f3n (multistage). Por ejemplo: La primera baja de un repo, baja dependencias, ejecuta maven/ant/compila y la segunda con el resultado generado (por ejemplo un jar) puede construir una imagen m\u00ednima con ese jar y una MV de java para su ejecuci\u00f3n.</p> <p>Es decir, podr\u00edamos en este ejemplo tener una m\u00e1quina para compilar un programa (con todas las dependencias nesarias) y otra con las dependencias m\u00ednimas para ejecutar ese programa.</p>"},{"location":"docker-z-guia-refinitiva/#run","title":"RUN","text":"<p>Ejecuta un comando en la capa actual. Por defecto se emplea: - En GNU/Linux: <code>/bin/sh -c</code> - En Microsoft Windows: <code>cmd /S /C</code></p>"},{"location":"docker-z-guia-refinitiva/#copyadd","title":"COPY/ADD","text":"<p><code>COPY/ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt; ... &lt;dest&gt;</code></p> <ul> <li><code>&lt;src&gt;</code>: El origen del archivo.</li> <li> <p><code>&lt;dest&gt;</code>: Indica la ruta dentro del contenedor.</p> </li> <li> <p>GNU/Linux admite par\u00e1metro <code>chown</code>.</p> </li> <li> <p><code>ADD</code> permite copiar un archivo desde una URL. Si src es un archivo comprimido, lo descomprime en destino.</p> </li> </ul>"},{"location":"docker-z-guia-refinitiva/#entrypoint","title":"ENTRYPOINT","text":"<p>El ejecutable del contenedor Ejemplo: <code>ENTRYPOINT [\"executable\",\"param1\",\"param2\"]</code></p> <p>Si luego hay un CMD, se le pasa al entrypoint.</p>"},{"location":"docker-z-guia-refinitiva/#cmd","title":"CMD","text":"<p>S\u00f3lo puede haber un CMD en el <code>Dockerfile</code>. Si hay m\u00e1s de uno, s\u00f3lo se aplicar\u00e1 el \u00faltimo.</p> <p>Indica el comando que levanta el servicio. Debe levantarse en primer plano para mantener vivo el contenedor.</p> <p>Ejemplo: <code>CMD [\"executable\",\"param1\",\"param2\"]</code></p>"},{"location":"docker-z-guia-refinitiva/#env","title":"ENV","text":"<p>Sirve para indicar variables de entorno con valores por defecto. El usuario puede cambiar estas variables para personalizar los ajustes a su gusto.</p>"},{"location":"docker-z-guia-refinitiva/#otros","title":"Otros","text":"<p>El archivo <code>.dockerignore</code> permite que no se copien al contenedor los archivos y/o directorios especificados como no necesarios para acelerar el proceso de construcci\u00f3n.</p>"},{"location":"docker-z-guia-refinitiva/#contenedores_1","title":"Contenedores","text":"<ul> <li>Variables de entorno: <code>-e</code></li> <li>Limitar recursos</li> </ul> <p>Limitar memoria:  <pre><code>--memory 200m (200 MiB)\n</code></pre></p> <p>Limitar al procesador 0 (el primero):  <pre><code>--cpuset-cpus 0\n</code></pre></p> <p>Renombrar un docker <pre><code>docker rename \n</code></pre></p> <p>Copiar archivos desde/hacia contenedor/host</p> <pre><code>docker cp\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#docker-logs","title":"Docker logs","text":"<p>Nos va a permitir ver los logs de un contenedor. - <code>-f</code> permite verlos en tiempo real - <code>-t</code> a\u00f1ade el timestamp al log (aunque la aplicaci\u00f3n de log no lo haga). \u00datil para tiempos sincronizados.</p>"},{"location":"docker-z-guia-refinitiva/#crear-unha-imagen-a-partir-de-un-contenedor","title":"Crear unha imagen a partir de un contenedor","text":""},{"location":"docker-z-guia-refinitiva/#construir-una-imagen","title":"Construir una imagen","text":"<pre><code>docker build -t imagen/tag .\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#docker-commit","title":"Docker commit","text":"<p>Permite crear una imagen a partir de un contenedor.</p>"},{"location":"docker-z-guia-refinitiva/#ejecutar-una-imagen-en-un-contenedor","title":"Ejecutar una imagen en un contenedor","text":"<pre><code>    docker run -it -d imagen/tag\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#imagenes-propias","title":"Im\u00e1genes propias","text":"<p>Si creas una cuenta en dockerhub puedes subir tu imagen:</p> <pre><code>    docker push imagen/tag\n</code></pre> <p>Con eso puedes bajar la imagen desde cualquier sitio:</p> <pre><code>    docker pull usuario/imagen/tag\n</code></pre> <p>En base a una imagen se pueden crear varios contenedores, por ejemplo:</p> <pre><code>    docker run -it -d -p 3001:3000 imagen/tag\n    docker run -it -d -p 3002:3000 imagen/tag\n</code></pre> <p>Cuando eliminamos un contenedor, su sistema de archivos e informaci\u00f3n tambi\u00e9n son eliminadas.</p> <p>Si se quieren guardar los datos al eliminar el docker, debemos guardar los vol\u00famenes de docker (normalmente se crean mediante opci\u00f3n de forma expl\u00edcita o se puede asociar un directorio).</p> <p>Tambi\u00e9n se pueden crear redes para comunicar distintos dockers entre ellas.</p> <p>Podemos utilizar <code>docker-compose</code> (o <code>docker compose</code>, dependiendo de la versi\u00f3n) cuando queremos que varios contenedores de docker se inicien al mismo tiempo (y adem\u00e1s establecer dependencias entre ellos).</p> <p>Para administrar muchos contenedores, podemos emplear orquestadores (por ejemplo Kubernetes).</p> <p>Ejemplos \u00fatiles de dockers: - Imagen de gitlab: https://docs.gitlab.com/ee/install/docker.html - Imagen de tensorflow/serving: https://www.tensorflow.org/install/docker?hl=es-419</p>"},{"location":"docker-z-guia-refinitiva/#pets-vs-cattle-mascotas-versus-ganado","title":"Pets vs cattle (mascotas versus ganado)","text":"<p>Si un servidor se cae, deber\u00eda ser reemplazo autom\u00e1ticamente y de forma transparente al usuario (los servidores son ganado).</p> <p>Para esto ayuda tener la aplicaci\u00f3n distribu\u00edda en microservicios.</p> <p>Si la ca\u00edda de un servidor origina un problema probablemente tengas una mascota, puesto que seguramente conozcas a ese servidor por su nombre: Afrodita, Zeus, MrBurns... lo mantengas y arregles cuando falla y planifiques su mantenimiento como pieza cr\u00edtica en tu organizaci\u00f3n.</p> <p>Si por el contrario tienes un grupo de servidores sin nombre o con nombres: svr1, svr2... del modo en que se ponen etiquetas en las orejas del ganado, a los que aplicas configuraciones autom\u00e1ticas (probablemente a todos las mismas) cuando uno cae, simplemente lo reemplazas por otro, como el ganado. Ejemplos de esto pueden ser: Clusters NO-SQL, servidores de bigdata, clusters de b\u00fasqueda, etc.</p> <p>Las organizaciones que poseen hardware en sus instalaciones, tienen hoy d\u00eda varios servidores en su rack y necesitan automatizar su instalaci\u00f3n, configuraci\u00f3n y uso. Existen herrameintas como Kubernetes, Pupper, Chef o Ansible que permiten automatizar y sacarle m\u00e1s rendimiento a nuestro ganado.</p> <p>M\u00e1s informaci\u00f3n:</p> <ul> <li>https://www.hava.io/blog/cattle-vs-pets-devops-explained</li> <li>https://www.ilimit.com/blog/orquestracion-cloud-pets-cattles/</li> </ul>"},{"location":"docker-z-guia-refinitiva/#imagenes-de-docker","title":"Im\u00e1genes de docker","text":"<ul> <li>Docker Hub</li> <li>Dockerfile: From, Run, Copy, Add, Entrypoint, Cmd y .dockerignore</li> <li>Danling Images: Im\u00e1genes no referenciadas, sin nombre o tag pero ocupan espacio.</li> </ul>"},{"location":"docker-z-guia-refinitiva/#redes-en-docker","title":"Redes en docker","text":"<p>Existen 5 tipos de driver: - none - bridge - host - macvlan - ipvlan - overlay</p> <p>https://docs.docker.com/network/</p> <p>Por defecto se usa bridge (crea el dispositivo: docker0).\\ No se puede hacer ping por nombre de contenedor (habr\u00e1 que poner la IP).</p> <pre><code>    docker network create NOMBRE --subnet 192.168.0.0/24 --gateway 192.168.0.1\n\n    docker network ls\n\n    docker run -d (--network NOMBRE) nginx (--ip 192.168.0.200) .\n</code></pre> <p>En las redes que nosotros creamos se permite hacer ping por nombre de host.</p> <p>A\u00f1ade contenedor a una red: <pre><code>    docker network connect NOMBRE contenedor\n</code></pre></p>"},{"location":"docker-z-guia-refinitiva/#estadisticas","title":"Estad\u00edsticas","text":"<p>Nos permiten ver estad\u00edsticas del contenedor: RAM, procesador en uso, uso de red y si tienen alg\u00fan l\u00edmite de uso de RAM.</p> <pre><code>    docker stats\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#docker-compose-o-docker-compose","title":"Docker Compose \u00f3 docker-compose","text":"<p>Para organizar/orquestar contenedores. Crear contenedores que trabajen juntos. Es decir, aplicaciones multicontenedor para deplegar r\u00e1pidamente. Usa docker-compose.yml. Emplea formato YAML.</p>"},{"location":"docker-z-guia-refinitiva/#etiquetas-en-docker-composeyml","title":"Etiquetas en docker-compose.yml","text":"<ul> <li>version</li> <li>services</li> <li>volumes</li> <li>networks</li> </ul>"},{"location":"docker-z-guia-refinitiva/#moviendo-dockers","title":"Moviendo dockers","text":"<ul> <li> <p>Opci\u00f3n 1: Exportando e importando <pre><code>    docker export container-name | gzip &gt; container-name.gz\n    zcat container-name.gz | docker import - container-name\n</code></pre></p> </li> <li> <p>Opci\u00f3n 2: Migrando la imagen <pre><code>    docker commit container-id image-name\n</code></pre></p> </li> <li> <p>Opci\u00f3n 3: Salvando y creando im\u00e1genes <pre><code>    docker save image-name &gt; image-name.tar\n\n    cat image-name.tar | docker load\n</code></pre></p> </li> <li> <p>Opci\u00f3n 4: Hacer backup del volumen de datos y restaurarlo <pre><code>    docker run --rm --volumes-from datavolume-name -v $(pwd):/backup image-name tar cvf  backup.tar /path-to-datavolume\n\n    docker run --rm --volumes-from datavolume-name -v $(pwd):/backup image-name bash -c \"cd /path-to-datavolume &amp;&amp; tar xvf /backup/backup.tar --strip 1\"\n</code></pre></p> </li> </ul> <p>Si queremos mover varios todos los dockers, otra opci\u00f3n ser\u00eda copiar el directorio de trabajo de docker:</p> <p><code>/var/lib/docker</code></p> <p>Habr\u00eda que tener en cuenta que debemos:</p> <ol> <li>Tener la misma versi\u00f3n de docker en los host de origen y destino.</li> <li>Preservar los permisos y propietarios de archivos y carpetas.</li> <li>Parar el servicio docker antes de copiar nada: <code>service socker stop</code></li> <li>Si hay otras rutas a carpetas, deben existir, tener los permisos adecuados y asegurarnos que no dan otros problemas.</li> </ol> <p>Lo l\u00f3gico en estos casos es planificar la migraci\u00f3n, probarla y ejecutar finalmente un script de migraci\u00f3n con los pasos necesarios para minimizar el tiempo de esta migraci\u00f3n.</p>"},{"location":"docker-z-guia-refinitiva/#extensiones-para-vscode","title":"Extensiones para VSCODE","text":"<ul> <li>Una extensi\u00f3n para gobernarlas a todas: Remote development</li> <li>https://code.visualstudio.com/remote/advancedcontainers/develop-remote-host</li> <li>https://code.visualstudio.com/docs/devcontainers/containers#installation</li> <li>https://code.visualstudio.com/docs/remote/ssh#_connect-to-a-remote-host</li> </ul>"},{"location":"docker-z-guia-refinitiva/#contenedores-interesantes-para-probar","title":"Contenedores interesantes para probar","text":"<ul> <li>rednode</li> <li>jenkins</li> <li>tensorflow</li> </ul> <p>Ejemplo con docker compose. Moodle:</p> <p>Bajar el <code>docker-compose.yml</code> de moodle hecho por bitnami.</p> <pre><code>curl -sSL https://raw.githubusercontent.com/bitnami/containers/main/bitnami/moodle/docker-compose.yml &gt; docker-compose.yml\n</code></pre> <p>Lanzalo:</p> <pre><code>    docker-compose up -d\n</code></pre>"},{"location":"docker-z-guia-refinitiva/#herramientas-relacionadas-con-dockers","title":"Herramientas relacionadas con dockers","text":"<ul> <li>Docker Desktop: Cliente oficial de docker en modo gr\u00e1fico. Para Windows/Linux/Mac. Es de pago para empresas grandes.</li> <li>Portainer.io: Panel de control web para contenedores (de pago). Gratis 5 contenedores con registro previo</li> <li>Podman.io: \"Sustituto\" de docker. Se ejecuta como programa (y no demonio o servicio). Con o sin root ejecuta los contenedores usando libpod (im\u00e1genes, vol\u00famenes, contenedores \"pod\"). Tambi\u00e9n tiene su versi\u00f3n podman desktop, que es opensource. Mantenido por RedHat. Herramientas relacionadas: Buildah, Skopeo. https://www.redhat.com/es/topics/containers/what-is-podman </li> <li>Rancher Desktop: Cliente open-source para gesti\u00f3n de Containers y Kubernetes para Windows, Linux y Mac.</li> <li>vaultproject.io: Hashicorp vault. Permite almacenar credenciales y usarlas como parte del proceso CD/CI para no tener que almacenarlas en el repositorio directamente.</li> </ul>"},{"location":"docker-z-guia-refinitiva/#plonk-stack","title":"PLONK Stack","text":"<p>Consiste en los siguientes elementos:</p> <ul> <li> <p>Prometheus.io: Monitorea y gestiona alertas. Soporta m\u00e9tricas en tiempo real y usa una BBDD con series temporales.</p> </li> <li> <p>Linux:</p> </li> <li> <p>OpenFaaS: \"Function as a service\". Haciendo uso de una arquitectura de microservicios podemos desarrollar, ejecutar y administrar funcionalidades en una aplicaci\u00f3n olvid\u00e1ndonos de la parte de la infraestructura (\"serverless\"). Ejemplos en los que se puede aplicar esta t\u00e9cnica son: procesos batch (por lotes), procesamiento en stream (flujo), procesos ETL, IoT (Internet de las cosas), apps para m\u00f3viles, aplicaciones web, APIs, etc. La diferencia con PaaS es que el desarrollador/admnistrador ni siquiera debe preocuparse por el escalado o aumentar los servidores.</p> </li> <li> <p>NATS: Mensajer\u00eda de alto rendimiento. Comunica sistemas/procesos/servicios. Partes: NATS Core, Jet Stream.</p> </li> <li> <p>Kubernetes: Orquestador para desplegar los contenedores en servidores.</p> </li> </ul> <p>M\u00e1s informaci\u00f3n: https://www.openfaas.com/blog/plonk-stack/</p>"},{"location":"docker-z-guia-refinitiva/#mirar-tambien","title":"Mirar tambi\u00e9n...","text":"<ul> <li>https://www.youtube.com/watch?v=MIl-LJodYUU</li> <li>https://bobcares.com/blog/move-docker-container-to-another-host/</li> </ul>"},{"location":"nube-0-intro/","title":"\u2601\ufe0f Computaci\u00f3n na nube","text":""},{"location":"nube-0-intro/#que-e-a-computacion-na-nube","title":"Que \u00e9 a computaci\u00f3n na nube","text":"<p>Se executas os teus servizos, programas, m\u00e1quinas virtuais ou contedores en servidores de outros ent\u00f3n \"est\u00e1s nas nubes\". Este uso de servidores remotos en distintas redes que poden estar localizadas en centros de datos en varios pa\u00edses \u00e9 o que co\u00f1ecemos por \"computaci\u00f3n na nube\".</p>"},{"location":"nube-0-intro/#vantaxes","title":"Vantaxes","text":"<ul> <li>Mellor conectividade: Velocidade, latencia, etc.</li> <li>Redundancia e tolerancia a fallos: Moitos fallos de hardware mesmo son imperceptibles.</li> <li>Escalabilidade e flexibilidade: Inversi\u00f3n inicial case cero.</li> <li>Centros de datos ben adaptados: Electricidade, seguridade f\u00edsica, l\u00f3xica, etc.</li> <li>Distintas ubicaci\u00f3ns xeogr\u00e1ficas: Podemos acceder nos proveedores grandes a distintos centros de datos ubicados en t\u00f3dolos continentes para garantir unha boa conectividade.</li> </ul>"},{"location":"nube-0-intro/#desvantaxes","title":"Desvantaxes","text":"<ul> <li>Custos: Manter un gran n\u00famero de recursos a medio/longo prazo \u00e9 moito m\u00e1is caro, incluso contando os custos de persoal. Este punto \u00e9 controvertido, posto que soe dicirse o contrario. Hai que analizar a situaci\u00f3n en cada caso particular e non basearse s\u00f3 nunha opini\u00f3n dun comercial.</li> <li>Protecci\u00f3n de datos: Normalmente os acordos para a protecci\u00f3n de datos, que permiten mover os datos a datacenters de f\u00f3ra de Europa, adoitan ser ef\u00e9meros e esot\u00e9ricos. Exemplos desto son: Safe Harbour e Privacy Seal, que demostran unha vez m\u00e1is a grande diferencia de concepto de protecci\u00f3n de datos e o distinto tratamento entre Europa e EEUU.</li> <li>Dependencia dun terceiro: Cambios de condici\u00f3ns unilaterais, fallos, prohibici\u00f3n de uso dos seus servizos (sic), bloqueos...</li> </ul>"},{"location":"nube-0-intro/#principais-proveedores-de-cloud-computing-computacion-na-nube","title":"Principais proveedores de Cloud Computing / Computaci\u00f3n na nube","text":"<ul> <li>Amazon AWS: https://aws.amazon.com/</li> <li>Microsoft Azure: https://azure.microsoft.com/</li> <li>Google Cloud: https://cloud.google.com/</li> </ul> <p>Segundo varios informes de operadoras, as grandes tecnol\u00f3xicas xeran entre o 55% e o 80% do tr\u00e1fico das redes mundiais. Estes informes adoitan a forma de notas de prensa e poden ofrecer resultados interesados, m\u00e1is probablemente se supere o 50% do tr\u00e1fico mundial total dado o tama\u00f1o destas megacorporaci\u00f3ns.</p> <p>Habitualmente esc\u00f3itase falar do termo GAFAM polos nomes das principais empresas tecnol\u00f3xicas: Google, Apple, Facebook, Amazon e Microsoft para referirse ao tr\u00e1fico e conexi\u00f3ns que prove\u00f1en delas.</p>"},{"location":"nube-0-intro/#platform-as-a-service-paas","title":"Platform as a Service (PaaS)","text":""},{"location":"nube-0-intro/#pago-por-uso-e-usos-idoneos","title":"Pago por uso e usos id\u00f3neos","text":"<p>O prezo da nube pode chegar a ser moi variable e est\u00e1 \u00edntimamente ligado ao uso de recursos. Se ben \u00e9 unha das grandes vantaxes porque non require unha inversi\u00f3n inicial en hardware, redes, acondicionamento, instalaci\u00f3n e persoal, esta vantaxe vaise diluindo co tempo.</p> <p>O uso m\u00e1is adecuado da nube \u00e9 para aquelas operaci\u00f3ns nas que \u00e9 impredecible o uso de recursos e son momentos puntuais. Tam\u00e9n para incrementar puntualmente os recursos ou para garantir un SLA superior ao que obter\u00edamos con servidores in-house.</p> <p>Sen embargo, cando unha empresa co\u00f1ece ben os seus recursos computacionais e ten persoal adicado \u00e9 indiscutible que a nube resulta m\u00e1is cara en pr\u00e1cticamente a totalidade dos escenarios, inclu\u00edndo os custes de persoal. Non todos os escenarios requiren as mesmas consideraci\u00f3ns e o prezo non \u00e9 sempre o elemento determinante \u00e1 hora de escoller entre unha ou outra opci\u00f3n.</p> <p>Outro uso moi adecuado ser\u00eda o de gardar unha copia de seguridade dos datos (cifrada) noutra localizaci\u00f3n. O ideal, se a t\u00faa empresa \u00e9 grande \u00e9 gardar os datos en distintos continentes para garantir o acceso en todo momento.</p> <p>Ante unha cat\u00e1strofe (como a ocorrida nas Torres Xemelgas no 2001) non dependeremos que os nosos datos e servidores estean nunha das Torres e o backup na outra. Tam\u00e9n deber\u00edamos ter en conta maremotos, terremotos e outras cat\u00e1strofes naturais as\u00ed como guerras e a situaci\u00f3n xeopol\u00edtica de onde gardamos os datos.</p> <p>Se temos adem\u00e1is unha copia dos datos na nube, outra vantaxe \u00e9 poder levantar as m\u00e1quinas necesarias en pouco tempo (se temos implementado e practicado un plan de continxencias) para continuar cos servizos. Evidentemente falamos de empresas grandes e que normalmente act\u00faan en varios pa\u00edses.</p> <p>Normalmente os servizos de virtualizaci\u00f3n na nube cobran polo uso de recursos: Procesador, memoria RAM, tr\u00e1fico de rede entrante e sa\u00ednte, GPU, almacenamento de datos, operaci\u00f3ns de lectura/escritura sobre eles...</p> <p>Non sempre precisamos todos os servizos activos, polo que se queremos aforrar custos, debemos reducir recursos. Unha boa idea se non precisamos as m\u00e1quinas \u00e9 destruilas e gardar os volumes de almacenamento ou os datos, tendo en conta o tempo que leva levantar unha m\u00e1quina cos servizos activos de novo.</p>"},{"location":"nube-0-intro/#nomes-dos-servizos-mais-habituais","title":"Nomes dos servizos m\u00e1is habituais","text":"<p>As correspondencias cos nomes poden non ser exactas xa que as veces o concepto cambia un pouco (sobre todo cos nomes xen\u00e9ricos por nomearse varias alternativas).</p> <ul> <li> <p>Computaci\u00f3n (CPU+RAM):</p> <ul> <li>Amazon Web Services (AWS):<ul> <li>Amazon EC2: Amazon Elastic Compute Cloud.</li> <li>Lightsail: Tipo VPS (Virtual Private Server). Facturaci\u00f3n simplificada, elecci\u00f3n limitada.</li> </ul> </li> <li>Google Cloud Platform (GCP):<ul> <li>GCE: Google Compute Engine.</li> </ul> </li> <li>Microsoft Azure:<ul> <li>Azure Virtual Machine / M\u00e1quina Virtual.</li> </ul> </li> <li>OpenStack / Nome xen\u00e9rico:<ul> <li>Instancia / M\u00e1quina Virtual.</li> <li>Contedor.</li> </ul> </li> </ul> </li> <li> <p>Almacenamento:</p> <ul> <li>Amazon Web Services (AWS):<ul> <li>EBS en instancias.</li> <li>S3 Obxectos de almacenamento.</li> <li>Glacier Obxectos de almacenamento con menor redundancia e de acceso lento.</li> </ul> </li> <li>Google Cloud Platform (GCP):<ul> <li>Persistent Disk / Durable Block Storage</li> <li>Cloud Storage.</li> </ul> </li> <li>Microsoft Azure:<ul> <li>Azure Blob Storage.</li> </ul> </li> <li>OpenStack / Nome xen\u00e9rico:<ul> <li>Object Storage (tam\u00e9n pode configurarse algo similar a un \"Cold Storage\").</li> <li>Block/Volume Storage (snapshots...).</li> </ul> </li> </ul> </li> </ul> <p>Hai un mont\u00f3n de servizos m\u00e1is con nomes comerciais baseados en soluci\u00f3ns de software co\u00f1ecidas. Tr\u00e1tase de vender unha soluci\u00f3n con procesamento para case cada nicho de mercado: IA, colas, DNS, Bases de Datos, etc. Cada proveedor tenta po\u00f1erlle os seus propios nomes.</p>"},{"location":"nube-0-intro/#alternativas","title":"Alternativas","text":"<ul> <li>As soluci\u00f3ns in-house (servidores f\u00edsicos na oficina ou en centro propio).</li> <li>Montar a t\u00faa propia nube:<ul> <li>Openstack</li> <li>Citrix CloudPlatform</li> <li>Eucalyptus</li> <li>Microsoft Azure Stack</li> <li>Red Hat OpenShift</li> <li>VMware vSphere</li> </ul> </li> </ul>"},{"location":"nube-0-intro/#a-nube-en-europa-cloud-en-europa","title":"A nube en Europa / Cloud en Europa","text":"<p>Europa trata de reducir a dependencia das grandes tecnol\u00f3xicas estadounidenses.</p> <ul> <li>ComputerHoy: O poder das grandes tecnol\u00f3xicas</li> <li>El Pa\u00eds: A UE blind\u00e1ndose contra as tecnol\u00f3xicas</li> <li>Informe de Oliver Wyman: EUROPEAN DIGITAL SOVEREIGNTY</li> <li>EU. Cloud Strategy</li> <li>Dataset da penetraci\u00f3n da nube nos distintos pa\u00edses da UE</li> <li>EU. Futures of big tech in Europe. Scenarios and policy implications: Foresight</li> </ul> <p>En China ter\u00e1s o\u00eddo falar seguramente das prohibici\u00f3ns en internet \u00e1s que se enfrentan os seus cidad\u00e1ns e do \"Gran Firewall Chin\u00e9s\". Este movemento dalles tam\u00e9n unha certa vantaxe competitiva e perm\u00edtelles desenvolver os seus propios servizos e redes sociais: QQ, Tiktok, etc.</p> <p>Estamos nunha econom\u00eda global, os prezos da nube dependen da enerx\u00eda, comunicaci\u00f3ns, redes, custos de persoal e pol\u00edticas de cada pa\u00eds. Na ecuaci\u00f3n tam\u00e9n entran os datos.</p> <p>Un dos activos m\u00e1is importantes das empresas son os datos. En Europa e EEUU xogamos en diferentes ligas. Cando os datos son en teor\u00eda dos cidad\u00e1ns (Europa) e non das empresas (EEUU) as empresas en Europa te\u00f1en un menor valor, posto que os datos non son un activo propiedade destas e deben ser m\u00e1is garantistas co seu uso.</p>"},{"location":"nube-0-intro/#proveedores-de-cloud","title":"Proveedores de Cloud","text":""},{"location":"nube-0-intro/#proveedores-de-cloud-computing-en-europa","title":"Proveedores de Cloud Computing en Europa","text":"Empresa Pa\u00eds de orixe Ano de comezo Contabo Alema\u00f1a 2003 Fuga Cloud Holanda 2006 Hetzner Alema\u00f1a 1997 OVH Francia 1999 Scaleway Francia 1999 Server Space Pa\u00edses Baixos 2008 Upcloud Finlandia 2012"},{"location":"nube-0-intro/#outros-proveedores-de-cloud-computing","title":"Outros proveedores de Cloud Computing","text":"Empresa Pa\u00eds de orixe Ano de comezo Cloud Sigma Su\u00edza 2009 Digital Ocean EEUU 2012 Ionos EEUU 1988 (1&amp;1) Linode EEUU 2003 Rack Space EEUU 1998 Vultr EEUU 2014 V2 Cloud Canad\u00e1 2012 <p>/!\\ O ano de comezo pode ser noutras actividades, as empresas m\u00e1is antigas non se adicaron sempre ao cloud e mesmo as modernas tentan sempre pasar por m\u00e1is antigas con trucos cosm\u00e9ticos para que se vexa que levan tempo no sector.</p> <p>Fonte: Elaboraci\u00f3n propia a partir dos datos presentes nas webs das empresas, pode haber erros.</p>"},{"location":"nube-0-intro/#elixindo-unha-compania-de-cloud-computing","title":"Elixindo unha compa\u00f1\u00eda de cloud computing","text":"<p>Elixir unha compa\u00f1\u00eda (ou varias) non \u00e9 tarefa sinxela. Seguramente ter\u00e1s o\u00eddo comentarios de todo tipo. Por exemplo:</p> <p>No caso de OVH ten tido problemas no pasado: incendios e incidentes en materia de datos persoais, adem\u00e1is non ten moi boa publicidade nas comunidades en internet por alg\u00fans erros e formas.</p> <p>Hetzner tam\u00e9n ten tido alg\u00fan problema, parece que moito m\u00e1is limitado coa s\u00faa KonsoleH nalg\u00fans servidores f\u00f3ra de Europa.</p> <p>1&amp;1, agora Ionos tam\u00e9n ten tido mala publicidade por algunhas das s\u00faas pol\u00edticas cos contratos.</p> <p>En xeral non hai empresas exentas de problemas. Se \u00e9 unha empresa grande e aguanta no tempo, vai ter sempre alg\u00fan problema. \u00c9 importante valorar estes incidentes e a s\u00faa resposta \u00e1 hora de elexir un servizo. \u00c9 conveniente mirar foros especializados en estas empresas de servizos, noticias e experiencias.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/","title":"\u2795 OpenStack: Instancias","text":"<p>Imos aprender a lanzar unha ou varias instancias en Openstack, un contorno de nube/cloud empregado en varias empresas e tam\u00e9n no CESGA.</p> <p>Se buscas recuperar unha instancia destru\u00edda en base a un volume gardado, consulta a secci\u00f3n \u2601\ufe0f OpenStack: Volumes \u2192 Como lanzar unha instancia a partir dun volume.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#configuracion-previa","title":"Configuraci\u00f3n previa","text":""},{"location":"nube-1-openstack-crear-lanzar-instancia/#acerca-de-openstack","title":"Acerca de Openstack","text":"<p>Por si tes curiosidade, Openstack ten moitos compo\u00f1entes, imos relacionarnos a trav\u00e9s do interfaz web con todos eles, para que te fagas unha idea:</p> <ul> <li>Horizon: O contorno de usuario (GUI). B\u00e1sicamente o panel de control ou dashboard que manexamos.</li> <li>Keystone: Provee autenticaci\u00f3n mediante diversos mecanismos (como usuario e contrasinal). Soporta: LDAP, OAuth, OpenID Connect, SAML e SQL</li> <li>Nova: Para acceso a recursos de computaci\u00f3n. Unha especie de meta-hypervisor que soporta: KVM, LXC (libvirt), QEMU, VMWare, Virtuozzo, zVM e Ironic. Fonte: docs openstack.</li> <li>Neutron: Xestiona as diferentes redes.</li> <li>Designate: Servizo de DNS.</li> <li>Barbicam: Ofrece almacenamento seguro de chaves, credenciais, certificados X509, chaves de cifrado...</li> <li>Ceilometer: Para monitorizar os recursos e ver que pasa. Saca m\u00e9tricas e garda o emprego hist\u00f3rico de recursos.</li> <li>Cinder: Provee almacenamento en bloques.</li> <li>Glance: Almacena e recupera imaxes do disco da m\u00e1quina virtual. Permite recuperar os datos dende distintas ubicaci\u00f3ns.</li> <li>Ironic: Permite o aprovisionamento de recursos hardware directamente, m\u00e1quinas virtuais ou contedores.</li> <li>Placement: Acceso API ao inventario e uso de recursos. Axuda a outros servizos a aprovisionar recursos.</li> <li>Swift: Permite o almacenamento de obxectos e provee de tolerancia a fallos.</li> <li>Octavia: Balanceador de carga.</li> <li>AODH: Servizo de alarmas. Provee disparadores e regras.</li> <li>Heat: Para orquestaci\u00f3n.</li> <li>Magnum: Fai posible a orquestaci\u00f3n de: Docker Swarm, Kubernetes e Apache Mesos en Openstack. Emprega heat para orquestar o Sistema Operativo.</li> <li>Manilla: Provee de acceso coordinado ou compartido a sistemas de arquivos compartidos ou distribuidos.</li> <li>Trove: Provee de bases de datos como servizo (relacionais e non relacionais).</li> <li>Zaqar: Servizo de mensaxer\u00eda.</li> <li>Mistral: Servizo de workflow/fluxo de traballo. Permite ordear e executar pasos. Xestiona o estado, a orde correta de execuci\u00f3n, paralelismo, sincronizaci\u00f3n e alta dispo\u00f1ibilidade.</li> <li>Zun: Servizo de contendores a trav\u00e9s de API.</li> </ul> <p>Podes atopar m\u00e1is informaci\u00f3n b\u00e1sica no artigo de redhat de informaci\u00f3n b\u00e1sica acerca de Openstack e se queres facer unha instalaci\u00f3n de Openstack, tam\u00e9n podes consultar este outro artigo en ingl\u00e9s de Daniel Persson.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#partes-do-panel-web-horizon","title":"Partes do panel web Horizon","text":"<p>Antes de comezar lembra que debes estar conectado \u00e1 VPN en caso necesario. No caso do CESGA, este panel de control est\u00e1 en: https://cloud.srv.cesga.es noutros casos de empresas que venden o servizo, debes crear o usuario de OpenStack antes de comezar.</p> <p>Inicia sesi\u00f3n no panel de control.</p> <p></p> <p>Se est\u00e1s no contorno do CESGA lembra empregar o dominio <code>hpc</code> e autenticar mediante <code>KeyStone Credentials</code>.</p> <p>ANtes de lanzar unha instancia \u00e9 unha boa pr\u00e1ctica e aforrar\u00e1s traballo se creas antes un par de chaves e defines correctamente un grupo de seguridade.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#creacion-do-par-de-chaves","title":"Creaci\u00f3n do par de chaves","text":"<p>Imos conectar sen contrasinal, cun par de claves p\u00fablica/privada. Podes ler m\u00e1is informaci\u00f3n acerca delas en: \ud83d\udd11 SSH e t\u00faneles. Esta forma de conectar \u00e9 o modo recomendado. Non se recomenda empregar contrasinais para conectar a servidores.</p> <p>Temos d\u00faas formas de crear este par de chaves. O habitual ser\u00eda telas xa creadas e empregar o comando <code>ssh-keygen</code> dende GNU/Linux ou dende PowerShell en Microsoft Windows. Este comando enc\u00e1rgase xa de crear os arquivos de chave p\u00fablica e privada cos permisos adecuados. Despois de creadas, poder\u00edamos subir a chave p\u00fablica (arquivo que rematar\u00e1 en .pub) que estar\u00eda dentro do directorio .ssh do noso directorio de usuario.</p> <p>Sen embargo, desta vez, imos facer que nos autoxenere unha clave SSH o propio panel web. Unha vez iniciemos sesi\u00f3n imos \u00e1: Computaci\u00f3n \u2192 Pares de claves.</p> <p></p> <p>Nesta p\u00e1xina podemos ver a lista de chaves (a parte p\u00fablica) que podemos asociar na creaci\u00f3n de instancias. As chaves que asociemos ser\u00e1n as que se po\u00f1an ao final do arquivo \ud83d\udcc4 $HOME/.ssh/authorized_keys para que poidamos conectar coas instancias que creemos.</p> <p>Se queremos crear un par novo, prememos no bot\u00f3n \"Crear Par de Claves\" e seleccionamos en \"Tipo de clave\" a opci\u00f3n \"Clave SSH\" e en Nombre de Par de Claves un nome calquera que nos sirva para identificar a clave.</p> <p></p> <p>Esto deber\u00eda baixarnos un arquivo co nome que lle te\u00f1amos dado rematado en .pem. Debemos gardalo, xa que cont\u00e9n a chave privada e non se poder\u00e1 volver a baixar. O que se env\u00eda ao servidor \u00e9 a parte p\u00fablica da chave.</p> <p>Podemos ter tantos pares de chaves como queiramos. \u00c9 recomendable empregar ou ben un xestor de chaves como KeepassXC conectado a un axente e sincronizar as chaves entre os equipos que traballemos ou ben xerar unha chave por equipo.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#creacion-do-grupo-de-seguridade","title":"Creaci\u00f3n do grupo de seguridade","text":"<p>Cando lanzamos unha instancia, esta debe ter un firewall. O grupo de seguridade \u00e9 o equivalente na nube a este firewall.</p> <p>Un grupo de seguridade ten un conxunto de regras de filtrado por protocolo, IP de orixe/destino e porto/s. Cada grupo de seguridade pode ter as s\u00faas propias regras.</p> <p>Unha instancia ten alomenos un grupo de seguridade.</p> <p>Imaxinemos un exemplo onde temos servidores de base de datos e servidores web. Probablemente non queiramos expo\u00f1er o porto 3306 dun MySQL a internet, pero si a alg\u00fans servidores web. Neste exemplo poder\u00edamos crear dous grupos de seguridade:</p> <ul> <li> <p>Servidores_web:</p> <ul> <li>Porto TCP 80 entrante aberto a 0.0.0.0/0.</li> <li>Porto TCP 3306 sa\u00ednte aberto a 0.0.0.0/0.</li> <li>Protocolo ICMP aberto a 0.0.0.0/0.</li> <li>Porto TCP 22 aberto a: 172.18.0.1/24.</li> </ul> </li> <li> <p>Servidores_bbdd:</p> <ul> <li>Porto TCP 3306 entrante aberto a 10.133.1.1/24.</li> <li>Protocolo ICMP aberto a 10.133.1.1/24 e 1.2.3.4/32.</li> <li>Porto UDP 1194 aberto a 1.2.3.4/32.</li> <li>Porto TCP 22 aberto a: 172.18.0.1/24.</li> </ul> </li> </ul> <p>Para crear estes dous grupos de seguridade de proba, debemos ir a: Red \u2192 Grupos de Seguridad.</p> <p></p> <p>Prememos no bot\u00f3n: \u2795 Crear grupo de seguridad.</p> <p></p> <p>Por defecto crear\u00e1 d\u00faas regras b\u00e1sicas que permiten todo o tr\u00e1fico sa\u00ednte, pero non o entrante. Hai que ter en conta ambos protocolos de rede: IPv4 e IPv6.</p> <p>.</p> <p>Se queremos engadir unha nova regra, prememos no bot\u00f3n Agregar regla.</p> <p>.</p> <p>Podemos elexir as opci\u00f3ns da direcci\u00f3n (entrante ou sa\u00ednte) porto ou rango de portos e os remotos, que tam\u00e9n poden ser outros grupos de seguridade.</p> <p>Unha vez engadida a regra, podemos borrala, pero non editala.</p>"},{"location":"nube-1-openstack-crear-lanzar-instancia/#lanzando-unha-ou-varias-instancias","title":"Lanzando unha ou varias instancias","text":"<p>Paso a paso</p> <p>Computaci\u00f3n \u2192 Instancias \u2192 Bot\u00f3n \"Lanzar instancia\"</p> <p></p> <p>Paso 1: Nome da instancia, n\u00famero de instancias a lanzar</p> <p></p> <p>Paso 2: Escollendo a imaxe base</p> <p></p> <p>Paso 3: Sabor da instancia (recursos)</p> <p></p> <p>Paso 4: Redes \u00e1s que se conectar\u00e1</p> <p></p> <p>Paso 5: Portos de rede</p> <p></p> <p>Paso 6: Grupos de seguridade</p> <p></p> <p>Paso 7: Autenticaci\u00f3n. Elexindo o par de chaves</p> <p></p> <p>Paso 8: Script de configuraci\u00f3n tras a instalaci\u00f3n</p> <p></p> <p>Paso 9: Grupo de servidores</p> <p></p> <p>Paso 10: Sugerencias de planificaci\u00f3n</p> <p></p> <p>Paso 11: Metadatos e executar instancia</p> <p></p>"},{"location":"nube-2-openstack-volumes/","title":"\ud83d\udcbf OpenStack: Volumes","text":"<p>Normalmente os servizos de virtualizaci\u00f3n na nube cobran polo uso de recursos: Procesador, memoria RAM, rede, GPU, espacio en disco...</p> <p>Non sempre necesitamos todos os servizos activos, polo que se queremos aforrar custos, debemos reducir recursos.</p> <p>Un volume \u00e9 o disco duro virtual onde se almacenan os datos das instancias en OpenStack.</p> <p>Imos ver unhas operaci\u00f3ns b\u00e1sicas sobre volumes en OpenStack empregando o interfaz web Horizon de Nova.</p> <ul> <li>Como cambiarlle o nome do volume a unha instancia.</li> <li>Como asociar/desasociar un volume dunha instancia.</li> <li>Como extender un volume.</li> <li>Como clonar un volume.</li> <li>Como borrar unha instancia.</li> <li>Como lanzar unha instancia a partir dun volume.</li> </ul>"},{"location":"nube-2-openstack-volumes/#como-cambiarlle-o-nome-do-volume-a-unha-instancia","title":"Como cambiarlle o nome do volume a unha instancia.","text":"<p>Non \u00e9 preciso nin desasociar o volume da instancia nin parala para renomear os volumes. Isto \u00e9 \u00fatil para localizalos con posterioridade.</p> <ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos no nome da instancia e nos sair\u00e1 informaci\u00f3n sobre a mesma, imos ao final da p\u00e1xina e veremos os volumes asociados:</p> <p></p> </li> <li> <p>Tras premer no volume ao que queremos cambiarlle o nome, aparecer\u00e1 informaci\u00f3n sobre o mesmo:</p> <p></p> </li> <li> <p>Prememos no bot\u00f3n \"Editar volumen\" e mudamos o nome ao que queiramos, seguidamente confirmamos os cambios no bot\u00f3n azul.</p> <p></p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-asociar-un-volume-a-unha-instancia-en-execucion","title":"Como asociar un volume a unha instancia en execuci\u00f3n.","text":"<ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos na frecha de \"Crear instancia\" da instancia correspondente para que nos apareza o men\u00fa:</p> <p></p> </li> <li> <p>Seleccionamos a opci\u00f3n \"Asociar Volume\", seleccionamos o volume que queremos asociar e prememos no bot\u00f3n azul para confirmar.</p> <p></p> </li> <li> <p>Debemos montar o volume no sistema operativo. Primeiro entramos na instancia (seleccionamos o nome no listado de instancias) e vemos ao final a qu\u00e9 dipositivo virtual se asociou o novo volume, neste caso a <code>/dev/vdb</code></p> <p></p> </li> <li> <p>Mont\u00e1molo co comando mount (ou de ser preciso formateamos). Podemos asegurarnos que exista correctamente dentro da m\u00e1quina o interfaz virtual que vimos previamente no interfaz web co comando <code>lsblk</code> dende unha consola SSH.</p> <p>5.1 Opci\u00f3n 1: Para montar un volume:</p> <pre><code>lsblk\nsudo mkdir /mnt/vdb\nsudo mount /dev/vdb /mnt/vdb\n</code></pre> <p>5.2 Opci\u00f3n 2: Para formatear (borra os datos) dun volume:</p> <pre><code>lsblk\nsudo mkdir /mnt/vdb\nsudo mkfs.ext3 /dev/vdb\nsudo mount /dev/vdb /mnt/vdb\n</code></pre> </li> <li> <p>Asegur\u00e1monos que estea correctamente montado executando o comando <code>mount</code> e vendo que aparece na listaxe.</p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-desasociar-un-volume","title":"Como desasociar un volume","text":"<p>Importante: Se non queres perder datos, lembra apagar a instancia se lle vas a desasociar un volume. A outra opci\u00f3n \u00e9 desmontar previamente o dispositivo.</p> <p>Nota: Non se pode desasociar o volume ra\u00edz (o que cont\u00e9n o sistema operativo) dunha instancia en execuci\u00f3n, para eso deber\u00e1s apagala ou borrala. Se non tes marcada a opci\u00f3n de borrar o volume cando se borre a instancia, o volume non deber\u00eda borrarse polo feito de eliminar a instancia.</p> <p>Imos desasociar un volume adicional.</p> <ol> <li> <p>Buscamos o volume con calquera dos comandos:</p> <ul> <li><code>mount</code></li> <li><code>lsblk</code></li> <li><code>df -h</code></li> </ul> </li> <li> <p>Desmontamos o volume:</p> <pre><code>umount /mnt/vdb\n</code></pre> </li> <li> <p>Imos \u00e1 interfaz web \u21d2 Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos na frecha de \"Crear instancia\" da instancia correspondente para que nos apareza o men\u00fa:</p> <p></p> </li> <li> <p>Seleccionamos a opci\u00f3n \"Desasociar Volume\", seleccionamos o volume que queremos desasociar e prememos no bot\u00f3n azul para confirmar.</p> <p></p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-extender-un-volume","title":"Como extender un volume.","text":"<p>Se o volume \u00e9 de sistema, debemos apagar a m\u00e1quina (realmente p\u00f3dese facer coa instancia encendida e logo reiniciar pero NON \u00e9 recomendable).</p> <ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos no nome da instancia e nos sair\u00e1 informaci\u00f3n sobre a mesma, imos ao final da p\u00e1xina e veremos os volumes asociados:</p> <p></p> </li> <li> <p>Tras premer no volume que queremos extender, aparecer\u00e1 informaci\u00f3n sobre o mesmo:</p> <p></p> </li> <li> <p>Prememos na frecha \u00e1 dereita do bot\u00f3n \"Editar volumen \u2193\" e seleccionamos \"Extender Volumen\".</p> <p></p> </li> <li> <p>Po\u00f1emos o novo tama\u00f1o e confirmamos co bot\u00f3n azul. Finalmente volvemos encender a instancia ou ven a reiniciamos de estar encendida.</p> </li> </ol> <p>Opci\u00f3n: Se non \u00e9 un volume de sistema, debemos desmontalo, cambiar o tama\u00f1o da partici\u00f3n e volvelo montar. Exemplo:</p> <pre><code>lsblk\ndf -h\nsudo umount /mnt/vdb\nsudo e2fsck -f /dev/vdb\nsudo resize2fs /dev/vdb\nsudo mount /dev/vdb /mnt/vdb\nlsblk\ndf -h\n</code></pre>"},{"location":"nube-2-openstack-volumes/#como-clonar-un-volume","title":"Como clonar un volume.","text":"<p>Debe estar o volume desasociado para que non dea problemas e para que nos deixe seleccionalo.</p> <ol> <li> <p>Imos a \"Vol\u00famenes \u21d2 Vol\u00famenes\" e prememos no bot\u00f3n \"Crear\"     </p> </li> <li> <p>No cadro damos un nome ao novo volume, en \"Origen del volumen\" seleccionamos \"Volumen\" e en \"Usar un volumen como origen\" seleccionamos a volume que queremos clonar. Confirmamos premendo no bot\u00f3n azul.</p> <p></p> </li> <li> <p>Tras uns intres xa estar\u00e1 listo o novo volume para asociar a unha instancia ou para crear unha nova instancia baseada nel.</p> </li> </ol>"},{"location":"nube-2-openstack-volumes/#como-borrar-unha-instancia-sen-borrar-o-volume","title":"Como borrar unha instancia sen borrar o volume.","text":"<ul> <li> <p>Opci\u00f3n 1: Est\u00e1 marcado borrar volume: Desasociamos antes o volume e despois borramos a instancia.</p> </li> <li> <p>Opci\u00f3n 2: Non est\u00e1 marcado borrar volume ao borrar a instancia. Simplemente borramos a instancia.</p> </li> </ul>"},{"location":"nube-2-openstack-volumes/#como-lanzar-unha-instancia-a-partir-dun-volume","title":"Como lanzar unha instancia a partir dun volume.","text":"<p>Se destrues unha instancia, por defecto non se destr\u00fae o volume (salvo que as\u00ed o te\u00f1as marcado). Se non vas a empregar a instancia ata a seguinte clase, \u00e9 unha boa pr\u00e1ctica borrala e volvela crear baseada no volume de datos que ti\u00f1a orixinalmente, as\u00ed como moito cambiar\u00e1 a IP. Este m\u00e9todo tam\u00e9n \u00e9 \u00fatil se queremos cambiar o sabor da instancia (CPU/RAM).</p> <ol> <li> <p>Imos a Computaci\u00f3n \u21d2 Instancias:</p> <p></p> </li> <li> <p>Prememos no bot\u00f3n \"Lanzar instancia\".</p> </li> <li> <p>Damos un nome \u00e1 nova instancia e decidimos cantas queremos lanzar (por defecto 1):</p> <p></p> </li> <li> <p>En \"Origen\" debemos marcar en \"Seleccionar Origen de arranque\" a opci\u00f3n \"Volumen\". Logo, abaixo en dispo\u00f1ible podemos buscar o volume que nos interese (que non estea xa asociado a outra m\u00e1quina) e premer no bot\u00f3n co frecha arriba \u2191 para seleccionalo.</p> <p></p> </li> <li> <p>Escollemos un sabor (procesador/RAM) como escoller\u00edamos nunha creaci\u00f3n normal dunha instancia:</p> <p></p> </li> <li> <p>Seleccionamos a rede na que queremos que estea:     </p> </li> <li> <p>Seleccionamos en caso necesario a configuraci\u00f3n en \"Puertos de Red\".     </p> </li> <li> <p>Marcamos o grupo de seguridade que lle queiramos aplicar:     </p> </li> <li> <p>\u00c9 importante seleccionar tam\u00e9n o par de chaves que queiramos meter a maiores dos que xa te\u00f1a. Presta atenci\u00f3n a esta parte, se \u00e9 unha imaxe doutra persoa incluir\u00e1 as chaves p\u00fablicas e privadas e meter\u00e1 as que ti lle indiques a maiores.</p> <p></p> </li> <li> <p>Finalmente prememos en \"Lanzar instancia\" e tras uns intres xa a teremos lanzada co volume seleccionado.</p> </li> </ol>"},{"location":"nube-3-openstack-grupos-seguridade/","title":"\ud83d\udee1\ufe0f OpenStack: Grupos de seguridade","text":"<p>O firewall na nube. Cada grupo de seguridade cont\u00e9n regras.</p> <p>Cada regra pode ser:</p> <ul> <li>Entrante, sa\u00ednte</li> <li>TCP/UDP</li> <li>Un porto ou un rango de portos</li> </ul> <p>En OpenStack acc\u00e9dese a trav\u00e9s do men\u00fa: \"Red\" \u21d2 \"Grupo de Seguridad\".</p> <p>Ollo, nalg\u00fans contornos alg\u00fans portos poden estar pechados debido a outras regras. Por exemplo: Pechar por seguridade os portos RDP ou o 3306 de MySQL e que non se poidan abrir a\u00ednda que se meta expl\u00edcitamente unha regra.</p>"},{"location":"nube-4-openstack-recovey/","title":"\u26c8\ufe0f OpenStack: Recuperaci\u00f3n","text":""},{"location":"nube-4-openstack-recovey/#recuperando-instancias-do-openstack-a-traves-dos-volumes","title":"Recuperando instancias do OpenStack a trav\u00e9s dos volumes","text":"<p>Se te tes quedado fora dunha instancia, sempre podes borrala (sen borrar o volume de datos asociado) e meter ese volume noutra instancia (nova ou existente). Desde esa m\u00e1quina a que tes acceso podes facer os cambios necesarios no volume, por exemplo copiar unha chave SSH ou po\u00f1erlle contrasinal ao usuario co que conectas (esto \u00faltimo \u00e9 inseguro).</p> <p>Un volume non debe estar asociado a outra instancia para poder asocialo (attach). Unha vez est\u00e1 libre, p\u00f3dese asociar a unha instancia en execuci\u00f3n.</p> <pre><code>sudo su\nlsblk # (1)!\nmkdir /mnt/volume-a-recuperar\nmount /dev/DISPOSITIVO /mnt/volume-a-recuperar\n</code></pre> <ol> <li>Este comando serve para averiguar o nome e n\u00famero do dispositivo (o \u00faltimo).</li> </ol>"},{"location":"nube-4-openstack-recovey/#opcion-1-mudando-o-contrasinal-de-usuario","title":"Opci\u00f3n 1: Mudando o contrasinal de usuario","text":"<pre><code>chroot /mnt/volume-a-recuperar /bin/bash\npasswd USUARIO # (1)!\n</code></pre> <ol> <li>En usuario debes po\u00f1er o usuario que empregas para conectar (mudar\u00e1s a clave del).</li> </ol>"},{"location":"nube-4-openstack-recovey/#opcion-2-copiando-a-chave-ssh-ao-authorized_keys","title":"Opci\u00f3n 2: Copiando a chave SSH ao authorized_keys","text":"<pre><code>mkdir /mnt/volume-a-recuperar/home/USUARIO/.ssh/\ncp $HOME/.ssh/id_rsa.pub /mnt/volume-a-recuperar/home/USUARIO/.ssh/\n</code></pre> <p>Emprega os comandos con sentido. Debes adaptalos ao teu caso.</p> <p>Esta t\u00e9cnica p\u00f3dese empregar tam\u00e9n nos servicios de computaci\u00f3n na nube como: Amazon AWS, Google Cloud Services, Microsoft Azure e outros.</p>"},{"location":"nube-5-openstack-crear-swap/","title":"\ud83d\udc22 SWAP en GNU/Linux","text":"<p>A SWAP \u00e9 a memoria virtual en GNU/Linux. Cando se acaba a memoria f\u00edsica, baixanse algunhas p\u00e1xinas de memoria ao almacenamento secundario adicado especialmente a isto.</p> <p>Algunhas veces pode que non chegue esta memoria virtual (ou que non fose configurada). Esto pod\u00e9molo ver co comando:</p> <pre><code>free -m\n</code></pre> <p>Se non vemos swap ou creemos que \u00e9 insuficiente, podemos engadir un arquivo para reservar parte do noso disco a esta memoria secundaria.</p>"},{"location":"nube-5-openstack-crear-swap/#pasos-para-engadir-un-arquivo-swap","title":"Pasos para engadir un arquivo SWAP","text":"<ol> <li>Creamos un arquivo para swap e o formateamos:</li> </ol> <pre><code>dd if=/dev/zero of=/arquivoswap bs=1024K count=4096\nmkswap /arquivoswap\n</code></pre> <ol> <li>Editamos como root o \u00b4/etc/fstab\u00b4. Este ficheiro de configuraci\u00f3n ind\u00edcanos que sistemas de arquivos se usan e se montan no sistema, tanto para o arranque, como para dar permisos de montaxe a usuarios.</li> </ol> <pre><code>sudo nano /etc/fstab\n</code></pre> <ol> <li>Nese arquivo metemos que o arquivo de swap se monte ao arranque:</li> </ol> <pre><code>/arquivoswap none swap sw 0 0\n</code></pre> <p>Curiosidade: Podes saber cando espacio ocupa un arquivo ou directorio co comando: <code>du -hs /directorio/</code></p> <ol> <li>Pon de m\u00e1scara de permisos 0600 ao arquivo /arquivoswap. Emprega o comando chmod. Estes permisos son bastante restrictivos, non queremos que calquer usuario poida acceder a este arquivo:</li> </ol> <pre><code>chmod 0600 /ficherito\n</code></pre> <ol> <li>Gardamos o arquivo e logo montamos t\u00f3dolos arquivos de swap (para non ter que reiniciar a m\u00e1quina):</li> </ol> <pre><code>swapon -a\n</code></pre> <ol> <li>Podemos ver que este espacio de swap foi engadido empregando de novo:</li> </ol> <pre><code>free -m\n</code></pre>"},{"location":"powerbi-0-python/","title":"\ud83d\udd74\ufe0f PowerBi e Python","text":""},{"location":"powerbi-0-python/#crear-un-novo-contorno-de-conda-para-microsoft-powerbi","title":"Crear un novo contorno de conda para Microsoft PowerBi","text":"<pre><code>conda create -n powerbi python=3.11\nconda activate powerbi\nconda install -c conda-forge matplotlib pandas mkl-service\n</code></pre>"},{"location":"powerbi-0-python/#configurar-un-contorno-conda-en-microsoft-powerbi","title":"Configurar un contorno conda en Microsoft PowerBI","text":"<ul> <li>Averiguar cal \u00e9 o directorio do contorno \"powerbi\", por exemplo con comando:</li> </ul> <pre><code>conda env list\n</code></pre> <ul> <li>Ir a: \"Archivo -&gt; Opciones y configuraci\u00f3n -&gt; Opciones\".</li> <li>Imos na parte esquerda, en: \"Creaci\u00f3n de scripts de Python\"</li> <li>En \"Directorios ra\u00edz de Python detectados:\" seleccionamos \"Otros\" e nos aparecer\u00e1 unha caixa para seleccionar un directorio cunha instalaci\u00f3n de Python.</li> <li>En \"Establezca un directorio ra\u00edz para Python\" preme en \"Examinar\" e selecciona o cartafol do contorno de conda que temos averiguado anteriormente.</li> </ul>"},{"location":"powerbi-0-python/#empregar-codigo-en-python-como-orixe-de-datos","title":"Empregar c\u00f3digo en Python como orixe de datos","text":"<ul> <li>Facer click en \"Inicio -&gt; Obtener datos -&gt; M\u00e1s...\"</li> <li>Buscar: \"Script de Python\".</li> <li>Podes empregar este c\u00f3digo como exemplo:</li> </ul> <pre><code>import pandas as pd\ndatos_estudantes = ({\n    'Nomes':[\"Fulano\", \"Mengana\", \"Zutano\", \"Perengana\"],\n    'Pesos' :[83, 56, 90, 60],\n    'Notas':[9, 8, 7, 6]\n        })\ndf = pd.DataFrame(datos_estudantes)\n</code></pre>"},{"location":"powerbi-0-python/#acceso-dende-powerbi-a-hadoop","title":"Acceso dende PowerBi a Hadoop","text":"<p>Podes acceder aos arquivos que estean no HDFS dende PowerBI </p> <p>Ver t\u00f3dolos arquivos:</p> <p>http://X.Y.Z.T:9870/webhdfs/v1/user?op=LISTSTATUS</p> <p>Descargar un arquivo concreto:</p> <p>http://hadoop1:9864/webhdfs/v1/user/oteusuario/arquivo.extension?op=OPEN&amp;namenoderpcaddress=hadoop1:9000&amp;offset=0</p> <p>Cambiar C:\\Windows\\system32\\drivers\\etc\\hosts e meter a IP do master co nome:</p> C:\\Windows\\system32\\drivers\\etc\\hosts<pre><code>10.133.28.88 hadoop1\n</code></pre> <p>Isto \u00e9 necesario porque internamente, cando baixamos un arquivo, por defecto temos configurado que vaia ao nome.</p> <p>Tam\u00e9n pode resultarche interesante:</p> <ul> <li>Expresi\u00f3ns DAX: https://learn.microsoft.com/es-es/dax/</li> <li>WebHDFS: https://hadoop.apache.org/docs/r1.0.4/webhdfs.html</li> </ul>"},{"location":"python-0-conceptos-previos/","title":"\ud83d\uddc2\ufe0f Arquivos en Python","text":""},{"location":"python-0-conceptos-previos/#rutas-absolutas-e-relativas-en-microsoft-windows-e-gnulinux","title":"Rutas absolutas e relativas en Microsoft Windows e GNU/Linux","text":"<p>As\u00ed de xeito r\u00e1pido poder\u00edamos definir:</p> <ul> <li>Ruta absoluta: Ruta completa, todas as indicaci\u00f3ns dende cero para chegar \u00e1 ruta.</li> <li>Ruta relativa: Partindo do directorio actual, as indicaci\u00f3ns para chegar \u00e1 ruta.</li> </ul>"},{"location":"python-0-conceptos-previos/#son-cuestions-de-formato-de-texto","title":"Son cuesti\u00f3ns de formato (de texto)...","text":"<p>Hai diferentes maneiras de po\u00f1er unha ruta (absoluta ou relativa) e que a mesma sexa compatible con Microsoft Windows e GNU/Linux.</p> <p>A m\u00e1is simple \u00e9 po\u00f1endo barras inclinadas / en lugar das invertidas \\</p> <p>No caso de querer empregar barras invertidas, debemos empregar dobre barra invertida para escapar o car\u00e1cter de escape por defecto, que \u00e9 a mesma barra invertida.</p> <p>Exemplo: <code>'C:\\\\Users\\\\USUARIO\\\\Downloads\\\\datasets\\\\proba.csv'</code></p> <p>Adem\u00e1is debemos detectar o sistema se pretendemos que o noso programa funcione en ambos e pretendemos empregar rutas escritas \"a man\".</p> <p>\ud83d\uddd2\ufe0f Nota: En Microsoft Windows poder\u00edamos omitir a letra da unidade nas rutas \u00ababsolutas\u00bb e coller\u00eda por defecto a letra da unidade onde se est\u00e1 a executar o script.</p> <p>\u26a0\ufe0f AVISO: Neste exemplo empregaremos rutas absolutas.</p> <pre><code>import platform\nsistema = platform.system()\n\nif sistema.casefold() == 'Windows'.casefold():\n    path_base='C:/Users/USUARIO/Downloads/datasets/'\nelse:\n    path_base='/home/usuario/Downloads/datasets/'\n</code></pre>"},{"location":"python-0-conceptos-previos/#comparacion-de-cadeas-de-texto","title":"Comparaci\u00f3n de cadeas de texto","text":"<p>\ud83d\udca1 Curiosidade polo m\u00e9todo casefold() empregado no c\u00f3digo de enriba? \u00c9 unha boa pr\u00e1ctica para comparar determinadas cadeas de texto, podes mirar a documentaci\u00f3n en: https://docs.python.org/3/library/stdtypes.html#str.casefold. B\u00e1sicamente ignora as mai\u00fasculas e min\u00fasculas e ten en conta cousas como que a dobre ss no alem\u00e1n pode equivaler \u00e1: \u00df. O algoritmo de casefold est\u00e1 descrito aqu\u00ed: https://www.unicode.org/versions/Unicode15.0.0/ch03.pdf. Se simplemente queres ignorar mai\u00fasculas, podes aplicar un lower() a ambas cadeas.</p> <p>Para engadir subdirectorios \u00e1 ruta, temos varias opci\u00f3ns:</p>"},{"location":"python-0-conceptos-previos/#suma-de-cadeas-de-texto","title":"Suma de cadeas de texto","text":"<pre><code>with open(path_base+'a-coruna.csv') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre> <p>\ud83d\udca1 Curiosidade do que fai o m\u00e9todo rstrip()? B\u00e1sicamente borra os caracteres da cola que lle indiquemos. Se non indicamos ning\u00fan, ent\u00f3n borrar\u00e1 os caracteres que sexan de tipo espacio en branco: espacios ' ', tabuladores '\\t' e novas li\u00f1as '\\n'. https://www.w3schools.com/python/ref_string_rstrip.asp e https://docs.python.org/3/library/stdtypes.html.</p>"},{"location":"python-0-conceptos-previos/#con-ospathjoin","title":"Con os.path.join","text":"<pre><code>import os\n\nwith open(os.path.join(path_base, 'lugo.csv')) as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre> <p>Tam\u00e9n existe a librar\u00eda pathlib: https://docs.python.org/3/library/pathlib.html.</p>"},{"location":"python-0-conceptos-previos/#con-f-string-format-string","title":"Con f-string (format string)","text":"<p>Po\u00f1eremos unha f antes das comillas e logo as variables entre chaves {}:</p> <pre><code>with open(f'{path_base}pontevedra.csv') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#con-r-string-raw-string","title":"Con r-string (raw string)","text":"<p>E se nos po\u00f1emos burros, con r-string tam\u00e9n podemos empregas as barras invertidas sen necesidade de escapalas. O texto non se interpreta, \u00e9 tal cual.</p> <pre><code>with open(r'C:\\Users\\USUARIO\\Downloads\\datasets\\ourense.csv') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#con-fr-string-format-e-raw","title":"Con fr-string (format e raw)","text":"<p>Tam\u00e9n podemos mezclar ambas combinaci\u00f3ns para obter o mellor de ambos mundos.</p> <pre><code>arquivo='ourense.csv'\nwith open(fr'C:\\Users\\USUARIO\\Downloads\\datasets\\{arquivo}') as ficheiro:\n    print(ficheiro.readline().rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#como-crear-un-arquivo-temporal","title":"C\u00f3mo crear un arquivo temporal","text":"<pre><code>import os\nimport tempfile\n\narquivo_temporal = os.path.join(tempfile.mktemp())\nprint(arquivo_temporal)\n</code></pre> <p>Esto daranos unha ruta a un novo arquivo que non existe cun nome que empezar\u00e1 por <code>tmp</code> e logo ter\u00e1 varios caracteres aleatorios. Exemplos: <code>tmp3yas5ei1</code>, <code>tmpvtwvejgk</code>.</p> <p>Dependendo do sistema, crear\u00e1 o arquivo en distintas ubicaci\u00f3ns:</p> <ul> <li>En Microsoft Windows no cartafol: <code>C:\\Users\\USUARIO\\AppData\\Local\\Temp\\</code></li> <li>En GNU/Linux no directorio temporal: <code>/tmp/</code></li> </ul>"},{"location":"python-0-conceptos-previos/#ler-arquivos-modo-simple","title":"Ler arquivos (modo simple)","text":"<pre><code>f = open(\"tmp.txt\", \"r\")\nprint(f.read())\n</code></pre>"},{"location":"python-0-conceptos-previos/#ler-arquivos-por-linas","title":"Ler arquivos por li\u00f1as","text":"<pre><code>ficheiro = open('/tmp/tmp.tmp', 'r')\n\nwhile li\u00f1a := ficheiro.readline():\n    print(li\u00f1a.rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#escribir-e-sobreescribir-nun-arquivo","title":"Escribir (e sobreescribir) nun arquivo","text":"<pre><code>ficheiro = open(\"tmp.txt\", \"w\")\nficheiro.write(\"Hola mundo!\")\nficheiro.close()\n</code></pre>"},{"location":"python-0-conceptos-previos/#como-engadir-contido-ao-final-dun-arquivo","title":"C\u00f3mo engadir contido ao final dun arquivo","text":"<pre><code>## Ler arquivos (modo simple)\nficheiro = open(\"tmp.txt\", \"a\")\nficheiro.write(\"Outra li\u00f1a!\")\nficheiro.close()\n</code></pre>"},{"location":"python-0-conceptos-previos/#manexo-de-erros","title":"\u2757 Manexo de erros","text":"<pre><code>import sys\n\nruta_arquivo=\"/tmp/tmp.tmp\"\n\ntry:\n  ficheiro = open(ruta_arquivo) #Se engado: 'rb' podo abrir o arquivo en binario\nexcept FileNotFoundError:\n    print(f\"Non se pode atopar o arquivo: {ruta_arquivo}.\")\n    sys.exit(1)\nexcept OSError:\n    print(f\"Erro de sistema abrindo o arquivo: {ruta_arquivo}\")\n    sys.exit(1)\nexcept Exception as err:\n    print(f\"Ocorreu un erro desco\u00f1ecido abrindo o arquivo: {ruta_arquivo} Erro: \",repr(err))\n    sys.exit(1)\nelse:\n  while li\u00f1a := ficheiro.readline():\n    print(li\u00f1a.rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#manexo-de-erros-con-with","title":"Manexo de erros con with","text":"<pre><code>ruta_arquivo=\"/tmp/tmp.tmp\"\n\nwith open(ruta_arquivo) as ficheiro:\n    while li\u00f1a := ficheiro.readline():\n        print(li\u00f1a.rstrip())\n</code></pre>"},{"location":"python-0-conceptos-previos/#tipos-de-apertura","title":"Tipos de apertura","text":"<p>No open() podemos especificar principalmente: r (lectura, por defecto), w (escritura), a (append ou engadir ao final) entre outras.</p> <p>Tam\u00e9n podemos abrir o arquivo no modo por defecto que \u00e9 modo texto (t) ou en binario (b)</p> <p>M\u00e1is informaci\u00f3n:</p> <ul> <li>https://www.w3schools.com/python/python_file_write.asp</li> </ul>"},{"location":"python-1-maxias/","title":"\ud83e\ude84 Ipython: Maxias pit\u00f3nicas","text":""},{"location":"python-1-maxias/#e-outras-herbas","title":"E outras herbas","text":"<p>Ipython engade algo de funcionalidade na consola: autocopletado, maxias, etc. \u00c9 un python interactivo. O jupyterlab precisa de ipython e ipykernel para funcionar correctamente.</p> <p>Podemos lanzar unha consola interactiva de iPython con ese mesmo comando:</p> <pre><code>(bigdata) PS C:\\&gt; ipython\nPython 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 8.12.0 -- An enhanced Interactive Python. Type '?' for help.\n</code></pre> <p>Podemos completar ou autocompletar e obter axuda con: TAB, Ctrl+TAB, Ctrl+Espacio...</p> <p>Tam\u00e9n temos dispo\u00f1ibles unha serie de funci\u00f3ns listas para empregar nos notebooks que poden ser moi \u00fatiles: https://ipython.readthedocs.io/en/stable/interactive/magics.html</p> <p>A continuaci\u00f3n veremos algunhas.</p>"},{"location":"python-1-maxias/#time","title":"%time","text":"<p>Perm\u00edtenos medir canto tempo leva unha execuci\u00f3n determinada.</p> <p>Exemplo:</p> <pre><code>import time\nfrom random import randint\n\ndef tarefa_pit\u00f3nica():\n    tempo=randint(1, 10)\n    print(f'Vaime levar: {tempo}')\n    time.sleep(tempo)\n\n%time tarefa_pit\u00f3nica()\n</code></pre>"},{"location":"python-1-maxias/#run","title":"%run","text":"<p>Executa scripts externos. Pode ser moi \u00fatil para preparar unha contorna cos datos, etc.</p> <pre><code>%run holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#load","title":"%load","text":"<p>Amosa o c\u00f3digo e despois o executa</p> <pre><code>%load holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#edit","title":"%edit","text":"<p>Abre o c\u00f3digo para edici\u00f3n e logo permite executalo</p> <pre><code>%edit holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#amosar-axuda-dunha-maxia","title":"Amosar axuda dunha maxia:","text":"<pre><code>%MAXIA??\n</code></pre> <pre><code>%edit??\n</code></pre>"},{"location":"python-1-maxias/#pycat","title":"%pycat","text":"<p>Amosa o c\u00f3digo</p> <pre><code>%pycat holamundo.py\n</code></pre>"},{"location":"python-1-maxias/#who","title":"%who","text":"<p>Amosa as variables en memoria</p> <pre><code>%who\n</code></pre>"},{"location":"python-1-maxias/#reset","title":"%reset","text":"<p>Borra o estado da memoria</p> <pre><code>%reset\n</code></pre>"},{"location":"python-1-maxias/#save","title":"%save","text":"<p>Salva o estado da sesi\u00f3n, \u00e9 dicir, as li\u00f1as que foron executadas.</p> <pre><code>%save C:\\\\Users\\\\USUARIO\\\\sesion.py\n</code></pre>"},{"location":"python-1-maxias/#lsmagic","title":"%lsmagic","text":"<p>Lista as diferentes maxias</p> <pre><code>%lsmagic\n</code></pre>"},{"location":"python-1-maxias/#env","title":"%env","text":"<p>Amosa as variables do sistema</p> <pre><code>%env\n</code></pre>"},{"location":"ssh-0-chaves-tuneles/","title":"\ud83d\udd11 SSH e t\u00faneles","text":"<p>E todo sen cavar nin picar pedra. Con pouco esforzo comprender\u00e1s dunha vez como funciona SSH, os erros m\u00e1is habituais e como facer un t\u00fanel e os tipos que hai. Comprender\u00e1s a potencia que esconden e aprender\u00e1s a explotala.</p>"},{"location":"ssh-0-chaves-tuneles/#que-e-ssh","title":"\u25fc\ufe0f Qu\u00e9 \u00e9 SSH","text":"<p>Un protocolo cifrado (Secure SHell) para conectar cun servidor e poder enviarlle comandos en modo texto. Permite moitas m\u00e1is opci\u00f3ns, como por exemplo, redirixir portos.</p>"},{"location":"ssh-0-chaves-tuneles/#xerar-chave-ssh","title":"\ud83d\udddd\ufe0f Xerar chave SSH","text":"<p>Hoxe en d\u00eda deber\u00edamos abandonar a autenticaci\u00f3n por usuario e clave en prol dun m\u00e9todo m\u00e1is seguro, o cifrado asim\u00e9trico que emprega chave p\u00fablica e privada.</p> <p>Dentro do noso HOME (cartafol de usuario). Habitualmente en GNU/Linux: <code>/home/USUARIO</code> e en Microsoft Windows: <code>C:\\Users\\USUARIO</code>, debe existir un directorio/cartafol <code>.ssh</code> que pode conter o seguinte:</p> <ul> <li>\ud83d\udcc1 .ssh<ul> <li>\ud83d\udcc4 known_hosts: Fingerprints dos servidores aos que nos temos conectado. A primeira vez que conectamos cun servidor, av\u00edsanos e nos amosa o fingerprint. Te\u00f3ricamente deber\u00edamos asegurarnos que \u00e9 correcto para evitar ataques tipo MITM.</li> <li>\ud83d\udcc4 authorized_keys: Fingerprints das chaves p\u00fablicas autorizadas a entrar no servidor.</li> <li>\ud83d\udcc4 config: Para non ter que empregar opci\u00f3ns ao conectar. P\u00f3dese empregar unha chave, usuario e redirecci\u00f3n de portos diferente por cada host.</li> <li>\ud83d\udd11 id_rsa: Chave privada (non publicar e protexer por frase de paso) permite descifrar/asinar o que se cifrou coa chave p\u00fablica.</li> <li>\ud83d\udd10 id_rsa.pub: Chave p\u00fablica, p\u00f3dese publicar e subir aos servidores. D\u00e9bese engadir ao final do arquivo known_hosts para autorizar a nosa chave.</li> </ul> </li> </ul> <p>Se non existe, podemos facer unha das seguintes cousas para crealo:</p> <ul> <li>Tentar conectar con calquer servidor por SSH. Exemplo: <code>ssh localhost</code>.</li> <li>Xerar unha chave SSH: <code>ssh-keygen</code>.</li> </ul>"},{"location":"ssh-0-chaves-tuneles/#microsoft-windows","title":"\ud83e\ude9f Microsoft Windows","text":"<p>Abrimos PowerShell e executamos:</p> <pre><code>ssh-keygen\n</code></pre> <p>V\u00eddeo de Youtube</p> <p></p>"},{"location":"ssh-0-chaves-tuneles/#gnulinux","title":"\ud83d\udc27 GNU/Linux","text":"<p>Abrimos unha consola xterm ou similar e executamos:</p> <pre><code>ssh-keygen\n</code></pre> <p>V\u00eddeo en ASCIINEMA</p> <p></p>"},{"location":"ssh-0-chaves-tuneles/#tunelizacion-ssh-empregando-ssh-para-redireccionar-portos-ssh-port-forwarding","title":"\ud83d\ude87 Tunelizaci\u00f3n SSH: Empregando SSH para redireccionar portos (SSH Port Forwarding)","text":"<p>Se precisamos acceder a un recurso que est\u00e1 detr\u00e1s dun firewall ou ben non \u00e9 accesible directamente pero ao que pode acceder un equipo que ten o servizo de SSH aberto e ao que nos podemos conectar, podemos crear un tunel SSH.</p> <p></p>"},{"location":"ssh-0-chaves-tuneles/#tipos-de-tuneles","title":"\u2675 Tipos de t\u00faneles","text":"<ul> <li>Locales: Abren no noso equipo (no que executamos o comando SSH) un porto. O destino pode ser o mesmo host ssh (localhost) ou outro destino ao que ese servidor te\u00f1a acceso.</li> <li>Remotos: Abren no porto do host SSH ao que nos conectamos. Podemos exportar un servizo local.</li> <li>Din\u00e1micos: Creamos un proxy socks que pode ser empregado por moitas aplicaci\u00f3ns (por exemplo, un navegador).</li> </ul>"},{"location":"ssh-0-chaves-tuneles/#comandos","title":"\ud83d\udd32 Comandos","text":"<p>Nunha consola, chamando SSH directamente podemos facer:</p> <pre><code>ssh teuser@10.133.X.X -L 1337:172.17.X.X:3306\n</code></pre> <p>Sintaxe: -L: Indica local. O n\u00famero: 1337 representa o porto local que se abrir\u00e1 no noso equipo. De conectamos a \u00e9l, levaranos \u00e1 IP: 172.17.X.X e porto 3306 a trav\u00e9s do servidor ao que nos estamos a conectar.</p>"},{"location":"ssh-0-chaves-tuneles/#quitarmudar-o-contrasinal-ou-frase-a-unha-chave","title":"Quitar/Mudar o contrasinal ou frase a unha chave","text":"<pre><code>ssh-keygen -p -f .ssh/id_rsa\n</code></pre>"},{"location":"ssh-0-chaves-tuneles/#xerar-a-chave-publica-a-partires-dunha-privada","title":"Xerar a chave p\u00fablica a partires dunha privada","text":"<pre><code>ssh-keygen -y -f .ssh/id_rsa &gt; .ssh/id_rsa.pub\n</code></pre>"},{"location":"windows-wsl/","title":"\ud83d\udc27 WSL","text":"<p>Windows Subsystem for Linux (WSL)</p>"},{"location":"windows-wsl/#requisitos-previos","title":"Requisitos previos","text":"<p>Consid\u00e9rase unha m\u00e1quina con Microsoft Windows 10/11.</p>"},{"location":"windows-wsl/#instalacion","title":"Instalaci\u00f3n","text":"<p>Require permisos de administrador ou root para instalar por primeira vez o compo\u00f1ente no sistema.</p> <p>Abrimos unha consola de PowerShell e escribimos o comando:</p> <pre><code>wsl --install\n</code></pre> <p>Por defecto instalaranos unha m\u00e1quina de Ubuntu.</p> <p>Tras a instalaci\u00f3n \u00e9 preciso reiniciar, av\u00edsanos coa mensaxe: La operaci\u00f3n solicitada se realiz\u00f3 correctamente. Los cambios se aplicar\u00e1n una vez que se reinicie el sistema..</p> <p>Tras reiniciar, se non nos entra cun simple comando wsl, volvemos a unha consola de PowerShell como usuarios e volvemos escribir:</p> <pre><code>wsl --install\n</code></pre> <p>Se queremos outro sabor de GNU/Linux podemos executar:</p> <pre><code>wsl --list --online\n</code></pre> <p></p> <p>E instalar a versi\u00f3n desexada, por exemplo:</p> <pre><code>wsl --install -d Debian\n</code></pre> <p>Recomendaci\u00f3n 1: Empregar systemd no inicio (para que inicie os demos/servizos):</p> <pre><code>echo -e \"[boot]\\nsystemd=true\"| sudo tee /etc/wsl.conf\n</code></pre> <p>Recomendaci\u00f3n 2: Permitir o uso de m\u00e1is memoria RAM Podes crear no teu cartafol de usuario un arquivo .wslconfig que se aplicar\u00eda en global a t\u00f3dalas m\u00e1quinas ou ben po\u00f1er o seguinte contido no arquivo /etc/wsl.conf dentro de cada m\u00e1quina.</p> <p><pre><code>[wsl]\nmemory=12G\n</code></pre> Podes atopar m\u00e1is informaci\u00f3n e opci\u00f3ns de configuraci\u00f3n do wsl en: https://learn.microsoft.com/en-us/windows/wsl/wsl-config</p>"},{"location":"windows-wsl/#entrar-no-sistema","title":"Entrar no sistema","text":"<p>Abrimos unha consola de PowerShell e executamos:</p> <pre><code>wsl\n</code></pre> <p>Para ver as distribuci\u00f3ns instaladas:</p> <pre><code>wsl -l\n</code></pre> <p>Se temos m\u00e1is dunha distribuci\u00f3n, debemos seleccionar cal queremos executar (ou executar\u00e1 a por defecto). Por exemplo:</p> <pre><code>wsl -d Debian\n</code></pre> <p>Dentro da m\u00e1quina entrar\u00e1 por defecto co usuario creado, con ese usuario pod\u00e9monos facer root con comando sudo: <code>sudo su</code>. Pedirache o contrasinal que elixiches ao crear a m\u00e1quina, non o contrasinal da conta de Microsoft Windows.</p>"},{"location":"windows-wsl/#apagar-un-wsl","title":"Apagar un WSL","text":"<pre><code>wsl --shutdown -d DISTRO\n</code></pre>"},{"location":"windows-wsl/#acceso-aos-arquivos","title":"Acceso aos arquivos","text":"<p>Abrir un explorador de arquivos e no enderezo, introduce: \\wsl$\\DISITRIBUCI\u00d3N. Exemplo con Ubuntu:</p> <pre><code>\\\\wsl$\\Ubuntu\n</code></pre> <p>Os arquivos g\u00e1rdanse nun ficheiro .vhdx dentro do cartafol: %LOCALAPPDATA%\\Packages\\ nese cartafol localizamos a nosa distribuci\u00f3n: TheDebian... ou CanonicalGroupLimited.Ubuntu... e dentro do cartafol da distro en: LocalState.</p>"},{"location":"windows-wsl/#actualizacion-de-wsl","title":"Actualizaci\u00f3n de WSL","text":"<p>Abrimos unha consola de PowerShell e escribimos o comando:</p> <pre><code>wsl --update\n</code></pre>"},{"location":"windows-wsl/#borrar-unha-distribucion-de-wsl","title":"Borrar unha distribuci\u00f3n de WSL","text":"<p>Imaxinemos que queremos borrar a distribuci\u00f3n Ubuntu:</p> <pre><code>wsl --unregister Ubuntu\n</code></pre>"},{"location":"windows-wsl/#exportar-e-importar-unha-distribucion","title":"Exportar e importar unha distribuci\u00f3n","text":"<p>Pode ser \u00fatil gardar unha copia de seguridade dunha distribuci\u00f3n e restaurala.</p> <pre><code>wsl --export Debian debian.tar\n</code></pre> <p>Podemos borrar a distribuci\u00f3n con: <code>wsl --unregister Debian</code></p> <pre><code>wsl --import Debian C:\\Users\\jose\\distros\\Debian C:\\Users\\jose\\debian.tar \n</code></pre> <p>Normalmente a ruta de instalaci\u00f3n por defecto adoita estar baixo: <code>C:\\Users\\**USUARIO**\\AppData\\Local\\Packages\\TheDebian...</code>. Neste exemplo creamos dentro do cartafol de usuario outro chamado \"distros\" para localizar o arquivo de disco virtual ext4.vhdx m\u00e1is f\u00e1cilmente.</p> <p>Ollo, se WSL non detecta o usuario tras unha importaci\u00f3n do sistema, devolveranos unha consola de root.</p>"},{"location":"windows-wsl/#erros-comuns","title":"Erros com\u00fans","text":""},{"location":"windows-wsl/#erro-createprocessparsecommon","title":"Erro CreateProcessParseCommon","text":"<pre><code>&lt;3&gt;WSL (10) ERROR: CreateProcessParseCommon:711: Failed to translate X:\\\n</code></pre> <p>Trata de executar os comandos de WSL na unidade por defecto onde est\u00e1 instalado o sistema operativo (habitualmente C:).</p>"},{"location":"windows-wsl/#erros-0x80370102-ou-0x8007019e-wslregisterdistribution","title":"Erros: 0x80370102 ou 0x8007019e (WslRegisterDistribution)","text":"<pre><code>WslRegisterDistribution failed with error: 0x80370102\nPlease enable the Virtual Machine Platform Windows feature and ensure virtualization is enabled in the BIOS.\nFor information please visit: https://aka.ms/enablevirtualization\nPress any key to continue...\n</code></pre> <p>Teremos que asegurarnos que:</p> <ol> <li>Virtualizaci\u00f3n activada na BIOS.</li> <li>Dependendo do SO:<ol> <li>Para Microsoft Windows 10: En \"Inicio\" -&gt; \"Aplicaciones y caracter\u00edsticas\" -&gt; \"Programas y caracter\u00edsticas\" -&gt; \"Activar o desactivar las funciones de Windows\" -&gt; En \"caracter\u00edsticas\".</li> <li>Para Microsoft Windows 11: \"Inicio\" -&gt; \"Activar o desactivar las caracter\u00edsticas de Windows\".</li> </ol> </li> <li>Busca a \"Plataforma de m\u00e1quina virtual\" e mira que estea seleccionada.</li> <li>Busca o \"Subsistema de Windows para Linux\" e mira que estea seleccionado.</li> <li>Preme en aceptar e reinicia o equipo.</li> </ol>"},{"location":"windows-wsl/#erro-non-inicia-os-demosservizos","title":"Erro: Non inicia os demos/servizos","text":"<p>Hai que indicarlle que empregue systemd: </p> <pre><code>echo -e \"[boot]\\nsystemd=true\"| sudo tee /etc/wsl.conf\n</code></pre> <p>Se segue sen funcionar, compre actualizar wsl:</p> <pre><code>wsl --update\n</code></pre>"}]}